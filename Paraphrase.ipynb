{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3d1057da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AdamW, T5ForConditionalGeneration, T5Tokenizer, Trainer, TrainingArguments, get_scheduler\n",
    "from datasets import load_dataset, load_metric\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "import gc\n",
    "from tqdm.auto import tqdm\n",
    "import random\n",
    "from copy import deepcopy\n",
    "from torch.autograd import variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "38b1cda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = T5Tokenizer.from_pretrained('t5-small')\n",
    "model = T5ForConditionalGeneration.from_pretrained('t5-small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42e2cb51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "931fee09",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5ForConditionalGeneration(\n",
       "  (shared): Embedding(32128, 512)\n",
       "  (encoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): T5Stack(\n",
       "    (embed_tokens): Embedding(32128, 512)\n",
       "    (block): ModuleList(\n",
       "      (0): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (relative_attention_bias): Embedding(32, 8)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (1): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): T5Block(\n",
       "        (layer): ModuleList(\n",
       "          (0): T5LayerSelfAttention(\n",
       "            (SelfAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (1): T5LayerCrossAttention(\n",
       "            (EncDecAttention): T5Attention(\n",
       "              (q): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (k): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (v): Linear(in_features=512, out_features=512, bias=False)\n",
       "              (o): Linear(in_features=512, out_features=512, bias=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (2): T5LayerFF(\n",
       "            (DenseReluDense): T5DenseReluDense(\n",
       "              (wi): Linear(in_features=512, out_features=2048, bias=False)\n",
       "              (wo): Linear(in_features=2048, out_features=512, bias=False)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (layer_norm): T5LayerNorm()\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (final_layer_norm): T5LayerNorm()\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (lm_head): Linear(in_features=512, out_features=32128, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6ace84ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "242026496"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.memory_allocated(device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "33d5629c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset squad (C:\\Users\\Pranav\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8880a6527af8435bb5365c63f16e57a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=2.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 87599\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
       "        num_rows: 10570\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad_raw = load_dataset('squad')\n",
    "squad_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "da8745eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_squad(examples):\n",
    "    return {'id': examples['id'],\n",
    "            'src':\n",
    "                ['question: ' + question + ' context: ' + context\n",
    "                 for question, context in zip(examples['question'], examples['context'])\n",
    "                ],\n",
    "            'trg': [answer['text'][0] for answer in examples['answers']],\n",
    "            'answers': examples['answers']\n",
    "           }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b264053b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Pranav\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\\cache-961250d0cdb39e2a.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Pranav\\.cache\\huggingface\\datasets\\squad\\plain_text\\1.0.0\\d6ec3ceb99ca480ce37cdd35555d6cb2511d223b9150cce08a837ef62ffea453\\cache-e448ae214532babe.arrow\n"
     ]
    }
   ],
   "source": [
    "squad = squad_raw.map(preprocess_squad, batched=True, remove_columns=squad_raw['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34b21879",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['answers', 'id', 'src', 'trg'],\n",
       "    num_rows: 10570\n",
       "})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "squad['validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a464030d",
   "metadata": {},
   "outputs": [],
   "source": [
    "squad_metric = load_metric(\"squad\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f4d76c0",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def eval_squad(model):\n",
    "    progress_bar = tqdm(range(len(squad['validation'])))\n",
    "\n",
    "    model.eval()\n",
    "    b_size = 32\n",
    "    start = 0\n",
    "    end = b_size\n",
    "    exists = True\n",
    "    while exists:\n",
    "        examples = squad['validation'][start: end]\n",
    "        input_ids = tokenizer(examples['src'], return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "        with torch.no_grad():\n",
    "            outputs = model.generate(input_ids=input_ids)\n",
    "\n",
    "        decoded = [{'id': ide, 'prediction_text': tokenizer.decode(outputs[i], skip_special_tokens=True)} for i, ide in zip(range(len(examples['id'])), examples['id'])]\n",
    "        refs = [{'id': examples['id'][i], 'answers': ans} for i, ans in enumerate(examples['answers'])]\n",
    "        squad_metric.add_batch(predictions=decoded, references=refs)\n",
    "        progress_bar.update(len(examples['id']))\n",
    "        start = end\n",
    "        end = -1 if end + b_size >= len(squad['validation']) else end + b_size\n",
    "        if start == -1:\n",
    "            break\n",
    "\n",
    "    return squad_metric.compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c56a3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_squad(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "019755bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Reusing dataset paws (C:\\Users\\Pranav\\.cache\\huggingface\\datasets\\paws\\labeled_final\\1.1.0\\09d8fae989bb569009a8f5b879ccf2924d3e5cd55bfe2e89e6dab1c0b50ecd34)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "af8352c0e2b3468589ea099be01fead4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=3.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "raw_paraphrases = load_dataset('paws', 'labeled_final')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a44c4853",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Pranav\\.cache\\huggingface\\datasets\\paws\\labeled_final\\1.1.0\\09d8fae989bb569009a8f5b879ccf2924d3e5cd55bfe2e89e6dab1c0b50ecd34\\cache-f8f4b05c63816056.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Pranav\\.cache\\huggingface\\datasets\\paws\\labeled_final\\1.1.0\\09d8fae989bb569009a8f5b879ccf2924d3e5cd55bfe2e89e6dab1c0b50ecd34\\cache-9bfc9aaee2aa1e33.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Pranav\\.cache\\huggingface\\datasets\\paws\\labeled_final\\1.1.0\\09d8fae989bb569009a8f5b879ccf2924d3e5cd55bfe2e89e6dab1c0b50ecd34\\cache-274702c64a43f78c.arrow\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['id', 'sentence1', 'sentence2', 'label'],\n",
       "        num_rows: 21829\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['id', 'sentence1', 'sentence2', 'label'],\n",
       "        num_rows: 3536\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['id', 'sentence1', 'sentence2', 'label'],\n",
       "        num_rows: 3539\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrases = raw_paraphrases.filter(lambda example: example['label'] == 1)\n",
    "paraphrases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "06b8918b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def insert_task_name(examples):\n",
    "    return {\n",
    "        'sentence1': ['paraphrase: ' + example for example in examples['sentence1']] + ['paraphrase: ' + example for example in examples['sentence2']],\n",
    "        'sentence2': [example for example in examples['sentence2']] + [example for example in examples['sentence1']]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2875bfd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading cached processed dataset at C:\\Users\\Pranav\\.cache\\huggingface\\datasets\\paws\\labeled_final\\1.1.0\\09d8fae989bb569009a8f5b879ccf2924d3e5cd55bfe2e89e6dab1c0b50ecd34\\cache-37d241fc255f3358.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Pranav\\.cache\\huggingface\\datasets\\paws\\labeled_final\\1.1.0\\09d8fae989bb569009a8f5b879ccf2924d3e5cd55bfe2e89e6dab1c0b50ecd34\\cache-60b05b6bb815b979.arrow\n",
      "Loading cached processed dataset at C:\\Users\\Pranav\\.cache\\huggingface\\datasets\\paws\\labeled_final\\1.1.0\\09d8fae989bb569009a8f5b879ccf2924d3e5cd55bfe2e89e6dab1c0b50ecd34\\cache-8f7ea547eff87668.arrow\n"
     ]
    }
   ],
   "source": [
    "paraphrases = paraphrases.map(insert_task_name, batched=True, remove_columns=paraphrases['train'].column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4b01994e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'sentence1': 'paraphrase: The NBA season of 1975 -- 76 was the 30th season of the National Basketball Association .',\n",
       "  'sentence2': 'The 1975 -- 76 season of the National Basketball Association was the 30th season of the NBA .'},\n",
       " {'sentence1': 'paraphrase: When comparable rates of flow can be maintained , the results are high .',\n",
       "  'sentence2': 'The results are high when comparable flow rates can be maintained .'})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paraphrases['train'][0], paraphrases['train'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a303659c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(paraphrases['train'], shuffle=True, batch_size=8)\n",
    "eval_loader = DataLoader(paraphrases['validation'], batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "52fc3c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "248f7345",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "num_training_steps = num_epochs * len(train_loader)\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "65bb16c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler\n",
    "def train():\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        for batch in train_loader:\n",
    "            input_ids = tokenizer(batch['sentence1'], return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "            labels = tokenizer(batch['sentence2'], return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "            outputs = model(input_ids=input_ids, labels=labels)\n",
    "            print(outputs.loss)\n",
    "            outputs.loss.backward()\n",
    "            print(torch.all(torch.tensor([torch.all(p.grad == 0) for n, p, in model.named_parameters()])))\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            del input_ids\n",
    "            del labels\n",
    "            del outputs\n",
    "            progress_bar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc295c2b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "741319311249416f975b6c77e049c194",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=16374.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2.3593, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.9244, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.6482, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(2.2818, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(2.0558, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(2.0197, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.8280, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(2.1202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(2.0513, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.7575, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.6337, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(2.5335, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.9168, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.3590, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.6405, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.7152, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.6065, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.4841, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.4990, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.5831, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.5965, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.3643, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.4458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.4165, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.6427, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.3013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.1951, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.3184, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.1937, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.4531, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.5798, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.3761, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.3665, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.3740, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.8250, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.2368, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.2013, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.3892, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.3156, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.1691, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.1609, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.0467, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.1018, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.0454, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.0173, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.2616, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.4930, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.0871, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.4406, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.0202, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.2166, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.0882, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.0457, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.1354, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.2858, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.3962, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.2009, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.0211, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.3046, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(0.9747, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.3463, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.0339, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.1401, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(0.9324, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.2045, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(0.7720, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.1039, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.2606, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.0994, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(1.1458, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(0.8594, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(0.9383, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(0.9174, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "tensor(False)\n",
      "tensor(0.9701, device='cuda:0', grad_fn=<NllLossBackward>)\n",
      "*** KeyboardInterrupt exception caught in code being profiled."
     ]
    }
   ],
   "source": [
    "%lprun -f train train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "908a76df",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EWC:\n",
    "    def __init__(self, model: nn.Module, dataset: list):\n",
    "\n",
    "        self.model = model\n",
    "        self.dataset = dataset\n",
    "\n",
    "        self.params = {n: p for n, p in self.model.named_parameters() if p.requires_grad}\n",
    "        self._means = {}\n",
    "        self._precision_matrices = self._diag_fisher()\n",
    "\n",
    "        for n, p in deepcopy(self.params).items():\n",
    "            self._means[n] = p.data.clone().detach().requires_grad_(True)\n",
    "\n",
    "    def _diag_fisher(self):\n",
    "        precision_matrices = {}\n",
    "        for n, p in deepcopy(self.params).items():\n",
    "            p.data.zero_()\n",
    "            precision_matrices[n] = p.data.clone().detach().requires_grad_(True)\n",
    "\n",
    "        for src, trg in self.dataset:\n",
    "            self.model.zero_grad()\n",
    "            input_ids = tokenizer(src, return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "            labels = tokenizer(trg, return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "            output = self.model(input_ids=input_ids, labels=labels).logits\n",
    "            loss = F.nll_loss(F.log_softmax(output, dim=2).squeeze(), labels.squeeze())\n",
    "            loss.backward()\n",
    "            del input_ids\n",
    "            del labels\n",
    "            del output\n",
    "\n",
    "            for n, p in self.model.named_parameters():\n",
    "                precision_matrices[n].data += p.grad.data ** 2 / len(self.dataset)\n",
    "\n",
    "        precision_matrices = {n: p for n, p in precision_matrices.items()}\n",
    "        return precision_matrices\n",
    "\n",
    "    def penalty(self, model: nn.Module):\n",
    "        loss = 0\n",
    "        for n, p in model.named_parameters():\n",
    "            _loss = self._precision_matrices[n] * (p - self._means[n]) ** 2\n",
    "            print(p - self._means[n])\n",
    "            loss += _loss.sum()\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d6f2e7aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = random.sample(list(zip(squad['train']['src'], squad['train']['trg'])), 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c0fc61f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ewc = EWC(model, samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f2e04b4d",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'shared.weight': tensor([[3.5317e-07, 1.2976e-06, 5.1204e-08,  ..., 1.5378e-08, 1.8123e-07,\n",
       "          4.3740e-07],\n",
       "         [2.7781e-07, 3.8440e-07, 1.4131e-07,  ..., 3.5741e-07, 1.2566e-08,\n",
       "          3.4311e-07],\n",
       "         [3.8527e-11, 6.6937e-11, 3.7453e-11,  ..., 2.1120e-11, 6.6215e-12,\n",
       "          2.5619e-11],\n",
       "         ...,\n",
       "         [2.2584e-40, 9.8149e-40, 9.2487e-41,  ..., 2.7520e-40, 5.1848e-44,\n",
       "          2.1676e-40],\n",
       "         [1.6189e-40, 6.7725e-40, 6.1530e-41,  ..., 1.8451e-40, 4.7644e-44,\n",
       "          1.4633e-40],\n",
       "         [1.4914e-40, 6.0309e-40, 5.4145e-41,  ..., 1.6387e-40, 4.7644e-44,\n",
       "          1.3058e-40]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.0.layer.0.SelfAttention.q.weight': tensor([[1.9472e-05, 4.6931e-06, 1.3818e-05,  ..., 3.2332e-06, 3.6220e-06,\n",
       "          1.8747e-05],\n",
       "         [1.7118e-05, 4.2751e-06, 5.5334e-06,  ..., 1.1947e-06, 5.7039e-06,\n",
       "          1.1829e-05],\n",
       "         [7.0245e-05, 3.0151e-06, 6.9561e-06,  ..., 6.2099e-06, 1.5882e-05,\n",
       "          1.9715e-05],\n",
       "         ...,\n",
       "         [4.2268e-06, 2.8433e-06, 8.3669e-06,  ..., 2.7170e-06, 4.9643e-06,\n",
       "          3.7470e-06],\n",
       "         [2.6900e-06, 1.8274e-06, 5.9854e-06,  ..., 7.5542e-06, 1.5504e-06,\n",
       "          1.4126e-05],\n",
       "         [3.8697e-05, 2.8598e-06, 1.6259e-05,  ..., 7.8940e-06, 1.5619e-05,\n",
       "          6.1190e-06]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.0.layer.0.SelfAttention.k.weight': tensor([[1.3150e-07, 8.1544e-08, 2.0199e-07,  ..., 5.6267e-08, 2.4437e-07,\n",
       "          3.8912e-08],\n",
       "         [2.1878e-08, 6.7020e-08, 1.2080e-06,  ..., 4.5829e-07, 2.2331e-07,\n",
       "          1.3096e-07],\n",
       "         [1.6101e-07, 1.4737e-07, 1.3958e-07,  ..., 2.3760e-07, 3.6859e-07,\n",
       "          4.5141e-07],\n",
       "         ...,\n",
       "         [6.0868e-08, 1.4386e-07, 1.4786e-07,  ..., 9.4213e-08, 8.1678e-08,\n",
       "          1.0286e-07],\n",
       "         [1.1163e-07, 1.3090e-07, 1.0688e-07,  ..., 6.2864e-08, 5.8942e-08,\n",
       "          1.1098e-07],\n",
       "         [5.4915e-08, 1.5550e-07, 1.1116e-07,  ..., 4.5590e-08, 1.0769e-07,\n",
       "          1.0393e-07]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.0.layer.0.SelfAttention.v.weight': tensor([[5.2606e-07, 5.6370e-07, 4.1031e-07,  ..., 1.2921e-06, 2.7238e-07,\n",
       "          1.0515e-06],\n",
       "         [1.4880e-06, 2.5550e-07, 1.4158e-06,  ..., 3.7955e-07, 4.7489e-07,\n",
       "          1.0630e-05],\n",
       "         [1.8186e-06, 7.2591e-06, 5.2502e-06,  ..., 6.5522e-07, 6.9157e-07,\n",
       "          2.0715e-06],\n",
       "         ...,\n",
       "         [5.1520e-07, 8.6149e-07, 1.1257e-06,  ..., 2.2654e-06, 2.8599e-07,\n",
       "          5.7711e-07],\n",
       "         [1.1988e-06, 3.0258e-06, 2.7612e-06,  ..., 5.1773e-07, 6.3310e-07,\n",
       "          1.1075e-06],\n",
       "         [2.1476e-07, 1.5864e-06, 6.9687e-07,  ..., 7.6058e-07, 4.6265e-07,\n",
       "          3.3379e-06]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.0.layer.0.SelfAttention.o.weight': tensor([[2.1365e-06, 7.5184e-07, 8.7502e-07,  ..., 4.0190e-07, 6.5952e-07,\n",
       "          2.3878e-07],\n",
       "         [1.1353e-06, 1.2354e-06, 1.1479e-06,  ..., 5.0827e-07, 8.6255e-06,\n",
       "          1.0215e-06],\n",
       "         [6.4591e-07, 1.4986e-06, 2.7339e-07,  ..., 3.8902e-07, 2.5327e-06,\n",
       "          4.8269e-07],\n",
       "         ...,\n",
       "         [1.7666e-06, 2.0955e-06, 1.3707e-06,  ..., 3.4374e-07, 1.9204e-06,\n",
       "          1.9298e-07],\n",
       "         [4.9540e-07, 4.9123e-07, 5.7744e-07,  ..., 5.0412e-07, 9.5641e-07,\n",
       "          1.5687e-07],\n",
       "         [4.2740e-06, 3.6129e-06, 3.3123e-07,  ..., 7.0490e-07, 1.1548e-06,\n",
       "          2.9668e-06]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight': tensor([[8.3047e-05, 2.9362e-04, 3.9525e-09, 1.8037e-03, 1.2081e-05, 8.5326e-05,\n",
       "          3.0549e-05, 1.1029e-04],\n",
       "         [3.2971e-03, 9.9880e-05, 2.5684e-05, 1.5667e-04, 8.5310e-04, 4.5261e-03,\n",
       "          1.1676e-06, 4.8850e-06],\n",
       "         [2.9078e-03, 1.1835e-04, 1.6283e-04, 4.4126e-04, 1.1944e-03, 2.6775e-03,\n",
       "          4.6351e-06, 8.9643e-07],\n",
       "         [1.9222e-03, 5.1184e-05, 4.8664e-05, 3.2423e-04, 1.1956e-03, 5.6176e-04,\n",
       "          8.4803e-07, 8.5298e-07],\n",
       "         [1.2510e-03, 4.8043e-05, 1.4925e-04, 3.4488e-04, 5.5383e-03, 2.1765e-04,\n",
       "          2.5594e-06, 1.0154e-06],\n",
       "         [3.4446e-03, 1.5482e-05, 1.5011e-04, 2.1992e-04, 1.3967e-03, 4.8313e-05,\n",
       "          3.9849e-07, 6.5294e-07],\n",
       "         [1.8994e-04, 3.1987e-05, 1.5275e-04, 1.7321e-04, 2.9918e-03, 6.4678e-06,\n",
       "          1.6330e-06, 3.6556e-07],\n",
       "         [8.6102e-04, 2.9883e-05, 5.1622e-04, 1.1809e-03, 7.6401e-04, 3.2405e-05,\n",
       "          3.6981e-06, 3.0637e-07],\n",
       "         [3.9046e-04, 3.0513e-04, 2.4241e-03, 1.4030e-03, 9.0517e-03, 2.5456e-05,\n",
       "          1.0107e-05, 8.5714e-06],\n",
       "         [2.8864e-04, 3.4985e-05, 4.9852e-04, 1.1696e-03, 6.3401e-03, 3.9623e-05,\n",
       "          2.1231e-05, 4.5085e-06],\n",
       "         [7.0073e-05, 1.0170e-04, 1.6316e-03, 2.9529e-03, 2.4605e-03, 3.7307e-05,\n",
       "          7.3930e-06, 1.8026e-06],\n",
       "         [4.7102e-05, 4.2916e-04, 4.2359e-03, 8.6686e-04, 1.1852e-02, 1.8840e-04,\n",
       "          4.7508e-05, 2.1183e-06],\n",
       "         [1.4363e-06, 7.6113e-05, 2.7515e-03, 2.2149e-03, 1.2702e-03, 2.8377e-05,\n",
       "          9.6493e-05, 2.7144e-05],\n",
       "         [2.2039e-06, 2.9489e-04, 2.8858e-02, 2.2105e-03, 1.9678e-04, 3.6510e-04,\n",
       "          2.0256e-04, 1.0906e-04],\n",
       "         [1.4247e-07, 1.0425e-03, 5.8805e-03, 5.2789e-03, 1.2275e-04, 3.2218e-04,\n",
       "          1.1619e-04, 6.8823e-05],\n",
       "         [2.7668e-09, 2.5514e-04, 3.4996e-03, 1.2294e-02, 7.0957e-06, 1.4641e-04,\n",
       "          1.2327e-04, 3.0516e-05],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [2.7102e-05, 5.1516e-03, 3.8708e-06, 2.4295e-04, 9.2802e-07, 8.9990e-05,\n",
       "          4.8678e-03, 1.4922e-02],\n",
       "         [3.0142e-07, 1.2962e-03, 1.2084e-04, 5.1310e-04, 3.1294e-06, 2.9049e-05,\n",
       "          4.1063e-03, 6.6739e-03],\n",
       "         [2.6545e-07, 6.3441e-04, 3.6256e-05, 2.2672e-04, 5.8783e-06, 3.7356e-04,\n",
       "          2.0502e-03, 4.4519e-03],\n",
       "         [5.6172e-07, 2.8319e-04, 9.9448e-05, 1.7412e-04, 2.0006e-05, 1.6172e-05,\n",
       "          2.1508e-03, 3.6063e-03],\n",
       "         [1.0402e-06, 2.1911e-04, 7.3242e-05, 1.5155e-04, 5.9811e-06, 7.3992e-05,\n",
       "          1.9079e-03, 7.2393e-04],\n",
       "         [5.7589e-06, 4.0644e-05, 2.8332e-04, 3.1260e-04, 4.8227e-05, 6.8401e-06,\n",
       "          4.8917e-04, 5.3406e-04],\n",
       "         [2.8766e-06, 1.1548e-04, 2.7355e-04, 1.5341e-04, 1.0518e-05, 1.0414e-05,\n",
       "          1.1060e-03, 1.0161e-03],\n",
       "         [3.4985e-06, 4.7070e-04, 1.4480e-03, 2.7664e-04, 7.8546e-05, 8.3844e-04,\n",
       "          4.5946e-03, 5.8822e-05],\n",
       "         [6.7976e-07, 1.4465e-04, 1.4603e-04, 1.5563e-03, 5.7582e-06, 1.2492e-05,\n",
       "          3.2767e-03, 4.2378e-05],\n",
       "         [4.3181e-07, 3.7581e-04, 1.4813e-03, 7.2431e-03, 2.8108e-05, 6.5753e-06,\n",
       "          2.8711e-03, 4.2112e-05],\n",
       "         [1.2640e-06, 3.8721e-04, 3.2348e-04, 1.6848e-03, 3.7290e-05, 7.3487e-05,\n",
       "          1.4113e-03, 4.9279e-06],\n",
       "         [1.7964e-05, 5.4265e-04, 2.5474e-03, 3.3452e-03, 5.9170e-05, 2.0600e-04,\n",
       "          7.5583e-04, 8.4513e-05],\n",
       "         [5.3579e-04, 4.3648e-04, 4.3368e-03, 8.7192e-03, 3.9675e-04, 5.6590e-04,\n",
       "          3.2904e-03, 8.0115e-05],\n",
       "         [2.3339e-05, 3.3667e-05, 1.5278e-03, 4.2428e-03, 2.3097e-04, 1.3825e-04,\n",
       "          2.1877e-04, 1.2009e-04],\n",
       "         [4.4047e-03, 5.6069e-04, 1.3970e-02, 1.1757e-02, 2.4274e-03, 5.3645e-03,\n",
       "          4.0092e-03, 1.5433e-03]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.0.layer.0.layer_norm.weight': tensor([0.0675, 0.0115, 0.0243, 0.0065, 0.0049, 0.0274, 0.0039, 0.0060, 0.0012,\n",
       "         0.0295, 0.0461, 0.0234, 0.0142, 0.0629, 0.0310, 0.0320, 0.0132, 0.0178,\n",
       "         0.0076, 0.0287, 0.0230, 0.0125, 0.0104, 0.0340, 0.0185, 0.0164, 0.0504,\n",
       "         0.0261, 0.0362, 0.0669, 0.0200, 0.0104, 0.0432, 0.0304, 0.0641, 0.0390,\n",
       "         0.1586, 0.0280, 0.0081, 0.0091, 0.0086, 0.0474, 0.0274, 0.0435, 0.0176,\n",
       "         0.1153, 0.0025, 0.0106, 0.0146, 0.0110, 0.0152, 0.0267, 0.0290, 0.0239,\n",
       "         0.0157, 0.0493, 0.0605, 0.0269, 0.0242, 0.1086, 0.0495, 0.0177, 0.0214,\n",
       "         0.0344, 0.1232, 0.0123, 0.1257, 0.0553, 0.0040, 0.0151, 0.0089, 0.1157,\n",
       "         0.0192, 0.0423, 0.0107, 0.0213, 0.0072, 0.0327, 0.0082, 0.0067, 0.0087,\n",
       "         0.0407, 0.0677, 0.0071, 0.0458, 0.0164, 0.0271, 0.0116, 0.0123, 0.0015,\n",
       "         0.0348, 0.0155, 0.0333, 0.0361, 0.0258, 0.0065, 0.0197, 0.0383, 0.2008,\n",
       "         0.0430, 0.0125, 0.0281, 0.0085, 0.0063, 0.1088, 0.0297, 0.0273, 0.0366,\n",
       "         0.0529, 0.0107, 0.0144, 0.0144, 0.0352, 0.0316, 0.0674, 0.0275, 0.0251,\n",
       "         0.0304, 0.1328, 0.0232, 0.0210, 0.0202, 0.0157, 0.0094, 0.0124, 0.0104,\n",
       "         0.0415, 0.0191, 0.7704, 0.0309, 0.0225, 0.0773, 0.0483, 0.0263, 0.0088,\n",
       "         0.0342, 0.0178, 0.0090, 0.0296, 0.0917, 0.0109, 0.0056, 0.0263, 0.0408,\n",
       "         0.0565, 0.0501, 0.0387, 0.0287, 0.0210, 0.0232, 0.0113, 0.2500, 0.0220,\n",
       "         0.0221, 0.0083, 0.0752, 0.0243, 0.0144, 0.0101, 0.1118, 0.0587, 0.0245,\n",
       "         0.0249, 0.0254, 0.0088, 0.0391, 0.0664, 0.0112, 0.0101, 0.0865, 0.0228,\n",
       "         0.0461, 0.0070, 0.0151, 0.0087, 0.0231, 0.0191, 0.0035, 0.0418, 0.0441,\n",
       "         0.1901, 0.0081, 0.0067, 0.0041, 0.0897, 0.0160, 0.1412, 0.0386, 0.0381,\n",
       "         0.0199, 0.0565, 0.0061, 0.0355, 0.0118, 0.0117, 0.0220, 0.0214, 0.0237,\n",
       "         0.0179, 0.0587, 0.0064, 0.0086, 0.0101, 0.0213, 0.0085, 0.0094, 0.0217,\n",
       "         0.0291, 0.0287, 0.0394, 0.0236, 0.0318, 0.0131, 0.0144, 0.0057, 0.1171,\n",
       "         0.0405, 0.0201, 0.0094, 0.0719, 0.0511, 0.0438, 0.0165, 0.0109, 0.0138,\n",
       "         0.0838, 0.0671, 0.0381, 0.0285, 0.0472, 0.0192, 0.0203, 0.0083, 0.0948,\n",
       "         0.0059, 0.0216, 0.0322, 0.0217, 0.0160, 0.0246, 0.0069, 0.1066, 0.0570,\n",
       "         0.0207, 0.0151, 0.0044, 0.0283, 0.0186, 0.0109, 0.0389, 0.0279, 0.0224,\n",
       "         0.0091, 0.1023, 0.0121, 0.0199, 0.0184, 0.0779, 0.0215, 0.0184, 0.0453,\n",
       "         0.0451, 0.0175, 0.0289, 0.0189, 0.0816, 0.0100, 0.0453, 0.0317, 0.0327,\n",
       "         0.0201, 0.0254, 0.0348, 0.0059, 0.0790, 0.0155, 0.0140, 0.0267, 0.0277,\n",
       "         0.0100, 0.0184, 0.0132, 0.0196, 0.0364, 0.0089, 0.0349, 0.0187, 0.0943,\n",
       "         0.0105, 0.0904, 0.0160, 0.0751, 0.1163, 0.0587, 0.0124, 0.0129, 0.0138,\n",
       "         0.0121, 0.0107, 0.0097, 0.0042, 0.0082, 0.0112, 0.0187, 0.0038, 0.0175,\n",
       "         0.0181, 0.0062, 0.0387, 0.0060, 0.0165, 0.0113, 0.0050, 0.0436, 0.0156,\n",
       "         0.0993, 0.0718, 0.0447, 0.0364, 0.0270, 0.0319, 0.0294, 0.1643, 0.0045,\n",
       "         0.0154, 0.0089, 0.0327, 0.0227, 0.0131, 0.0268, 0.0129, 0.0215, 0.0070,\n",
       "         0.0314, 0.0232, 0.0338, 0.0183, 0.0347, 0.0293, 0.0565, 0.0048, 0.0125,\n",
       "         0.0229, 0.0081, 0.0687, 0.0442, 0.0350, 0.0206, 0.0782, 0.0586, 0.0189,\n",
       "         0.0219, 0.0152, 0.0400, 0.0715, 0.0101, 0.0219, 0.0139, 0.0131, 0.0257,\n",
       "         0.0213, 0.0252, 0.0257, 0.0068, 0.0177, 0.0230, 0.0581, 0.0037, 0.0473,\n",
       "         0.0324, 0.0178, 0.0117, 0.1105, 0.0778, 0.0281, 0.0319, 0.0467, 0.0376,\n",
       "         0.0122, 0.0071, 0.1161, 0.0105, 0.0145, 0.0125, 0.0094, 0.0252, 0.0198,\n",
       "         0.0600, 0.0194, 0.0172, 0.0219, 0.0251, 0.0401, 0.0968, 0.0094, 0.0568,\n",
       "         0.0671, 0.0146, 0.0093, 0.0665, 0.0226, 0.0132, 0.0233, 0.0043, 0.0157,\n",
       "         0.0376, 0.0164, 0.0489, 0.0471, 0.0608, 0.0298, 0.0173, 0.0067, 0.0303,\n",
       "         0.0437, 0.0202, 0.0241, 0.0308, 0.0473, 0.0299, 0.0077, 0.0331, 0.0326,\n",
       "         0.0401, 0.0651, 0.0877, 0.0307, 0.0398, 0.0837, 0.0274, 0.0267, 0.0222,\n",
       "         0.0247, 0.0078, 0.0551, 0.0485, 0.0047, 0.1193, 0.0091, 0.0173, 0.0362,\n",
       "         0.0303, 0.0227, 0.0236, 0.0788, 0.0405, 0.0217, 0.0150, 0.0121, 0.0321,\n",
       "         0.0776, 0.0834, 0.0208, 0.0127, 0.0049, 0.0242, 0.0203, 0.0487, 0.0226,\n",
       "         0.0961, 0.0508, 0.0524, 0.0143, 0.0472, 0.0614, 0.0352, 0.0217, 0.0127,\n",
       "         0.0155, 0.1449, 0.0805, 0.0162, 0.0122, 0.1194, 0.0298, 0.0142, 0.0637,\n",
       "         0.0187, 0.0439, 0.0471, 0.0096, 0.0265, 0.0184, 0.0608, 0.0460, 0.0311,\n",
       "         0.0208, 0.0180, 0.0246, 0.0245, 0.0061, 0.0185, 0.0336, 0.0370, 0.0675,\n",
       "         0.0160, 0.0201, 0.0157, 0.0432, 0.0364, 0.0325, 0.0077, 0.0114, 0.0645,\n",
       "         0.1632, 0.0185, 0.0059, 0.0370, 0.0132, 0.0455, 0.0133, 0.0255],\n",
       "        device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.0.layer.1.DenseReluDense.wi.weight': tensor([[2.7746e-07, 6.8370e-07, 3.6886e-07,  ..., 6.6275e-07, 3.9611e-07,\n",
       "          6.2435e-07],\n",
       "         [1.0711e-08, 4.1436e-09, 9.4616e-07,  ..., 2.3942e-07, 1.8019e-07,\n",
       "          3.3370e-08],\n",
       "         [1.4274e-06, 8.6619e-07, 4.7356e-07,  ..., 6.8637e-07, 6.1166e-07,\n",
       "          1.7843e-06],\n",
       "         ...,\n",
       "         [9.0021e-08, 6.5948e-09, 6.0656e-07,  ..., 6.1557e-07, 3.2865e-07,\n",
       "          9.7213e-08],\n",
       "         [5.8970e-09, 4.4068e-08, 8.3755e-08,  ..., 4.6940e-08, 1.5073e-07,\n",
       "          1.7518e-08],\n",
       "         [9.7870e-09, 1.7165e-08, 2.6068e-08,  ..., 1.3047e-07, 4.6584e-09,\n",
       "          2.0219e-07]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.0.layer.1.DenseReluDense.wo.weight': tensor([[3.8557e-07, 9.6970e-08, 6.6006e-07,  ..., 1.6419e-08, 2.8099e-07,\n",
       "          1.2699e-06],\n",
       "         [2.4168e-07, 3.9371e-07, 2.9181e-06,  ..., 6.1545e-08, 6.3336e-07,\n",
       "          3.2867e-07],\n",
       "         [1.2824e-07, 7.9576e-06, 2.3108e-07,  ..., 4.1819e-08, 8.4117e-07,\n",
       "          6.0101e-07],\n",
       "         ...,\n",
       "         [4.1594e-07, 1.0351e-06, 2.2886e-06,  ..., 4.0594e-08, 3.1048e-07,\n",
       "          3.7346e-08],\n",
       "         [8.1002e-07, 1.7245e-07, 2.7581e-07,  ..., 1.2342e-08, 2.1763e-07,\n",
       "          1.1590e-07],\n",
       "         [8.8312e-07, 6.8789e-07, 4.3308e-07,  ..., 6.2479e-08, 5.2313e-08,\n",
       "          5.6327e-07]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.0.layer.1.layer_norm.weight': tensor([1.6886e-03, 1.8698e-03, 3.1276e-03, 1.8389e-03, 3.0609e-04, 4.9860e-03,\n",
       "         1.1095e-03, 4.3896e-03, 1.9786e-04, 5.6558e-03, 8.7949e-03, 2.2355e-03,\n",
       "         2.8671e-03, 6.0683e-03, 8.6535e-04, 9.0901e-04, 8.3515e-03, 7.6367e-04,\n",
       "         1.2261e-03, 6.5155e-04, 4.4670e-03, 9.9583e-03, 4.9387e-03, 3.3186e-04,\n",
       "         3.5669e-03, 1.3205e-03, 2.5575e-03, 2.0178e-03, 1.5687e-03, 1.0104e-02,\n",
       "         4.1979e-03, 2.2569e-03, 5.8743e-04, 3.3637e-03, 1.9110e-03, 1.1584e-03,\n",
       "         2.1363e-03, 6.8661e-03, 1.3432e-03, 3.3639e-03, 6.0497e-03, 5.4301e-03,\n",
       "         5.1186e-03, 4.3814e-03, 3.1056e-03, 2.2140e-03, 2.4222e-04, 1.6707e-03,\n",
       "         1.1459e-03, 5.2476e-03, 4.3601e-03, 3.8033e-03, 1.8234e-03, 7.7533e-03,\n",
       "         2.0770e-03, 3.0792e-03, 2.6586e-03, 4.5140e-03, 3.6354e-03, 2.3896e-03,\n",
       "         3.2473e-03, 7.7702e-03, 1.2835e-03, 1.1373e-03, 8.9135e-03, 3.1926e-03,\n",
       "         2.0962e-03, 3.1152e-03, 8.6662e-04, 1.7492e-03, 5.8786e-03, 4.1695e-03,\n",
       "         3.6985e-03, 2.8941e-03, 1.7985e-03, 7.8542e-04, 8.7321e-03, 3.9501e-04,\n",
       "         5.3341e-04, 3.0891e-03, 4.2267e-03, 9.2382e-03, 5.4669e-03, 6.2648e-04,\n",
       "         4.1000e-03, 5.6691e-04, 1.7424e-02, 2.5256e-03, 6.4689e-03, 3.6897e-04,\n",
       "         5.9940e-03, 4.7487e-03, 2.6604e-03, 5.0545e-03, 1.8392e-03, 9.2252e-03,\n",
       "         1.6571e-03, 3.4739e-03, 4.6066e-02, 1.4267e-03, 5.0840e-03, 1.0902e-03,\n",
       "         1.1608e-03, 3.5927e-03, 3.5537e-03, 6.2855e-03, 3.5850e-03, 1.7170e-03,\n",
       "         9.3327e-03, 2.9551e-03, 3.3000e-03, 1.4224e-03, 3.8019e-03, 2.6427e-03,\n",
       "         3.7237e-03, 2.2487e-03, 3.2226e-03, 1.8994e-03, 7.4571e-03, 1.6914e-03,\n",
       "         8.6742e-04, 3.8087e-03, 4.2146e-03, 8.2509e-04, 6.3241e-03, 1.5824e-03,\n",
       "         1.9310e-03, 6.5938e-03, 1.4608e-02, 2.2669e-03, 1.9621e-03, 4.9056e-03,\n",
       "         2.2793e-03, 2.2211e-03, 5.8588e-04, 3.4350e-03, 1.5075e-03, 8.9066e-04,\n",
       "         8.9557e-04, 4.4038e-03, 6.7718e-04, 1.1903e-03, 4.5972e-03, 2.8115e-03,\n",
       "         7.4220e-04, 2.5510e-03, 5.6897e-04, 8.0990e-03, 1.0608e-02, 2.1604e-03,\n",
       "         1.6072e-03, 4.8116e-03, 2.0599e-03, 5.3200e-03, 1.1741e-03, 5.2241e-03,\n",
       "         7.2681e-04, 1.3568e-03, 6.4767e-04, 4.3028e-04, 3.1792e-03, 2.1030e-03,\n",
       "         2.6808e-03, 1.9954e-03, 1.3564e-03, 4.7014e-03, 2.7534e-03, 7.8071e-04,\n",
       "         2.5998e-03, 1.4588e-03, 1.9890e-03, 2.7148e-03, 7.8861e-03, 3.8573e-03,\n",
       "         9.3141e-04, 1.1169e-03, 4.9984e-03, 7.2091e-04, 4.4431e-03, 2.2114e-03,\n",
       "         3.4761e-03, 4.4883e-03, 1.8119e-03, 1.6360e-03, 2.0555e-03, 1.1753e-03,\n",
       "         3.5384e-03, 2.2402e-04, 4.0723e-03, 8.1285e-04, 9.2711e-04, 3.7055e-02,\n",
       "         4.8576e-03, 3.8647e-03, 1.7587e-03, 1.2415e-03, 3.0970e-03, 1.5850e-03,\n",
       "         3.0934e-03, 3.8565e-03, 2.1111e-03, 1.2365e-03, 3.5784e-03, 2.2463e-03,\n",
       "         4.9017e-04, 3.9362e-03, 9.5236e-04, 2.1044e-03, 3.4932e-03, 2.0660e-03,\n",
       "         4.3757e-03, 4.5627e-03, 1.2187e-03, 1.7720e-03, 9.2287e-04, 2.1846e-03,\n",
       "         1.2876e-03, 4.5340e-03, 1.2806e-03, 2.9838e-03, 8.4555e-03, 4.3680e-03,\n",
       "         1.3835e-03, 1.9433e-02, 7.1582e-04, 6.0793e-03, 2.9646e-03, 5.0720e-03,\n",
       "         6.0293e-04, 1.2877e-02, 1.5270e-02, 3.9113e-03, 2.9446e-03, 7.7499e-03,\n",
       "         3.7504e-03, 1.1459e-03, 4.4836e-03, 3.6513e-03, 1.4737e-03, 2.3523e-03,\n",
       "         3.2711e-03, 1.8425e-03, 4.2987e-03, 6.0788e-03, 1.2179e-03, 1.2458e-03,\n",
       "         9.0250e-03, 3.8955e-03, 2.8633e-03, 3.3643e-03, 2.0437e-03, 4.1290e-03,\n",
       "         6.4111e-04, 3.2119e-03, 2.2121e-02, 3.3099e-03, 4.4349e-03, 1.5752e-03,\n",
       "         3.1147e-03, 3.9714e-03, 5.3361e-01, 4.6377e-03, 9.8503e-04, 1.9578e-03,\n",
       "         1.1406e-02, 8.8788e-03, 1.9510e-03, 5.0200e-03, 3.5234e-03, 4.0374e-03,\n",
       "         1.1813e-03, 2.2295e-03, 1.9330e-03, 6.3979e-04, 7.8125e-03, 1.2023e-01,\n",
       "         9.8839e-04, 2.6053e-03, 1.4159e-03, 1.0786e-03, 8.6306e-04, 4.5938e-03,\n",
       "         1.7944e-03, 2.1291e-03, 6.4840e-03, 1.8948e-03, 1.9654e-03, 2.8620e-03,\n",
       "         2.8642e-03, 2.4013e-03, 1.3463e-03, 8.5480e-04, 6.3645e-03, 3.7038e-03,\n",
       "         6.0824e-04, 1.2992e-03, 1.3489e-03, 8.2016e-03, 2.1217e-03, 2.2888e-03,\n",
       "         1.5578e-03, 8.4694e-04, 2.5101e-03, 3.0177e-03, 8.7845e-04, 7.9239e-03,\n",
       "         2.7594e-03, 4.2922e-04, 2.3497e-03, 5.8110e-04, 3.8590e-03, 2.7056e-03,\n",
       "         6.1638e-04, 3.3590e-03, 1.4164e-03, 3.2129e-03, 4.7447e-03, 2.3233e-03,\n",
       "         1.0789e-02, 3.0206e-03, 5.3844e-03, 3.8151e-03, 5.5143e-03, 3.5010e-03,\n",
       "         1.1661e-03, 3.1994e-03, 5.2597e-04, 1.7775e-03, 5.1890e-04, 2.5560e-03,\n",
       "         1.9434e-03, 2.0348e-03, 3.2095e-03, 2.7204e-03, 2.8237e-03, 2.1471e-03,\n",
       "         1.4735e-03, 2.8463e-03, 2.5648e-03, 2.1656e-02, 4.8156e-03, 6.1602e-04,\n",
       "         2.2272e-03, 3.1438e-03, 1.1674e-02, 1.3845e-03, 8.7641e-04, 6.3375e-03,\n",
       "         1.6639e-03, 9.6250e-04, 7.1279e-04, 1.6827e-03, 8.5732e-03, 8.4596e-03,\n",
       "         2.3826e-03, 7.5500e-04, 1.0263e-03, 4.3218e-03, 1.5530e-03, 1.9999e-03,\n",
       "         1.9456e-03, 6.2311e-03, 2.2580e-03, 4.9668e-03, 4.0646e-03, 2.5246e-03,\n",
       "         4.6920e-03, 2.3687e-04, 3.5876e-03, 2.7447e-03, 2.0791e-03, 2.7067e-03,\n",
       "         4.4061e-03, 7.1197e-03, 4.4362e-03, 2.2533e-03, 6.2817e-03, 1.9271e-03,\n",
       "         3.0298e-03, 7.9291e-04, 2.1111e-02, 8.9564e-04, 2.9593e-03, 2.4027e-03,\n",
       "         1.5416e-03, 1.3687e-03, 7.1308e-04, 2.4332e-03, 5.5603e-04, 6.8999e-03,\n",
       "         1.1941e-03, 2.1872e-02, 7.6012e-04, 9.6299e-04, 3.0620e-03, 1.8310e-03,\n",
       "         8.3445e-03, 2.2690e-03, 4.2509e-03, 4.5395e-03, 1.6421e-03, 6.3770e-04,\n",
       "         4.8487e-03, 1.0579e-03, 1.7178e-03, 2.2714e-03, 1.4857e-03, 8.3916e-04,\n",
       "         3.5967e-03, 3.4441e-03, 9.9291e-04, 5.0560e-04, 7.1893e-04, 4.3172e-04,\n",
       "         2.3994e-03, 1.4690e-03, 3.5933e-03, 5.3793e-04, 2.0570e-03, 1.6908e-03,\n",
       "         2.9158e-03, 2.8394e-03, 1.2339e-01, 5.1502e-03, 1.4369e-02, 3.7874e-03,\n",
       "         1.0003e-02, 6.5423e-03, 2.7189e-03, 9.9478e-04, 2.0667e-03, 2.9854e-03,\n",
       "         6.6328e-03, 6.9285e-02, 7.0944e-03, 2.2316e-03, 1.1039e-03, 4.1817e-03,\n",
       "         3.2547e-03, 4.2179e-03, 2.3425e-03, 5.3447e-03, 3.0657e-03, 9.2846e-04,\n",
       "         4.0648e-04, 2.9141e-03, 3.2483e-03, 2.6710e-03, 1.9098e-03, 4.3016e-03,\n",
       "         1.1145e-02, 4.1329e-04, 4.9220e-04, 7.4083e-03, 1.3519e-03, 1.8491e-03,\n",
       "         6.7071e-03, 4.1449e-03, 1.7465e-03, 9.8936e-03, 9.1477e-03, 3.6917e-03,\n",
       "         6.8035e-03, 2.7985e-03, 5.7653e-03, 1.6309e-03, 1.6097e-03, 1.6952e-03,\n",
       "         3.0734e-03, 6.3296e-03, 4.4108e-03, 6.8942e-03, 4.2809e-03, 1.7734e-02,\n",
       "         1.1093e-02, 6.1409e-04, 6.8334e-03, 4.1424e-03, 3.6655e-03, 3.7839e-03,\n",
       "         1.5641e-03, 8.2705e-04, 1.0505e-02, 3.3712e-03, 6.6950e-04, 6.4801e-03,\n",
       "         2.7048e-03, 8.1076e-04, 1.4587e-03, 1.4352e-03, 2.1462e-03, 4.0863e-03,\n",
       "         1.3097e-01, 3.4351e-03, 4.2371e-03, 6.5493e-03, 4.2247e-03, 3.9023e-03,\n",
       "         2.5834e-03, 3.9867e-03, 1.4478e-02, 2.9349e-04, 6.0379e-03, 6.5319e-03,\n",
       "         4.0459e-03, 7.2484e-04, 2.6273e-03, 2.1578e-04, 5.5968e-04, 5.6854e-03,\n",
       "         1.1308e-03, 1.4665e-03], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.1.layer.0.SelfAttention.q.weight': tensor([[1.2939e-05, 1.0796e-05, 2.5276e-05,  ..., 8.9172e-06, 1.7714e-05,\n",
       "          1.4205e-05],\n",
       "         [8.9245e-06, 1.0711e-05, 1.4634e-05,  ..., 8.6097e-06, 6.2366e-06,\n",
       "          1.6559e-05],\n",
       "         [4.4791e-05, 1.4340e-05, 3.0832e-05,  ..., 3.2439e-05, 2.0907e-05,\n",
       "          1.6890e-05],\n",
       "         ...,\n",
       "         [3.6477e-05, 6.3021e-06, 3.6962e-05,  ..., 1.0535e-05, 6.3234e-06,\n",
       "          8.5527e-06],\n",
       "         [5.0554e-05, 2.0489e-05, 2.5637e-05,  ..., 1.8141e-05, 5.6318e-06,\n",
       "          2.2896e-05],\n",
       "         [7.7706e-05, 1.3450e-05, 1.2977e-04,  ..., 3.5716e-05, 3.2235e-05,\n",
       "          3.7523e-05]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.1.layer.0.SelfAttention.k.weight': tensor([[5.2713e-07, 4.8800e-07, 2.6473e-07,  ..., 2.9301e-07, 6.1060e-07,\n",
       "          6.7505e-07],\n",
       "         [7.0696e-08, 1.5338e-07, 4.1872e-07,  ..., 1.7049e-07, 3.0680e-07,\n",
       "          3.6018e-07],\n",
       "         [2.1247e-07, 4.0538e-07, 4.1829e-07,  ..., 1.3636e-07, 3.2662e-07,\n",
       "          7.0294e-07],\n",
       "         ...,\n",
       "         [1.7228e-07, 1.3434e-07, 3.5862e-08,  ..., 4.1486e-07, 2.4834e-07,\n",
       "          2.0463e-07],\n",
       "         [1.4316e-07, 2.9603e-07, 3.2492e-07,  ..., 1.2559e-07, 2.3644e-07,\n",
       "          2.2156e-07],\n",
       "         [2.4591e-07, 8.5495e-07, 4.7468e-07,  ..., 1.9657e-07, 4.1824e-07,\n",
       "          4.5076e-07]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.1.layer.0.SelfAttention.v.weight': tensor([[2.3971e-06, 2.7661e-07, 1.1151e-06,  ..., 1.3735e-06, 7.4511e-07,\n",
       "          9.5396e-07],\n",
       "         [1.4138e-07, 1.7712e-07, 1.5110e-07,  ..., 1.9783e-07, 5.0072e-07,\n",
       "          5.2004e-07],\n",
       "         [2.9656e-06, 1.8240e-06, 5.4925e-07,  ..., 6.4199e-08, 7.6379e-07,\n",
       "          5.1480e-07],\n",
       "         ...,\n",
       "         [1.6898e-07, 1.3429e-06, 1.8526e-06,  ..., 6.0547e-07, 1.5804e-07,\n",
       "          5.2452e-07],\n",
       "         [5.8369e-07, 1.1297e-06, 1.4717e-06,  ..., 1.4012e-06, 7.1333e-07,\n",
       "          5.4404e-07],\n",
       "         [6.4461e-07, 1.2338e-06, 4.7649e-07,  ..., 1.3025e-06, 4.2505e-07,\n",
       "          6.3451e-07]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.1.layer.0.SelfAttention.o.weight': tensor([[6.2691e-07, 8.2351e-07, 4.8303e-07,  ..., 2.4058e-07, 2.6936e-07,\n",
       "          4.5447e-07],\n",
       "         [4.7483e-07, 2.8706e-07, 2.1854e-07,  ..., 3.2288e-07, 1.1167e-06,\n",
       "          7.8504e-07],\n",
       "         [5.5375e-07, 7.0784e-07, 6.6680e-07,  ..., 7.7781e-07, 5.4174e-07,\n",
       "          7.6204e-07],\n",
       "         ...,\n",
       "         [8.9261e-07, 3.9998e-07, 5.0964e-07,  ..., 5.6462e-07, 3.7562e-07,\n",
       "          1.1880e-06],\n",
       "         [2.4614e-07, 1.6540e-07, 1.9152e-07,  ..., 5.1373e-07, 3.7155e-07,\n",
       "          2.5353e-07],\n",
       "         [4.8137e-07, 9.3278e-07, 7.7074e-07,  ..., 3.5993e-07, 8.8819e-07,\n",
       "          6.9754e-07]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.1.layer.0.layer_norm.weight': tensor([6.2445e-02, 1.3723e-02, 1.9185e-01, 1.4607e-02, 2.8004e-03, 2.4820e-03,\n",
       "         2.3599e-02, 9.5255e-03, 5.5814e-03, 3.8980e-02, 7.3516e-03, 6.9156e-02,\n",
       "         5.8492e-03, 2.6932e-02, 2.2883e-02, 1.6183e-02, 3.7922e-02, 9.2941e-03,\n",
       "         5.1090e-02, 5.0432e-02, 7.3132e-02, 6.7008e-02, 2.3969e-02, 3.8625e-02,\n",
       "         6.9638e-02, 3.5390e-02, 2.2542e-02, 1.5576e-02, 7.4156e-02, 7.0282e+00,\n",
       "         6.5523e-02, 2.8334e-03, 2.0123e-02, 5.0585e-02, 1.5126e-02, 1.1723e-02,\n",
       "         1.3060e-02, 4.7705e-02, 3.8850e-02, 1.4776e-02, 1.5873e-02, 1.9451e-02,\n",
       "         1.8730e-01, 1.0943e-02, 3.5863e-02, 3.0868e-02, 2.6640e-03, 2.5485e-02,\n",
       "         2.5235e-02, 2.8793e-02, 4.8452e-02, 2.5307e-03, 6.0106e-02, 1.0805e-01,\n",
       "         1.0505e-02, 7.6233e-03, 1.6327e-02, 1.7857e-02, 2.1869e-02, 1.1165e-02,\n",
       "         5.1077e-02, 2.4352e-01, 7.0594e-03, 7.7392e-03, 7.9354e-03, 1.5186e-02,\n",
       "         5.8799e-03, 1.4934e-02, 8.8406e-03, 1.7154e-02, 3.6870e-02, 1.6459e-02,\n",
       "         2.5135e-02, 1.9501e-02, 7.0906e-03, 3.9682e-02, 1.8698e-02, 4.8449e-03,\n",
       "         3.4695e-02, 1.8018e-02, 1.9458e-02, 3.5696e-02, 1.9737e-02, 1.5976e-02,\n",
       "         4.8779e-02, 6.5937e-03, 2.0782e-02, 1.6632e-02, 1.8704e-02, 7.1596e-03,\n",
       "         3.5707e-02, 2.6148e-02, 7.1375e-02, 1.9434e-02, 1.3986e-02, 2.6072e-02,\n",
       "         1.9985e-02, 7.4509e-02, 2.1510e-01, 2.0800e-02, 8.1014e-02, 2.5826e-02,\n",
       "         1.8874e-02, 2.2813e-02, 2.2798e-02, 3.9179e-02, 4.5354e-02, 4.5864e-02,\n",
       "         3.5881e-01, 1.2849e-02, 8.2701e-03, 1.1248e-02, 8.3623e-02, 1.9432e-02,\n",
       "         1.5574e-01, 1.4536e-01, 3.0688e-02, 7.4985e-02, 5.6361e-02, 1.9973e-02,\n",
       "         2.2988e-02, 1.5757e-02, 5.1228e-02, 6.6793e-02, 3.7295e-02, 5.0972e-03,\n",
       "         2.5919e-02, 2.1708e-02, 1.9869e+01, 1.3083e-02, 3.4943e-02, 4.6965e-03,\n",
       "         8.0998e-03, 6.2996e-03, 2.7656e-02, 2.4880e-02, 4.2566e-01, 5.0993e-02,\n",
       "         3.0045e-02, 4.5616e-02, 6.6296e-02, 4.8196e-03, 3.9192e-02, 1.0056e-02,\n",
       "         1.4523e-02, 7.9222e-02, 1.5496e-02, 1.5967e-01, 6.9161e-03, 4.4746e-01,\n",
       "         1.7354e-02, 4.0999e-02, 2.5044e-02, 1.8337e-02, 1.5159e-02, 1.1333e-02,\n",
       "         1.9459e-02, 3.5531e-03, 1.4218e-02, 4.3261e-02, 1.1007e-02, 2.9272e-02,\n",
       "         2.3117e-02, 1.1814e-02, 2.4271e-02, 1.9618e-02, 2.6706e-01, 1.4717e-02,\n",
       "         4.2581e-02, 3.3505e-02, 1.0884e-02, 1.2020e-02, 3.3766e-02, 5.9816e-02,\n",
       "         6.4775e-02, 1.1700e-02, 3.8028e-02, 9.0362e-03, 9.5808e-03, 1.0380e-02,\n",
       "         1.1096e-02, 1.4630e-02, 1.9932e-02, 1.1656e-02, 7.1973e-02, 4.5199e-02,\n",
       "         7.3178e-02, 7.8291e-03, 2.9695e-02, 6.9501e-03, 5.3987e-02, 3.3967e-01,\n",
       "         2.9783e-02, 1.9231e-02, 1.8231e-02, 5.1659e-03, 7.8865e-02, 2.2999e-02,\n",
       "         5.8018e-02, 2.0054e-02, 1.2421e-02, 3.0112e-02, 1.3706e-02, 4.0337e-01,\n",
       "         2.0749e-02, 2.6779e-02, 1.7638e-02, 1.0438e-02, 4.2145e-02, 6.4569e-02,\n",
       "         3.7690e-02, 5.9940e-02, 1.2317e-02, 6.6294e-02, 9.0872e-03, 3.3093e-02,\n",
       "         1.4982e-02, 3.0965e-02, 3.9582e-03, 2.1127e-02, 1.0822e-02, 7.1197e-02,\n",
       "         9.9177e-03, 7.6880e-02, 6.7528e-03, 3.4199e-02, 2.6452e-02, 8.6072e-03,\n",
       "         6.8853e-03, 1.0593e-02, 1.3886e-02, 1.3685e-02, 4.0223e-02, 3.8582e-02,\n",
       "         8.2675e-03, 8.0360e-03, 3.2575e-02, 4.1392e-02, 3.2835e-02, 2.0628e-02,\n",
       "         1.3331e-02, 4.6595e-02, 5.3301e-02, 3.6017e-02, 2.1554e-02, 3.6314e-03,\n",
       "         8.4284e-02, 4.0083e-03, 3.0366e-02, 1.2152e-02, 3.4561e-02, 5.2380e-02,\n",
       "         1.7560e-02, 2.1901e-02, 4.3847e-02, 1.8852e-02, 1.5969e-02, 4.9659e-02,\n",
       "         1.2229e-02, 2.7062e-02, 1.1166e+01, 2.4418e-02, 1.5659e-02, 9.6238e-03,\n",
       "         2.8110e-02, 2.3488e-02, 1.3856e-02, 1.1066e-02, 1.3048e-01, 3.4448e-02,\n",
       "         1.6446e-02, 5.8106e-02, 1.5767e-02, 2.4935e-02, 4.9508e-02, 2.1888e+00,\n",
       "         1.8207e-02, 7.0362e-02, 1.1246e-02, 9.5559e-03, 1.8394e-02, 6.8660e-03,\n",
       "         3.4715e-02, 1.2703e-02, 1.0989e-02, 1.0989e-02, 2.6092e-02, 3.4156e-02,\n",
       "         3.9937e-02, 8.0090e-03, 1.0657e-02, 1.6615e-02, 1.6541e-02, 4.1964e-02,\n",
       "         1.5713e-02, 8.1535e-03, 6.4850e-03, 5.7253e-02, 1.7205e-02, 8.3324e-03,\n",
       "         2.1092e-02, 1.1383e-02, 5.8354e-03, 1.5171e-02, 9.2543e-03, 1.9099e-02,\n",
       "         1.3259e-02, 3.7983e-03, 3.8281e-02, 4.1473e-03, 2.1264e-02, 3.9379e-03,\n",
       "         3.1097e-02, 1.2885e-01, 5.3656e-02, 1.8025e-02, 3.0427e-02, 4.6687e-02,\n",
       "         4.0097e-02, 3.2848e-02, 1.3938e-02, 3.2360e-02, 3.2779e-02, 1.7609e-02,\n",
       "         1.9161e-02, 5.1911e-02, 2.2391e-02, 1.6113e-02, 2.3329e-02, 1.1618e-02,\n",
       "         1.9967e-02, 2.3847e-02, 1.4859e-02, 1.2075e-02, 9.1152e-03, 1.5139e-02,\n",
       "         5.0541e-02, 2.8690e-02, 2.3629e-02, 3.8291e-01, 8.8683e-03, 7.8566e-03,\n",
       "         2.3736e-02, 1.7937e-02, 2.7819e-02, 1.3393e-02, 1.6454e-02, 3.2530e-02,\n",
       "         3.1744e-02, 7.1478e-03, 1.4384e-02, 2.2296e-02, 3.0834e-02, 3.6697e-02,\n",
       "         2.5453e-02, 2.2479e-02, 1.2924e-02, 2.2964e-02, 1.0342e-02, 2.4819e-02,\n",
       "         1.4124e-02, 3.4013e-02, 1.0396e-02, 4.4819e-02, 1.7541e-02, 1.2590e-02,\n",
       "         9.0361e-02, 2.3033e-02, 2.7340e-02, 1.9364e-02, 1.8405e-02, 1.7775e-02,\n",
       "         1.9754e-02, 1.6921e-02, 1.0232e-02, 6.1378e-02, 8.2171e-03, 1.2050e-02,\n",
       "         3.3057e-02, 4.2235e-02, 1.0720e-01, 4.1325e-03, 1.7148e-02, 5.8153e-03,\n",
       "         5.1081e-02, 1.6906e-02, 5.3427e-02, 1.6846e-02, 2.1901e-02, 3.4948e-02,\n",
       "         4.8135e-02, 7.4204e-02, 4.8613e-02, 7.9178e-03, 6.9321e-03, 2.5297e-02,\n",
       "         1.4805e-01, 7.5601e-02, 1.7029e-02, 9.4283e-03, 1.7822e-02, 3.3759e-02,\n",
       "         1.2433e-01, 1.0231e-02, 5.5243e-02, 4.4534e-02, 1.1723e-02, 4.3239e-02,\n",
       "         4.6233e-02, 4.7617e-02, 2.1526e-02, 6.7970e-03, 1.4515e-02, 1.1862e-02,\n",
       "         1.3932e-02, 1.1401e-02, 1.6893e-02, 1.9883e-02, 4.5356e-02, 2.5380e-02,\n",
       "         1.0672e-02, 1.6871e-02, 5.1367e-01, 5.1204e-02, 4.5425e-01, 3.2346e-02,\n",
       "         3.0301e-02, 2.6412e-02, 2.4222e-02, 9.7788e-03, 2.7840e-02, 1.8427e-02,\n",
       "         5.0510e-02, 9.9961e+00, 2.3751e-02, 2.1789e-02, 3.0798e-02, 2.5892e-02,\n",
       "         2.8138e-02, 2.2723e-02, 1.3324e-01, 3.3595e-02, 1.2638e-02, 7.6337e-02,\n",
       "         7.0165e-02, 3.3834e-02, 4.7179e-02, 6.1246e-03, 4.2720e-02, 4.1069e-02,\n",
       "         4.8189e-02, 3.8070e-02, 7.1830e-03, 2.1336e-01, 5.2832e-03, 1.3245e-02,\n",
       "         1.3057e-02, 6.2009e-03, 1.8907e-02, 2.2770e-02, 6.0033e-02, 1.2155e-01,\n",
       "         5.1279e-02, 2.6510e-02, 3.5512e-02, 6.6031e-02, 1.1829e-02, 2.4949e-02,\n",
       "         1.2269e-02, 3.6749e-02, 2.5345e-02, 2.8033e-02, 2.1523e-02, 3.1145e-02,\n",
       "         1.5343e-02, 5.1560e-02, 1.2578e-02, 5.7604e-02, 2.5406e-02, 1.9434e-02,\n",
       "         1.1167e-02, 3.2025e-03, 5.1027e-02, 2.7129e-02, 2.7395e-02, 5.8141e-03,\n",
       "         4.9212e-02, 3.9202e-03, 6.1339e-02, 2.1750e-02, 1.4424e-02, 4.3468e-03,\n",
       "         1.0255e+01, 9.8701e-03, 7.4522e-03, 2.4358e-02, 5.1392e-02, 1.0662e-02,\n",
       "         8.2621e-03, 4.2090e-02, 3.9147e-02, 1.1725e-02, 4.6375e-03, 5.2264e-02,\n",
       "         7.8417e-03, 5.2529e-03, 2.8690e-02, 2.6327e-02, 9.9000e-03, 1.2634e-02,\n",
       "         8.3656e-03, 1.0646e-02], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.1.layer.1.DenseReluDense.wi.weight': tensor([[1.6979e-08, 6.9051e-08, 3.3379e-09,  ..., 5.0202e-10, 3.3083e-08,\n",
       "          5.5885e-09],\n",
       "         [1.6723e-09, 1.5646e-09, 2.2736e-09,  ..., 8.2428e-10, 8.7366e-10,\n",
       "          3.7104e-08],\n",
       "         [1.3261e-07, 1.5702e-07, 3.4912e-08,  ..., 7.1624e-08, 5.6616e-08,\n",
       "          1.6349e-07],\n",
       "         ...,\n",
       "         [8.9979e-08, 7.1657e-08, 3.8981e-07,  ..., 2.6553e-08, 1.3443e-07,\n",
       "          1.1663e-07],\n",
       "         [7.8458e-08, 8.6518e-08, 1.0485e-07,  ..., 3.2910e-08, 8.3280e-08,\n",
       "          1.1449e-07],\n",
       "         [4.3986e-07, 1.0937e-07, 1.9938e-07,  ..., 6.0688e-07, 1.1287e-07,\n",
       "          3.4891e-07]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.1.layer.1.DenseReluDense.wo.weight': tensor([[1.0807e-07, 1.8689e-09, 7.8211e-07,  ..., 2.6935e-06, 1.7554e-07,\n",
       "          3.8404e-08],\n",
       "         [8.4440e-08, 1.8792e-09, 3.5741e-07,  ..., 4.1330e-06, 1.5707e-07,\n",
       "          1.7136e-08],\n",
       "         [2.0074e-07, 6.6020e-10, 5.0061e-07,  ..., 9.5363e-08, 2.8784e-07,\n",
       "          1.1020e-07],\n",
       "         ...,\n",
       "         [4.1989e-07, 1.3971e-09, 3.5624e-07,  ..., 1.5397e-07, 1.0605e-07,\n",
       "          2.7080e-08],\n",
       "         [3.1455e-09, 1.1462e-09, 7.6626e-07,  ..., 1.2400e-07, 5.2473e-08,\n",
       "          2.6717e-08],\n",
       "         [1.5817e-07, 7.1373e-10, 3.3594e-08,  ..., 3.4753e-06, 1.5236e-07,\n",
       "          4.9563e-08]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.1.layer.1.layer_norm.weight': tensor([1.4137e-03, 3.2939e-03, 1.7890e-03, 1.0670e-03, 1.2606e-03, 2.4198e-03,\n",
       "         3.8686e-04, 3.6346e-04, 1.1520e-03, 1.9677e-03, 3.4502e-04, 3.5599e-04,\n",
       "         8.4461e-04, 1.5902e-03, 1.3169e-03, 1.1717e-03, 2.4252e-03, 6.5542e-04,\n",
       "         1.6082e-03, 2.3158e-03, 2.2251e-04, 5.4579e-04, 4.8325e-04, 1.7298e-04,\n",
       "         1.0142e-03, 1.4317e-03, 2.4024e-03, 2.8849e-03, 2.3791e-03, 6.6343e-03,\n",
       "         1.1271e-03, 4.2291e-04, 3.5695e-03, 1.0242e-03, 9.1803e-04, 1.3748e-03,\n",
       "         2.2937e-03, 9.2657e-04, 5.2363e-04, 8.2357e-04, 2.2619e-03, 1.7401e-03,\n",
       "         6.2286e-03, 4.9599e-04, 4.7601e-03, 7.3765e-03, 1.3572e-04, 4.0185e-03,\n",
       "         1.3293e-03, 8.1561e-04, 3.4394e-03, 5.8625e-03, 3.6001e-04, 3.0283e-03,\n",
       "         2.8379e-03, 3.7439e-04, 1.8038e-03, 2.7416e-03, 8.1758e-03, 1.8072e-03,\n",
       "         1.0715e-03, 5.8707e-03, 5.6889e-04, 2.3459e-03, 6.7575e-04, 1.1789e-03,\n",
       "         7.3967e-04, 1.5197e-03, 9.9102e-04, 3.8121e-04, 3.2750e-03, 1.2494e-03,\n",
       "         2.4645e-03, 4.4409e-04, 1.3864e-03, 8.8425e-04, 1.7000e-03, 1.3833e-03,\n",
       "         1.4121e-03, 3.2581e-03, 4.4283e-03, 7.2133e-03, 1.0483e-03, 4.5131e-04,\n",
       "         6.6343e-04, 3.6738e-04, 9.9252e-04, 2.9501e-03, 8.5542e-04, 1.2662e-04,\n",
       "         1.6742e-03, 8.6453e-04, 3.6058e-04, 3.3778e-04, 9.0358e-04, 8.5544e-04,\n",
       "         1.1743e-03, 7.0927e-04, 2.4940e-03, 2.1339e-03, 3.4471e-04, 1.7059e-03,\n",
       "         1.7704e-03, 4.8694e-04, 1.6078e-03, 2.7916e-03, 4.0083e-03, 1.3183e-03,\n",
       "         1.9041e-02, 2.0898e-03, 2.1474e-04, 2.6960e-04, 3.5912e-04, 6.6959e-04,\n",
       "         7.0945e-04, 2.3641e-03, 2.5115e-03, 8.0731e-04, 1.0016e-03, 1.5723e-03,\n",
       "         1.2202e-03, 2.0495e-03, 1.1333e-03, 6.4446e-04, 1.0853e-03, 7.4016e-04,\n",
       "         1.4607e-03, 2.4906e-03, 1.6738e-02, 2.6279e-03, 1.7083e-03, 1.0529e-03,\n",
       "         7.8355e-04, 2.3295e-03, 6.3226e-04, 1.5458e-03, 1.5867e-03, 8.3451e-04,\n",
       "         1.7257e-03, 2.1819e-03, 1.0721e-03, 2.6328e-03, 1.6291e-03, 5.0612e-03,\n",
       "         7.1651e-03, 5.5590e-03, 2.6195e-03, 1.3865e-03, 1.5853e-03, 7.0297e-03,\n",
       "         5.9368e-04, 1.3801e-03, 6.9788e-04, 1.2674e-03, 6.3027e-04, 5.6796e-03,\n",
       "         3.5689e-03, 3.7037e-03, 1.8495e-03, 1.7935e-04, 6.9659e-04, 8.9619e-04,\n",
       "         3.5764e-03, 1.2863e-03, 1.9008e-03, 4.1653e-03, 3.7844e-03, 7.7014e-04,\n",
       "         1.2681e-03, 3.1654e-03, 2.1353e-03, 1.7279e-03, 4.7475e-03, 9.3417e-04,\n",
       "         1.6631e-03, 2.4541e-03, 1.0205e-03, 3.4202e-04, 1.7212e-03, 7.8100e-04,\n",
       "         6.5605e-03, 1.2387e-03, 1.0311e-03, 4.1339e-04, 4.8963e-03, 1.5139e-03,\n",
       "         1.9464e-03, 3.7149e-04, 1.4962e-03, 5.9888e-04, 1.0556e-03, 4.3412e-02,\n",
       "         1.5674e-03, 1.9084e-03, 3.0590e-03, 5.2774e-03, 8.8032e-04, 1.3863e-03,\n",
       "         9.8318e-04, 9.7579e-03, 1.4691e-03, 1.0380e-03, 4.3080e-04, 2.8435e-03,\n",
       "         2.0293e-03, 9.9258e-04, 2.4037e-04, 1.8347e-03, 4.9783e-03, 2.8273e-03,\n",
       "         1.6534e-03, 1.4736e-03, 4.9022e-04, 5.4197e-04, 6.1394e-04, 5.1913e-03,\n",
       "         9.8508e-04, 2.9912e-03, 7.7449e-03, 2.2264e-03, 1.3969e-03, 1.2338e-03,\n",
       "         1.0903e-03, 7.3240e-04, 5.3683e-04, 2.1017e-03, 1.7898e-03, 7.1300e-04,\n",
       "         4.4259e-04, 5.8432e-04, 1.4084e-03, 1.7715e-03, 1.5281e-03, 3.4367e-03,\n",
       "         3.3664e-04, 1.9089e-03, 3.0998e-03, 1.3166e-03, 1.7161e-03, 2.4429e-03,\n",
       "         1.1853e-03, 6.5653e-04, 1.5651e-03, 1.4247e-03, 4.1177e-04, 9.8015e-04,\n",
       "         1.7581e-02, 2.5839e-03, 3.9821e-03, 1.3276e-03, 1.1143e-03, 2.2349e-03,\n",
       "         3.9236e-04, 9.3662e-03, 1.9836e-03, 1.6152e-03, 1.5620e-03, 1.0728e-03,\n",
       "         5.1522e-04, 5.4626e-04, 5.3575e-02, 5.7704e-04, 1.2522e-03, 5.3326e-04,\n",
       "         2.1979e-02, 1.0405e-03, 9.5900e-04, 1.4910e-03, 1.2083e-03, 5.9906e-04,\n",
       "         1.5783e-03, 9.5343e-04, 5.9405e-04, 7.6806e-04, 1.3688e-03, 7.6759e-03,\n",
       "         2.7457e-03, 1.6052e-03, 1.1582e-03, 6.0769e-04, 3.6320e-04, 1.7353e-03,\n",
       "         8.8275e-04, 2.5866e-04, 1.8295e-03, 4.2643e-04, 1.3018e-03, 3.4410e-04,\n",
       "         3.2102e-03, 7.3121e-03, 2.2907e-03, 2.0448e-03, 1.7412e-03, 7.2959e-04,\n",
       "         5.7508e-03, 1.1016e-03, 4.5015e-04, 8.6078e-04, 6.5102e-04, 4.3846e-04,\n",
       "         3.5142e-03, 1.5646e-03, 3.9739e-04, 2.2664e-03, 5.7929e-04, 1.7167e-03,\n",
       "         3.5754e-04, 6.7877e-04, 1.0038e-03, 5.4974e-03, 3.4763e-03, 7.7368e-04,\n",
       "         7.6935e-03, 2.1468e-03, 2.9539e-03, 1.0788e-02, 1.3112e-03, 4.9578e-04,\n",
       "         1.1886e-03, 1.0198e-03, 7.6016e-04, 7.3728e-04, 2.1025e-03, 1.8909e-03,\n",
       "         2.8586e-04, 2.7145e-03, 2.4113e-03, 1.6711e-03, 1.9715e-03, 4.2709e-04,\n",
       "         2.1061e-03, 1.2056e-03, 5.5339e-04, 7.2507e-04, 1.6256e-03, 3.8436e-04,\n",
       "         3.7519e-04, 1.2744e-03, 1.4980e-03, 7.9579e-03, 4.0593e-03, 8.3017e-04,\n",
       "         1.6725e-03, 1.8361e-03, 7.1477e-03, 1.3564e-03, 1.8540e-03, 1.5576e-03,\n",
       "         4.4419e-03, 2.7234e-03, 7.4086e-04, 1.1867e-03, 1.0549e-03, 1.2737e-03,\n",
       "         2.6012e-04, 4.6623e-04, 3.3670e-04, 2.5514e-03, 7.3790e-04, 5.6161e-04,\n",
       "         4.5436e-04, 1.7138e-03, 1.1114e-03, 1.5966e-03, 7.4439e-04, 3.5576e-03,\n",
       "         1.5521e-03, 4.3693e-04, 5.3570e-03, 1.7315e-03, 9.9823e-04, 1.2311e-03,\n",
       "         1.1723e-02, 9.7291e-04, 1.2467e-03, 3.3289e-03, 3.6546e-03, 4.9558e-03,\n",
       "         6.2994e-04, 1.1260e-03, 3.7321e-03, 2.2464e-03, 6.6935e-04, 4.0026e-04,\n",
       "         6.7385e-04, 7.1573e-04, 1.9424e-03, 9.4135e-04, 8.4450e-04, 1.3310e-03,\n",
       "         4.5190e-03, 2.7895e-03, 3.0355e-03, 1.2852e-03, 2.5935e-03, 1.0871e-03,\n",
       "         7.2299e-03, 6.9845e-02, 1.1514e-03, 1.3392e-04, 1.1806e-03, 2.2441e-04,\n",
       "         2.9965e-03, 6.5890e-04, 2.0363e-03, 1.1731e-03, 2.7790e-04, 1.1268e-03,\n",
       "         2.7610e-03, 3.0337e-03, 2.8415e-03, 2.7223e-04, 1.7848e-03, 6.2952e-04,\n",
       "         1.9676e-03, 1.2216e-03, 5.9422e-04, 7.5466e-03, 2.3322e-03, 3.1091e-03,\n",
       "         6.9134e-04, 4.4360e-03, 7.7721e-01, 1.7652e-03, 1.6556e-02, 6.7975e-04,\n",
       "         1.0471e-03, 1.2624e-03, 1.1149e-03, 9.7309e-03, 2.9620e-03, 1.6291e-03,\n",
       "         9.2798e-04, 2.5837e-02, 1.8552e-03, 5.2946e-03, 3.5871e-04, 1.5485e-03,\n",
       "         4.9126e-04, 1.2383e-03, 4.8469e-03, 2.6669e-03, 1.7647e-03, 1.3606e-03,\n",
       "         1.3247e-03, 1.2977e-03, 1.0643e-03, 9.6416e-04, 8.4541e-04, 1.0555e-03,\n",
       "         1.1576e-03, 5.9302e-04, 1.9992e-03, 1.1515e-02, 9.2754e-04, 3.2244e-04,\n",
       "         5.5226e-03, 1.9754e-03, 1.7565e-03, 2.4112e-03, 1.4097e-03, 9.9658e-03,\n",
       "         1.1097e-03, 9.4332e-03, 2.6250e-03, 8.3946e-04, 2.3534e-03, 5.1843e-04,\n",
       "         1.3490e-03, 2.1184e-03, 1.7171e-03, 6.7949e-03, 1.8765e-03, 1.2938e-03,\n",
       "         2.1850e-03, 4.2753e-04, 7.7262e-04, 1.3512e-03, 1.2871e-03, 1.7898e-03,\n",
       "         1.0796e-03, 8.3612e-04, 6.4870e-04, 1.5687e-03, 4.6607e-03, 1.4769e-03,\n",
       "         1.9378e-03, 6.7781e-04, 4.4399e-04, 1.5605e-03, 6.7055e-04, 1.1963e-03,\n",
       "         9.2689e-02, 3.4913e-03, 1.5342e-03, 1.5138e-03, 2.1266e-03, 1.5144e-03,\n",
       "         3.8284e-03, 4.1914e-04, 1.6995e-03, 6.2543e-04, 1.3483e-03, 4.3292e-03,\n",
       "         5.6927e-04, 9.3177e-04, 9.3578e-04, 5.2105e-03, 4.5477e-04, 8.2352e-04,\n",
       "         7.3467e-04, 1.3632e-03], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.2.layer.0.SelfAttention.q.weight': tensor([[1.3756e-04, 8.6282e-05, 2.8207e-05,  ..., 1.7941e-05, 1.5974e-05,\n",
       "          7.9308e-05],\n",
       "         [2.4772e-05, 6.2133e-05, 5.6854e-05,  ..., 7.8524e-06, 1.5138e-05,\n",
       "          5.8990e-05],\n",
       "         [1.1243e-05, 4.0170e-05, 2.0938e-05,  ..., 4.2348e-05, 5.1078e-05,\n",
       "          8.4462e-05],\n",
       "         ...,\n",
       "         [2.4314e-04, 1.1853e-03, 4.1544e-04,  ..., 2.1243e-04, 1.6717e-04,\n",
       "          5.6898e-04],\n",
       "         [5.6428e-05, 6.5019e-05, 3.4816e-05,  ..., 1.1531e-05, 2.7240e-05,\n",
       "          1.2877e-05],\n",
       "         [4.7837e-05, 5.8307e-05, 2.4314e-05,  ..., 3.1252e-05, 2.7690e-05,\n",
       "          4.6162e-05]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.2.layer.0.SelfAttention.k.weight': tensor([[1.9100e-06, 6.4935e-07, 7.9601e-07,  ..., 2.5519e-07, 4.8847e-07,\n",
       "          4.5857e-07],\n",
       "         [6.6887e-07, 5.6191e-07, 4.9049e-07,  ..., 2.0742e-07, 5.7095e-07,\n",
       "          9.8148e-07],\n",
       "         [1.1333e-06, 4.2598e-07, 1.8981e-07,  ..., 3.5460e-07, 3.1520e-07,\n",
       "          2.0893e-07],\n",
       "         ...,\n",
       "         [8.1155e-06, 1.4333e-05, 1.3532e-05,  ..., 1.3754e-06, 2.3795e-06,\n",
       "          4.4800e-06],\n",
       "         [5.9525e-07, 1.2486e-06, 2.9841e-07,  ..., 1.2105e-07, 1.4535e-07,\n",
       "          2.2565e-07],\n",
       "         [1.7230e-06, 9.2816e-07, 3.1898e-07,  ..., 4.9662e-07, 4.0974e-07,\n",
       "          2.7698e-07]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.2.layer.0.SelfAttention.v.weight': tensor([[4.5209e-07, 9.0905e-08, 1.5583e-06,  ..., 1.1590e-07, 6.2630e-08,\n",
       "          5.4122e-07],\n",
       "         [2.0760e-07, 1.3430e-06, 3.7834e-07,  ..., 4.7166e-07, 1.8136e-07,\n",
       "          1.5267e-06],\n",
       "         [3.2432e-07, 8.1123e-07, 1.5565e-06,  ..., 2.1570e-07, 1.1195e-07,\n",
       "          2.1191e-06],\n",
       "         ...,\n",
       "         [5.0680e-07, 3.8166e-07, 9.1271e-07,  ..., 2.1410e-07, 3.4170e-07,\n",
       "          1.0795e-06],\n",
       "         [3.0942e-07, 9.8215e-07, 1.5291e-06,  ..., 5.7621e-08, 9.6230e-08,\n",
       "          4.5526e-07],\n",
       "         [4.9142e-07, 1.1114e-06, 5.3124e-07,  ..., 7.2342e-07, 9.4465e-07,\n",
       "          4.1746e-07]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.2.layer.0.SelfAttention.o.weight': tensor([[8.8170e-07, 3.0375e-07, 6.9324e-07,  ..., 2.6100e-07, 1.1707e-07,\n",
       "          6.5121e-07],\n",
       "         [2.0297e-06, 3.7162e-07, 1.1741e-06,  ..., 1.2471e-06, 2.0135e-07,\n",
       "          1.5282e-07],\n",
       "         [1.1095e-07, 2.6001e-07, 8.0295e-07,  ..., 4.7097e-07, 1.3028e-07,\n",
       "          7.1701e-08],\n",
       "         ...,\n",
       "         [5.6552e-07, 6.5495e-08, 9.3360e-08,  ..., 2.8005e-07, 2.6425e-07,\n",
       "          4.3310e-07],\n",
       "         [1.6182e-07, 2.0103e-07, 2.5903e-07,  ..., 4.5072e-08, 3.3346e-07,\n",
       "          2.9280e-07],\n",
       "         [4.7089e-07, 2.8883e-07, 3.0215e-07,  ..., 3.1531e-07, 1.8163e-07,\n",
       "          2.7852e-07]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.2.layer.0.layer_norm.weight': tensor([2.7247e-02, 1.2960e-02, 4.4049e-02, 5.4451e-02, 2.6950e-02, 7.0936e-02,\n",
       "         3.0265e-02, 1.3807e-02, 1.1580e-02, 5.2735e-02, 2.9559e-02, 7.6116e-02,\n",
       "         3.2400e-02, 1.4584e-02, 4.0739e-02, 1.8316e-02, 5.5582e-02, 2.4790e-02,\n",
       "         2.7500e-02, 6.4174e-03, 1.2918e-02, 2.1745e-02, 2.2649e-02, 1.1902e-02,\n",
       "         1.3408e-02, 2.4238e-02, 1.0053e-02, 4.0136e-03, 4.0188e-02, 1.0042e+01,\n",
       "         5.9739e-03, 5.3506e-03, 7.3558e-03, 9.7320e-03, 2.5193e-02, 2.6279e-02,\n",
       "         2.0895e-02, 7.5763e-02, 1.9742e-02, 1.5351e-02, 2.7488e-02, 3.3853e-02,\n",
       "         5.7165e-01, 3.8239e-02, 2.7143e-02, 7.7137e-02, 6.6731e-03, 3.1205e-02,\n",
       "         2.6578e-02, 1.8954e-02, 2.3268e-02, 7.1348e-03, 2.4316e-02, 9.6598e-02,\n",
       "         9.1656e-03, 8.6283e-03, 1.2254e-02, 3.6020e-03, 5.8462e-02, 8.2197e-03,\n",
       "         1.0194e-01, 5.1792e-01, 5.7731e-03, 1.4714e-02, 2.0532e-02, 1.0869e-02,\n",
       "         2.4482e-03, 4.8799e-03, 6.8951e-03, 1.0582e-02, 1.6869e-02, 1.3954e-02,\n",
       "         1.3766e-02, 6.5357e-03, 3.8435e-03, 4.9560e-02, 1.0005e-02, 7.3966e-03,\n",
       "         2.2815e-02, 1.8958e-02, 4.2064e-02, 7.2432e-02, 1.6248e-02, 3.5580e-02,\n",
       "         5.2894e-03, 4.8389e-03, 6.7780e-03, 2.6460e-02, 1.6834e-01, 7.4024e-03,\n",
       "         1.1303e-02, 2.6861e-02, 1.3306e-02, 2.0805e-02, 1.5268e-02, 8.0462e-03,\n",
       "         3.4023e-02, 7.0448e-03, 8.8912e-02, 2.2711e-02, 7.4293e-03, 2.1761e-02,\n",
       "         4.3402e-02, 2.2890e-02, 3.8370e-02, 5.6501e-02, 3.6431e-02, 2.7634e-02,\n",
       "         1.5404e-01, 1.6375e-02, 4.9070e-02, 5.5656e-02, 9.5022e-02, 7.5093e-03,\n",
       "         9.5819e-03, 1.3154e-01, 2.3598e-02, 3.6668e-02, 9.4580e-02, 1.5240e-02,\n",
       "         2.2215e-02, 1.0766e-02, 1.2845e-02, 1.5254e-02, 3.2553e-02, 3.5861e-02,\n",
       "         1.2335e-02, 1.7690e-02, 1.6058e+01, 2.5674e-02, 1.8132e-02, 4.9155e-02,\n",
       "         1.8056e-02, 1.4502e-02, 1.5831e-02, 6.0120e-03, 1.9419e+00, 3.8478e-02,\n",
       "         2.2065e-02, 1.0713e-02, 1.2476e-02, 1.3497e-02, 4.6967e-02, 9.5467e-03,\n",
       "         2.5199e-02, 1.7292e-02, 1.1080e-02, 3.7213e-02, 1.1555e-02, 7.5905e-02,\n",
       "         8.6599e-03, 1.4575e-02, 1.5257e-02, 7.7888e-03, 6.2361e-03, 1.0123e-02,\n",
       "         3.6414e-02, 2.1275e-02, 7.0257e-03, 2.0764e-02, 2.0293e-02, 2.8785e-02,\n",
       "         2.2382e-02, 1.6470e-02, 3.5291e-02, 7.9204e-03, 1.0765e-01, 2.4097e-02,\n",
       "         2.7878e-02, 4.7508e-02, 1.1999e-02, 1.8500e-02, 1.1334e-02, 3.2173e-02,\n",
       "         3.5700e-02, 1.2121e-02, 4.9702e-03, 2.2893e-02, 1.8207e-01, 3.6586e-03,\n",
       "         7.0289e-02, 5.3059e-03, 1.3621e-02, 5.6444e-03, 1.2486e-01, 3.4028e-02,\n",
       "         9.3421e-03, 1.1529e-02, 8.9969e-03, 5.5713e-03, 8.2008e-03, 9.4643e-02,\n",
       "         3.6711e-02, 2.0205e-02, 5.8601e-02, 8.5212e-03, 9.8930e-03, 1.7853e-02,\n",
       "         2.6824e-02, 3.4952e-02, 5.4998e-02, 2.5148e-02, 1.1870e-02, 4.8586e-01,\n",
       "         9.5627e-03, 9.1282e-03, 3.9083e-02, 2.9018e-02, 1.4330e-02, 3.2265e-02,\n",
       "         1.1603e-02, 4.1095e-02, 1.8169e-02, 2.9789e-02, 5.0991e-03, 2.4424e-01,\n",
       "         3.1481e-02, 5.8964e-03, 2.3876e-02, 1.2378e-02, 1.9226e-02, 1.7199e-02,\n",
       "         2.9838e-02, 9.5228e-02, 2.4218e-02, 2.3337e-02, 1.0834e-02, 1.8686e-02,\n",
       "         1.9287e-02, 2.2049e-02, 9.7072e-03, 2.1515e-03, 3.4380e-02, 1.1521e-02,\n",
       "         5.9310e-02, 2.0247e-02, 3.2771e-02, 2.2713e-02, 2.1808e-03, 1.8544e-02,\n",
       "         1.1809e-02, 5.9283e-03, 1.0365e-02, 1.3423e-02, 6.9499e-03, 4.9227e-02,\n",
       "         3.9153e-01, 5.0594e-02, 2.7463e-02, 1.3852e-02, 2.2490e-02, 2.3128e-03,\n",
       "         2.0039e-02, 1.2546e-02, 2.6040e-02, 3.1408e-02, 3.0089e-03, 6.9232e-03,\n",
       "         6.7252e-02, 1.4322e-02, 8.2258e+00, 1.9189e-02, 1.6110e-02, 7.9308e-03,\n",
       "         1.8813e+00, 4.2823e-02, 9.5874e-02, 9.2742e-03, 5.6164e-03, 1.0245e-02,\n",
       "         3.6619e-03, 4.0387e-03, 1.7873e-02, 9.9282e-03, 4.2467e-02, 3.5645e+00,\n",
       "         2.8255e-02, 2.1129e-02, 1.8709e-02, 9.8937e-03, 3.1841e-02, 8.5525e-03,\n",
       "         1.6184e-02, 2.8588e-02, 2.0518e-02, 7.5755e-03, 2.3473e-02, 1.4598e-02,\n",
       "         3.9335e-02, 1.1153e-02, 1.0981e-02, 2.0872e-02, 2.2434e-02, 8.0074e-03,\n",
       "         1.7333e-02, 5.9145e-03, 1.5374e-02, 1.6412e-02, 1.3271e-02, 4.7582e-02,\n",
       "         1.1882e-02, 8.3643e-03, 5.6482e-03, 2.1408e-02, 2.7484e-02, 1.5011e-02,\n",
       "         1.6570e-02, 2.1408e-02, 1.3855e-02, 1.9284e-02, 2.5131e-02, 1.3044e-02,\n",
       "         5.4189e-02, 1.7062e-02, 3.2372e-02, 2.2543e-02, 6.6952e-02, 5.1558e-02,\n",
       "         3.3293e-02, 4.2675e-02, 1.3075e-02, 2.4326e-02, 1.5575e-02, 2.8632e-02,\n",
       "         7.4802e-02, 1.8230e-02, 3.2534e-02, 1.9738e-02, 9.5518e-03, 4.3114e-03,\n",
       "         1.4132e-02, 5.0288e-03, 2.2824e-02, 2.4175e-02, 3.1380e-02, 5.2875e-03,\n",
       "         3.0567e-02, 2.1685e-02, 2.8420e-02, 2.0499e+00, 2.0755e-02, 1.8146e-02,\n",
       "         6.3004e-03, 1.1621e-02, 1.0481e-02, 7.8923e-03, 2.9454e-03, 7.4242e-03,\n",
       "         2.6246e-02, 3.2575e-02, 5.6734e-03, 1.8207e-02, 3.6575e-02, 6.8842e-02,\n",
       "         1.7688e-02, 5.4343e-03, 1.7723e-03, 1.6033e-02, 2.0067e-02, 3.6589e-02,\n",
       "         1.4699e-02, 1.0314e-02, 6.2291e-02, 1.3688e-02, 3.0246e-02, 8.3719e-03,\n",
       "         3.2546e-02, 1.0396e-02, 3.2039e-02, 2.1000e-02, 7.5520e-03, 1.3338e-02,\n",
       "         7.4386e-02, 5.3527e-03, 9.5137e-03, 2.1233e-02, 7.3093e-03, 2.4547e-02,\n",
       "         2.6484e-02, 7.9126e-03, 1.3430e-01, 6.3881e-02, 1.1503e-02, 3.8613e-02,\n",
       "         1.5278e-02, 7.8417e-03, 5.3550e-02, 2.2686e-02, 4.5823e-03, 6.0341e-02,\n",
       "         2.2116e-02, 9.1220e-03, 7.9893e-03, 1.0160e-02, 1.7988e-02, 1.3494e-02,\n",
       "         6.3295e-02, 1.1307e+00, 9.5547e-03, 3.2738e-02, 9.2319e-03, 2.8292e-03,\n",
       "         1.7519e-01, 5.5040e-03, 7.5382e-02, 1.4673e-02, 5.1947e-02, 8.4551e-03,\n",
       "         2.4479e-02, 2.8339e-02, 3.8595e-02, 7.9234e-03, 2.9529e-02, 9.4386e-03,\n",
       "         1.4683e-02, 1.4444e-02, 1.6760e-02, 1.4831e-01, 4.5267e-02, 3.3163e-02,\n",
       "         1.9053e-02, 9.2870e-03, 2.7367e-01, 2.9085e-02, 8.8041e-02, 8.7338e-03,\n",
       "         3.5506e-02, 1.7418e-02, 3.5028e-02, 4.4224e-02, 1.0844e-02, 2.4901e-02,\n",
       "         1.3732e-02, 1.1031e+01, 1.1250e-02, 4.2337e-02, 6.7627e-03, 2.4901e-02,\n",
       "         6.1367e-03, 8.0598e-03, 8.5193e-03, 8.1695e-03, 1.5721e-02, 1.7697e-02,\n",
       "         1.5279e-02, 8.0467e-03, 6.8827e-02, 5.9643e-03, 1.5034e-02, 6.1740e-03,\n",
       "         2.3236e-02, 1.8299e-02, 3.7082e-02, 2.2901e-01, 8.0269e-03, 9.7077e-03,\n",
       "         7.4834e-03, 2.1081e-02, 9.4729e-03, 2.8130e-02, 5.8937e-02, 6.8750e-02,\n",
       "         1.0557e-02, 4.2290e-02, 3.0522e-02, 2.0076e-02, 1.2988e-02, 1.3641e-02,\n",
       "         3.7015e-02, 8.7427e-03, 1.3637e-02, 3.5571e-02, 1.3102e-02, 5.7999e-02,\n",
       "         1.1717e-02, 1.3659e-02, 3.2351e-02, 2.8758e-02, 5.0424e-03, 1.7757e-02,\n",
       "         3.4124e-02, 1.8682e-02, 6.4229e-02, 3.0458e-02, 5.4828e-02, 2.8613e-02,\n",
       "         8.5881e-03, 6.8455e-03, 7.9378e-02, 5.1643e-03, 3.6633e-03, 9.7202e-03,\n",
       "         1.8009e+01, 9.4058e-03, 1.1475e-02, 2.1974e-02, 5.4733e-02, 4.9354e-03,\n",
       "         9.6943e-03, 2.4933e-02, 5.9345e-02, 1.8951e-02, 2.0391e-02, 5.6060e-02,\n",
       "         3.4330e-02, 4.0806e-02, 3.3312e-02, 1.9194e-02, 6.8394e-03, 2.0531e-02,\n",
       "         4.1025e-03, 4.9172e-03], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.2.layer.1.DenseReluDense.wi.weight': tensor([[3.4962e-06, 1.0489e-06, 5.1704e-06,  ..., 9.2823e-07, 1.0370e-06,\n",
       "          5.2199e-06],\n",
       "         [2.8259e-11, 6.2801e-11, 7.5035e-11,  ..., 2.2171e-11, 3.7429e-11,\n",
       "          1.5658e-10],\n",
       "         [1.1912e-09, 3.9160e-10, 6.3674e-11,  ..., 3.9334e-10, 1.0146e-10,\n",
       "          2.0871e-09],\n",
       "         ...,\n",
       "         [3.2995e-10, 5.6737e-10, 6.2692e-11,  ..., 2.2169e-10, 8.3099e-11,\n",
       "          2.1091e-09],\n",
       "         [9.5287e-09, 1.5775e-09, 2.1530e-08,  ..., 2.1351e-08, 5.0166e-09,\n",
       "          1.1763e-08],\n",
       "         [1.8998e-09, 8.0994e-11, 1.4360e-10,  ..., 1.7856e-10, 2.0067e-10,\n",
       "          9.8579e-10]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.2.layer.1.DenseReluDense.wo.weight': tensor([[3.2405e-06, 5.5119e-10, 2.4592e-11,  ..., 1.9559e-08, 6.5615e-09,\n",
       "          8.4330e-11],\n",
       "         [4.1556e-07, 1.6146e-09, 3.6284e-11,  ..., 9.1504e-09, 3.4368e-09,\n",
       "          1.1392e-10],\n",
       "         [3.0322e-06, 9.0977e-10, 8.5036e-12,  ..., 7.7134e-09, 1.2168e-08,\n",
       "          6.9579e-11],\n",
       "         ...,\n",
       "         [2.6714e-06, 1.5048e-09, 1.4423e-12,  ..., 1.8975e-08, 8.7727e-09,\n",
       "          7.2798e-11],\n",
       "         [4.1389e-07, 8.4800e-10, 1.3681e-11,  ..., 5.0249e-09, 8.2687e-09,\n",
       "          6.0868e-11],\n",
       "         [4.3215e-07, 4.6214e-09, 1.3843e-11,  ..., 1.0396e-08, 9.6664e-09,\n",
       "          5.9786e-12]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.2.layer.1.layer_norm.weight': tensor([3.4181e-04, 2.9113e-04, 2.8192e-04, 9.4288e-04, 1.5852e-04, 1.2203e-04,\n",
       "         2.4486e-03, 6.9676e-04, 3.7107e-04, 2.8445e-04, 7.3493e-05, 8.9820e-04,\n",
       "         1.7834e-04, 1.8250e-04, 8.0831e-04, 6.2921e-04, 1.2591e-03, 5.6744e-04,\n",
       "         2.5933e-03, 2.0607e-04, 1.9737e-04, 4.9995e-04, 3.8014e-04, 6.1607e-04,\n",
       "         8.6137e-04, 2.5551e-03, 5.2891e-04, 1.5473e-04, 1.2354e-03, 4.1985e-04,\n",
       "         4.6811e-04, 5.3396e-04, 5.4845e-04, 3.2492e-04, 8.8844e-04, 5.2381e-04,\n",
       "         2.2695e-03, 4.7607e-04, 8.8025e-04, 2.5992e-04, 1.2759e-03, 6.5243e-04,\n",
       "         4.4252e-03, 9.7535e-04, 3.4777e-04, 7.5285e-04, 3.2234e-04, 7.9183e-04,\n",
       "         2.1453e-04, 1.7165e-04, 8.5311e-04, 3.0403e-04, 2.2017e-04, 2.9400e-04,\n",
       "         4.5114e-04, 4.8991e-04, 1.0194e-03, 2.4552e-04, 6.2101e-04, 3.7129e-04,\n",
       "         5.4947e-04, 1.4184e-03, 3.4083e-04, 3.5948e-03, 2.5467e-04, 1.8526e-04,\n",
       "         3.0144e-04, 3.4968e-04, 4.2766e-04, 3.0562e-04, 8.7606e-04, 1.8082e-03,\n",
       "         8.5529e-05, 8.0051e-04, 5.6108e-04, 3.5792e-04, 1.3126e-03, 1.0637e-04,\n",
       "         3.9670e-04, 2.1952e-03, 4.8191e-04, 1.3607e-03, 9.0644e-04, 2.3151e-04,\n",
       "         7.4497e-04, 1.8631e-04, 6.8302e-04, 9.4949e-04, 3.8526e-04, 1.8553e-04,\n",
       "         1.5038e-04, 2.4323e-03, 2.9583e-04, 2.7895e-04, 1.3825e-04, 2.7657e-04,\n",
       "         7.6551e-04, 1.6230e-03, 4.2869e-03, 8.5647e-04, 1.5341e-04, 4.2083e-04,\n",
       "         9.3175e-04, 7.8119e-04, 2.9252e-04, 2.3529e-04, 3.7287e-05, 2.0871e-04,\n",
       "         4.8577e-03, 6.1654e-04, 7.1275e-04, 7.4159e-04, 1.4621e-04, 3.4765e-04,\n",
       "         9.2924e-04, 3.0034e-04, 2.6890e-04, 6.6760e-04, 7.2834e-04, 7.4251e-04,\n",
       "         2.1608e-04, 2.8094e-04, 2.7246e-04, 4.3323e-04, 1.8536e-04, 4.9925e-04,\n",
       "         3.9088e-04, 7.2921e-04, 1.6010e-03, 3.8429e-04, 1.2104e-04, 5.7339e-05,\n",
       "         1.7019e-03, 4.9971e-04, 2.3828e-03, 3.1226e-04, 6.5393e-04, 1.2020e-03,\n",
       "         4.2594e-04, 3.0940e-04, 1.0378e-03, 1.4516e-04, 2.5589e-04, 6.2855e-04,\n",
       "         5.6654e-04, 1.2960e-03, 8.3431e-04, 1.0141e-03, 2.4574e-04, 2.7791e-03,\n",
       "         1.6283e-04, 1.2642e-03, 1.6859e-04, 6.3145e-04, 2.9966e-04, 9.8767e-04,\n",
       "         2.6527e-04, 4.6318e-04, 9.1676e-05, 3.1905e-04, 1.7610e-04, 1.5063e-03,\n",
       "         5.1540e-04, 2.3478e-04, 1.4993e-03, 3.2954e-04, 1.1037e-03, 2.4435e-04,\n",
       "         3.0066e-04, 3.6638e-04, 2.4702e-03, 7.0791e-04, 6.0790e-04, 3.2593e-04,\n",
       "         9.5722e-04, 1.0214e-03, 1.9270e-04, 1.6531e-03, 6.8654e-04, 3.4868e-04,\n",
       "         4.7502e-04, 2.9393e-04, 3.6328e-04, 7.1379e-04, 4.0860e-04, 8.2537e-04,\n",
       "         6.0450e-04, 5.1845e-04, 1.0363e-03, 1.4010e-04, 9.4223e-04, 7.0744e-03,\n",
       "         3.0123e-04, 1.4387e-04, 5.4025e-04, 5.1342e-04, 2.7250e-04, 3.9361e-04,\n",
       "         1.5408e-04, 4.6068e-04, 7.6638e-04, 4.8704e-04, 1.7258e-03, 2.6562e-03,\n",
       "         3.9049e-04, 3.1581e-04, 1.1708e-03, 1.1447e-03, 5.6197e-04, 2.2416e-04,\n",
       "         8.0136e-04, 4.6487e-04, 1.7405e-04, 1.2134e-03, 7.0191e-04, 2.7653e-04,\n",
       "         1.1705e-04, 1.1905e-03, 2.4002e-03, 3.1727e-04, 6.6477e-04, 4.6961e-04,\n",
       "         3.2131e-04, 1.4998e-04, 1.0941e-04, 5.0684e-04, 4.8366e-04, 2.0872e-04,\n",
       "         7.7985e-04, 4.1957e-04, 1.9722e-04, 1.6808e-04, 1.3656e-03, 9.9756e-04,\n",
       "         3.7049e-04, 9.3344e-04, 1.0515e-03, 6.1744e-03, 3.3527e-04, 4.8873e-04,\n",
       "         5.0304e-04, 1.0686e-04, 1.0100e-03, 8.3964e-05, 4.3706e-04, 2.9675e-04,\n",
       "         4.6402e-03, 1.1173e-03, 5.8122e-04, 2.3269e-04, 1.6042e-03, 4.4778e-04,\n",
       "         7.3584e-04, 1.6591e-04, 9.6901e-04, 3.5467e-04, 1.9318e-04, 2.5566e-04,\n",
       "         4.2587e-04, 6.3793e-04, 2.4342e-02, 2.3243e-04, 1.5454e-04, 6.7622e-04,\n",
       "         1.1128e-03, 1.4745e-04, 3.3214e-04, 3.5948e-04, 1.6217e-04, 2.8969e-04,\n",
       "         3.1770e-04, 9.0414e-05, 2.9748e-04, 3.4192e-04, 1.4057e-03, 5.9684e-03,\n",
       "         1.7546e-04, 2.9946e-04, 9.2988e-04, 2.0547e-04, 2.0163e-04, 6.8589e-04,\n",
       "         8.2981e-04, 2.3836e-04, 1.9254e-03, 2.1419e-04, 1.5524e-04, 3.9762e-04,\n",
       "         2.2390e-04, 6.5870e-04, 2.9715e-04, 2.1002e-04, 9.8434e-05, 3.7702e-04,\n",
       "         3.1054e-04, 2.9410e-04, 2.2651e-04, 1.5556e-04, 7.0025e-04, 1.3578e-03,\n",
       "         1.4033e-04, 4.0832e-04, 1.4706e-04, 1.7898e-04, 8.3345e-04, 1.0050e-03,\n",
       "         2.6481e-04, 4.0519e-04, 4.8851e-04, 3.3172e-04, 7.2140e-04, 3.9504e-04,\n",
       "         1.8022e-03, 5.5862e-04, 2.8482e-04, 5.8049e-04, 8.6349e-04, 1.6665e-04,\n",
       "         2.3657e-03, 1.1351e-03, 1.4034e-03, 2.5777e-04, 1.3780e-04, 1.2878e-03,\n",
       "         2.9314e-04, 5.8720e-04, 1.3654e-03, 2.8871e-04, 3.6948e-04, 4.4325e-04,\n",
       "         6.1318e-04, 6.9266e-05, 2.6234e-04, 2.1760e-04, 1.8909e-04, 2.4629e-04,\n",
       "         1.8907e-04, 1.2598e-04, 2.3045e-04, 7.6667e-03, 3.0802e-04, 4.3613e-04,\n",
       "         1.5932e-03, 6.1714e-04, 8.0344e-05, 1.3082e-04, 3.7111e-04, 5.0593e-04,\n",
       "         1.1877e-03, 6.1845e-04, 5.5564e-04, 4.5062e-04, 2.5420e-04, 2.8831e-04,\n",
       "         3.2402e-04, 5.4371e-05, 4.2864e-04, 1.3085e-04, 2.0510e-04, 3.9125e-04,\n",
       "         1.5565e-03, 7.3689e-04, 4.7605e-04, 2.4642e-04, 6.8710e-04, 5.2404e-04,\n",
       "         1.0325e-04, 4.7845e-04, 1.4491e-04, 1.3248e-04, 3.6220e-03, 5.0722e-04,\n",
       "         2.7778e-04, 4.7685e-04, 3.1794e-04, 2.8510e-04, 6.2027e-04, 1.0098e-03,\n",
       "         3.7405e-04, 2.0861e-04, 6.2082e-04, 5.1174e-04, 3.0590e-04, 5.0019e-05,\n",
       "         4.9198e-04, 1.2789e-04, 3.9381e-04, 8.6399e-04, 2.2295e-03, 5.5287e-04,\n",
       "         5.0757e-04, 2.7242e-04, 1.4189e-04, 5.3277e-04, 2.4305e-03, 2.0444e-03,\n",
       "         8.6026e-04, 1.9593e-02, 8.3415e-04, 2.4101e-04, 8.0367e-04, 2.4859e-04,\n",
       "         3.7939e-04, 2.0649e-04, 7.0236e-04, 3.5892e-04, 8.5495e-04, 4.2585e-04,\n",
       "         1.6381e-04, 5.0354e-04, 6.7743e-04, 2.4223e-04, 1.0698e-03, 1.7623e-04,\n",
       "         3.0460e-04, 6.4596e-04, 3.8264e-04, 8.7908e-04, 6.3933e-05, 5.6911e-04,\n",
       "         4.3815e-04, 1.3124e-03, 2.6705e-02, 2.0063e-04, 8.6889e-03, 3.1201e-04,\n",
       "         1.8224e-03, 9.5780e-04, 3.6789e-04, 2.9332e-04, 7.1255e-04, 3.3465e-04,\n",
       "         4.0781e-04, 3.3722e-02, 4.2353e-04, 5.4467e-04, 4.1408e-04, 1.7700e-03,\n",
       "         5.5534e-04, 1.8356e-04, 2.0756e-04, 4.9572e-04, 5.4056e-04, 2.2495e-04,\n",
       "         4.2718e-04, 1.3259e-03, 4.7433e-04, 4.5521e-04, 1.6680e-04, 5.2593e-04,\n",
       "         6.2163e-04, 2.9533e-04, 3.6767e-04, 4.7192e-03, 7.5641e-04, 3.9738e-04,\n",
       "         2.6392e-04, 1.6731e-04, 2.1402e-03, 1.2908e-03, 1.6920e-04, 1.1834e-03,\n",
       "         3.3538e-04, 2.0453e-03, 2.0839e-04, 5.7128e-05, 6.3833e-04, 2.9407e-04,\n",
       "         6.5009e-04, 4.8746e-04, 1.2022e-03, 2.3648e-04, 5.9598e-04, 2.1959e-04,\n",
       "         4.6802e-04, 4.0425e-04, 5.2420e-04, 4.5635e-04, 3.1372e-04, 1.2849e-03,\n",
       "         1.2790e-04, 8.5140e-04, 3.0740e-04, 3.8500e-04, 4.7131e-05, 2.0336e-04,\n",
       "         2.5896e-04, 3.8292e-04, 3.5590e-04, 1.2596e-04, 3.0851e-04, 3.7168e-04,\n",
       "         1.2628e-01, 4.9765e-04, 3.8315e-04, 1.7679e-03, 9.4637e-04, 5.1979e-04,\n",
       "         3.2908e-03, 5.3130e-04, 1.0602e-02, 1.7317e-03, 2.0776e-03, 2.9511e-04,\n",
       "         1.9144e-04, 1.4386e-03, 9.1594e-04, 6.4333e-05, 9.5095e-04, 1.9166e-04,\n",
       "         2.2413e-04, 3.5872e-04], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.3.layer.0.SelfAttention.q.weight': tensor([[3.6022e-04, 8.2011e-04, 1.3859e-04,  ..., 7.1811e-05, 1.1893e-04,\n",
       "          1.4574e-04],\n",
       "         [1.7694e-05, 2.6775e-05, 5.0150e-06,  ..., 4.4746e-06, 4.1879e-06,\n",
       "          1.0982e-05],\n",
       "         [4.5960e-05, 3.9776e-05, 1.6708e-05,  ..., 4.3228e-05, 6.6659e-06,\n",
       "          2.3154e-06],\n",
       "         ...,\n",
       "         [6.1160e-06, 1.9859e-05, 3.7684e-06,  ..., 1.5921e-05, 3.7315e-06,\n",
       "          1.2965e-05],\n",
       "         [1.9276e-05, 4.9972e-05, 6.3783e-05,  ..., 1.9056e-05, 3.9109e-05,\n",
       "          1.4873e-05],\n",
       "         [1.0471e-05, 7.1293e-06, 5.5589e-06,  ..., 1.1751e-05, 5.3695e-06,\n",
       "          1.1585e-05]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.3.layer.0.SelfAttention.k.weight': tensor([[2.7223e-05, 4.5950e-05, 3.9121e-06,  ..., 5.9642e-06, 8.4365e-07,\n",
       "          1.5296e-06],\n",
       "         [8.3310e-07, 3.3918e-06, 7.1744e-08,  ..., 3.1586e-07, 2.7744e-08,\n",
       "          1.9413e-07],\n",
       "         [8.3234e-08, 1.5851e-07, 7.4722e-08,  ..., 9.2719e-08, 7.6532e-09,\n",
       "          2.2483e-07],\n",
       "         ...,\n",
       "         [1.0285e-07, 4.2229e-07, 1.7554e-07,  ..., 1.5589e-07, 1.1322e-07,\n",
       "          8.3544e-08],\n",
       "         [3.9892e-07, 1.6479e-07, 3.7741e-07,  ..., 4.2513e-07, 5.3378e-08,\n",
       "          2.1095e-07],\n",
       "         [6.8744e-07, 1.2488e-06, 1.6213e-07,  ..., 9.7418e-08, 2.4479e-07,\n",
       "          1.8749e-07]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.3.layer.0.SelfAttention.v.weight': tensor([[2.4975e-07, 2.8583e-07, 3.1416e-07,  ..., 6.6171e-07, 2.4624e-07,\n",
       "          1.9611e-07],\n",
       "         [4.4170e-07, 4.8507e-07, 2.6677e-07,  ..., 1.5077e-06, 5.0335e-07,\n",
       "          4.9035e-07],\n",
       "         [4.7533e-07, 5.3296e-08, 2.2117e-07,  ..., 1.5432e-07, 4.1841e-07,\n",
       "          3.7209e-07],\n",
       "         ...,\n",
       "         [4.4810e-07, 1.7956e-06, 7.2928e-07,  ..., 1.9771e-07, 5.2319e-07,\n",
       "          2.8922e-06],\n",
       "         [6.4359e-07, 1.1329e-06, 9.2283e-07,  ..., 3.3091e-07, 1.3873e-07,\n",
       "          9.3892e-07],\n",
       "         [1.8247e-07, 7.7838e-07, 8.0489e-07,  ..., 2.8830e-06, 8.3575e-07,\n",
       "          2.2656e-06]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.3.layer.0.SelfAttention.o.weight': tensor([[1.3305e-07, 1.2173e-06, 2.0053e-07,  ..., 1.2747e-06, 1.2669e-06,\n",
       "          8.2289e-07],\n",
       "         [1.4494e-07, 8.6441e-07, 8.3258e-08,  ..., 1.2339e-06, 1.7611e-07,\n",
       "          4.8081e-07],\n",
       "         [2.4174e-07, 9.4008e-07, 2.0841e-06,  ..., 6.2393e-07, 2.2433e-06,\n",
       "          5.6426e-07],\n",
       "         ...,\n",
       "         [1.4875e-07, 6.1356e-07, 2.0189e-07,  ..., 2.2858e-06, 1.7108e-06,\n",
       "          3.0981e-06],\n",
       "         [2.7314e-07, 1.0757e-07, 6.0142e-08,  ..., 7.5173e-07, 2.4887e-07,\n",
       "          5.4171e-07],\n",
       "         [6.9806e-08, 2.6424e-07, 2.2848e-07,  ..., 3.1662e-07, 7.5496e-07,\n",
       "          2.1892e-06]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.3.layer.0.layer_norm.weight': tensor([6.9771e-03, 9.3007e-03, 5.2935e-02, 5.1733e-02, 5.8317e-03, 4.3877e-03,\n",
       "         1.6981e-02, 5.2172e-03, 1.1683e-02, 9.4535e-03, 2.9789e-02, 6.2940e-02,\n",
       "         9.5576e-03, 5.0000e-03, 7.7844e-03, 2.2923e-03, 2.3247e-02, 5.3878e-02,\n",
       "         1.3501e-02, 1.0107e-02, 4.5326e-02, 3.7686e-02, 1.4723e-02, 6.0658e-02,\n",
       "         8.6231e-03, 3.4102e-02, 1.2192e-02, 6.6900e-03, 9.5852e-03, 9.2396e+00,\n",
       "         2.4012e-02, 2.4891e-02, 3.0740e-02, 1.4023e-02, 4.0662e-02, 2.9761e-02,\n",
       "         3.0756e-02, 2.2255e-02, 2.7876e-02, 2.1013e-02, 6.9494e-03, 2.1111e-02,\n",
       "         2.9101e-01, 5.6675e-03, 1.8752e-02, 2.2890e-03, 1.9727e-02, 2.7392e-02,\n",
       "         9.1274e-03, 1.2078e-02, 2.4099e-02, 3.3736e-02, 1.6731e-02, 1.9454e-02,\n",
       "         1.5174e-01, 1.5028e-02, 7.9741e-03, 2.3934e-02, 4.9114e-02, 1.2519e-02,\n",
       "         4.1243e-02, 3.7687e-01, 8.7366e-03, 2.9993e-02, 3.3375e-02, 5.6431e-02,\n",
       "         1.7553e-02, 1.0968e-02, 6.4397e-03, 2.1202e-02, 1.9490e-02, 7.1736e-03,\n",
       "         7.7150e-03, 7.5318e-03, 1.0012e-02, 8.7636e-03, 2.2277e-02, 3.0652e-02,\n",
       "         1.4943e-02, 1.2572e-01, 1.2060e-01, 6.5585e-02, 1.3224e-02, 1.4345e-02,\n",
       "         2.4648e-02, 6.3524e-03, 1.6921e-02, 4.6587e-02, 1.5132e-02, 1.0836e-02,\n",
       "         1.0983e-02, 3.3162e-02, 1.6001e-02, 1.2760e-02, 2.8562e-02, 5.0711e-02,\n",
       "         9.5113e-02, 6.4116e-03, 1.2902e-01, 4.0094e-02, 1.3317e-02, 8.4725e-03,\n",
       "         6.7453e-03, 4.7078e-02, 5.8965e-03, 1.1532e-02, 4.7350e-03, 7.2409e-03,\n",
       "         6.0258e-01, 9.7563e-03, 8.1767e-02, 1.8207e-02, 2.1965e-02, 1.0721e-02,\n",
       "         1.8116e-02, 5.1745e-02, 2.1409e-02, 5.7953e-02, 4.3490e-02, 3.8259e-02,\n",
       "         1.6777e-02, 9.2950e-03, 2.0463e-02, 5.4977e-02, 2.2903e-02, 1.4371e-02,\n",
       "         3.0726e-02, 1.6380e-02, 8.1630e+00, 2.4927e-02, 1.5557e-02, 9.7551e-03,\n",
       "         3.1384e-02, 2.7309e-02, 2.9590e-02, 2.9537e-02, 9.2322e-01, 1.6489e-02,\n",
       "         1.3186e-02, 8.7349e-02, 2.4278e-02, 2.1620e-02, 3.1708e-02, 4.1817e-02,\n",
       "         2.2383e-02, 2.7907e-02, 5.9625e-03, 9.2102e-02, 3.4061e-03, 1.2586e-01,\n",
       "         4.4172e-03, 1.6351e-02, 1.5497e-02, 1.0483e-02, 1.6186e-02, 8.0923e-03,\n",
       "         8.8228e-03, 1.3925e-02, 3.4961e-02, 1.6639e-02, 3.3775e-02, 8.0746e-02,\n",
       "         3.3267e-02, 9.3894e-03, 3.6386e-02, 1.6699e-02, 3.6209e-02, 1.5974e-02,\n",
       "         2.7646e-02, 4.6361e-03, 1.8390e-02, 1.3117e-02, 1.9484e-03, 1.4254e-02,\n",
       "         3.5521e-02, 7.3411e-03, 2.0558e-02, 4.5229e-02, 1.7001e-02, 5.1461e-03,\n",
       "         1.8462e-02, 3.9282e-03, 3.5791e-02, 2.6361e-02, 1.6949e-02, 2.5461e-02,\n",
       "         1.0877e-02, 4.9756e-02, 1.0169e-02, 1.3956e-02, 4.1360e-02, 2.7016e-01,\n",
       "         2.5124e-02, 3.2851e-02, 1.8032e-02, 2.1794e-02, 9.7057e-03, 1.3991e-02,\n",
       "         2.7632e-02, 2.3133e-02, 7.3200e-02, 1.1095e-02, 1.3989e-02, 6.0715e-01,\n",
       "         5.8749e-02, 3.9338e-02, 4.7728e-02, 2.2872e-02, 1.6193e-02, 3.5083e-03,\n",
       "         2.1745e-02, 1.6643e-02, 2.6304e-02, 5.4197e-02, 1.1762e-02, 1.6385e-02,\n",
       "         7.2074e-03, 1.1561e-01, 5.7699e-02, 1.9219e-02, 2.7130e-02, 2.5675e-02,\n",
       "         1.4239e-02, 7.5786e-02, 2.1602e-02, 9.6502e-03, 5.7486e-02, 8.4052e-03,\n",
       "         1.1459e-01, 4.2003e-02, 1.7628e-02, 5.2913e-03, 1.8515e-02, 1.1097e-02,\n",
       "         4.8830e-03, 1.7087e-02, 1.5760e-01, 4.2312e-02, 2.0042e-03, 2.8644e-02,\n",
       "         1.2141e-02, 1.8682e-02, 8.6544e-03, 6.5620e-03, 1.1881e-02, 2.7252e-02,\n",
       "         4.9507e-01, 6.8370e-02, 6.6767e-02, 1.0628e-02, 3.3502e-02, 9.3355e-03,\n",
       "         2.1252e-02, 2.1201e-02, 1.6016e-02, 4.7203e-02, 1.6015e-02, 3.2146e-03,\n",
       "         1.5664e-02, 2.1877e-02, 8.0438e+00, 8.1032e-02, 1.3847e-02, 8.0533e-03,\n",
       "         1.1300e-01, 2.0952e-02, 2.1506e-02, 2.1529e-03, 1.3405e-02, 2.2409e-02,\n",
       "         8.1016e-03, 2.8637e-02, 2.2627e-02, 2.1913e-02, 8.6032e-03, 2.9876e+00,\n",
       "         2.6930e-02, 2.0687e-02, 4.4022e-02, 2.7736e-02, 1.0030e-02, 5.0671e-03,\n",
       "         1.1990e-02, 1.8101e-02, 1.5994e-02, 1.1547e-02, 2.8001e-02, 1.8028e-02,\n",
       "         1.8571e-02, 1.0719e-01, 3.7377e-02, 2.0222e-02, 1.1708e-01, 2.0022e-02,\n",
       "         6.4095e-02, 3.2316e-02, 5.5175e-03, 5.3201e-03, 1.8539e-02, 1.2866e-02,\n",
       "         2.8310e-02, 2.3740e-02, 4.1068e-02, 6.5700e-03, 1.0845e-02, 4.6629e-02,\n",
       "         6.4348e-03, 4.2620e-02, 1.6689e-02, 2.3825e-02, 1.8201e-02, 5.3505e-02,\n",
       "         1.1283e-01, 1.1730e-02, 6.2670e-03, 2.6535e-02, 2.0305e-02, 5.6903e-03,\n",
       "         5.2210e-02, 2.7902e-02, 5.1277e-02, 2.8579e-02, 4.0174e-02, 4.3096e-02,\n",
       "         4.5765e-02, 2.7422e-02, 4.2723e-03, 7.1639e-03, 3.5462e-03, 4.2779e-02,\n",
       "         2.1392e-02, 4.0691e-02, 3.1307e-03, 1.4622e-02, 4.8516e-03, 1.0438e-02,\n",
       "         8.4751e-03, 1.0921e-02, 5.7843e-03, 8.3659e-01, 3.8377e-02, 1.0309e-02,\n",
       "         9.5881e-03, 3.0032e-02, 7.3688e-03, 2.0911e-02, 1.1391e-02, 1.2241e-02,\n",
       "         3.3267e-02, 1.8612e-02, 4.4995e-02, 1.8310e-02, 1.4532e-02, 4.0083e-02,\n",
       "         2.5727e-02, 3.5698e-03, 2.5731e-02, 3.3552e-03, 1.2776e-02, 2.4110e-02,\n",
       "         7.8506e-03, 4.7200e-03, 2.3100e-02, 1.8679e-02, 1.2336e-02, 6.2363e-03,\n",
       "         5.5181e-02, 1.8151e-02, 2.4961e-02, 9.8931e-03, 5.6487e-03, 3.9047e-02,\n",
       "         2.0750e-02, 1.3469e-02, 5.4857e-03, 9.3352e-03, 2.1252e-02, 4.0997e-02,\n",
       "         1.9170e-02, 5.6161e-03, 3.2683e-03, 9.4013e-03, 2.9064e-03, 1.6323e-02,\n",
       "         1.2314e-02, 4.4070e-02, 7.9237e-02, 7.3612e-03, 1.8966e-02, 2.3351e-02,\n",
       "         1.1476e-02, 3.4474e-03, 1.2948e-02, 3.7863e-03, 9.6491e-03, 1.9907e-02,\n",
       "         2.1330e-02, 8.4719e-01, 1.5569e-02, 5.0969e-02, 6.2714e-03, 1.7718e-02,\n",
       "         3.0864e-02, 1.4161e-02, 1.7319e-02, 1.3497e-02, 1.6434e-02, 2.4633e-02,\n",
       "         9.3420e-03, 2.0446e-02, 6.6853e-03, 1.0772e-01, 1.2474e-02, 2.4121e-02,\n",
       "         9.4256e-03, 3.6477e-02, 2.3269e-02, 6.3350e-02, 1.7126e-02, 1.3560e-02,\n",
       "         7.3434e-03, 8.6233e-02, 2.6768e+00, 1.1907e-02, 3.0589e-01, 6.2939e-03,\n",
       "         1.4299e-02, 7.7342e-03, 1.4408e-02, 1.6133e-02, 4.4332e-03, 1.2012e-02,\n",
       "         1.0780e-02, 1.2888e+01, 2.7182e-02, 2.8506e-02, 1.5255e-02, 3.7287e-02,\n",
       "         1.0494e-02, 2.0335e-02, 8.2491e-03, 6.0384e-03, 1.9576e-02, 9.7742e-03,\n",
       "         1.2266e-02, 3.5286e-02, 2.1498e-03, 1.0089e-02, 1.0280e-02, 2.2458e-02,\n",
       "         3.4900e-02, 8.3747e-03, 1.5535e-02, 8.4164e-02, 6.7498e-03, 1.3568e-02,\n",
       "         1.7469e-02, 9.0705e-03, 3.6617e-02, 2.0173e-02, 4.8249e-02, 6.8559e-02,\n",
       "         6.9426e-02, 1.6712e-02, 1.9761e-02, 1.8375e-02, 1.5269e-02, 6.5386e-03,\n",
       "         5.2999e-02, 1.5370e-02, 1.7420e-02, 1.1953e-02, 1.3888e-02, 1.5006e-02,\n",
       "         1.6857e-02, 9.4667e-02, 5.6289e-03, 1.3843e-02, 9.7932e-03, 3.0025e-02,\n",
       "         5.9821e-03, 1.1333e-02, 7.2714e-02, 2.0437e-02, 5.1176e-03, 2.6526e-02,\n",
       "         1.5310e-02, 1.7769e-02, 3.0757e-02, 2.5332e-02, 1.2744e-02, 8.9973e-03,\n",
       "         9.5523e+00, 4.8861e-03, 6.4961e-02, 1.6425e-02, 1.8289e-02, 2.7601e-02,\n",
       "         3.2329e-02, 1.5024e-02, 2.9223e-02, 4.2724e-02, 1.7778e-02, 1.1537e-02,\n",
       "         9.7542e-03, 2.4222e-02, 4.1406e-02, 3.9678e-02, 1.6331e-02, 3.5361e-02,\n",
       "         1.7131e-02, 2.4562e-02], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.3.layer.1.DenseReluDense.wi.weight': tensor([[4.8848e-07, 2.6699e-08, 2.1837e-08,  ..., 1.5182e-09, 7.0809e-08,\n",
       "          5.8823e-07],\n",
       "         [2.6758e-08, 1.7904e-08, 1.8677e-09,  ..., 8.1152e-08, 1.7172e-09,\n",
       "          4.2642e-09],\n",
       "         [1.4730e-07, 1.9090e-07, 3.3027e-07,  ..., 1.4401e-07, 2.8627e-07,\n",
       "          2.8377e-07],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.7080e-09, 1.4139e-08, 8.5546e-10,  ..., 1.6688e-10, 4.6524e-10,\n",
       "          8.8967e-11],\n",
       "         [3.6365e-12, 4.5787e-12, 6.1108e-12,  ..., 4.7044e-12, 2.9594e-12,\n",
       "          7.0842e-12]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.3.layer.1.DenseReluDense.wo.weight': tensor([[9.8302e-09, 4.0539e-09, 3.6409e-07,  ..., 0.0000e+00, 5.8039e-10,\n",
       "          9.9635e-11],\n",
       "         [6.3493e-10, 1.8941e-08, 9.8866e-08,  ..., 0.0000e+00, 1.6084e-11,\n",
       "          2.9186e-11],\n",
       "         [1.8783e-08, 2.4997e-08, 2.6790e-07,  ..., 0.0000e+00, 6.8413e-11,\n",
       "          5.7786e-14],\n",
       "         ...,\n",
       "         [3.3475e-08, 5.8134e-08, 3.8352e-07,  ..., 0.0000e+00, 2.7440e-11,\n",
       "          3.2433e-11],\n",
       "         [1.7172e-08, 2.5940e-08, 4.0519e-07,  ..., 0.0000e+00, 2.9924e-11,\n",
       "          1.2389e-11],\n",
       "         [7.6788e-09, 5.4063e-09, 2.3367e-07,  ..., 0.0000e+00, 1.1240e-14,\n",
       "          5.9994e-12]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.3.layer.1.layer_norm.weight': tensor([6.2602e-04, 3.4671e-04, 5.6523e-04, 1.8496e-03, 9.7910e-05, 1.2217e-04,\n",
       "         3.1559e-04, 1.6339e-03, 2.1920e-03, 3.0104e-04, 5.3102e-05, 3.6267e-04,\n",
       "         7.4794e-05, 1.1438e-04, 5.0394e-04, 3.1705e-04, 3.4776e-04, 8.9444e-04,\n",
       "         1.9761e-04, 1.2129e-04, 1.2016e-04, 4.1032e-04, 1.9085e-03, 2.2370e-04,\n",
       "         1.9762e-04, 8.3097e-04, 1.7997e-04, 1.0277e-03, 6.0484e-04, 1.7019e-03,\n",
       "         5.5184e-04, 4.4276e-04, 2.9369e-04, 4.2835e-04, 9.8372e-04, 3.6672e-04,\n",
       "         1.8414e-04, 1.4526e-04, 5.3328e-04, 1.2147e-04, 1.1720e-04, 2.4226e-04,\n",
       "         1.6353e-03, 2.2319e-04, 9.3694e-04, 2.3468e-04, 8.3781e-04, 1.9313e-04,\n",
       "         2.5042e-04, 8.5603e-05, 9.3108e-05, 6.3112e-04, 4.8246e-04, 1.3113e-03,\n",
       "         8.0982e-04, 1.8218e-04, 1.4393e-04, 3.6056e-04, 1.8134e-04, 8.3126e-05,\n",
       "         8.7374e-05, 1.3154e-03, 5.6150e-04, 3.3796e-04, 2.2109e-04, 1.0722e-04,\n",
       "         1.4606e-04, 8.4442e-04, 1.1015e-04, 5.8722e-05, 2.4534e-04, 7.6127e-04,\n",
       "         6.1303e-05, 8.4710e-04, 1.5040e-04, 3.4092e-04, 6.6613e-05, 4.1752e-04,\n",
       "         1.7544e-04, 4.9249e-03, 1.4039e-03, 4.8113e-04, 1.2741e-04, 2.8684e-04,\n",
       "         1.1617e-04, 1.0732e-03, 8.8102e-05, 4.5960e-04, 1.8868e-04, 1.0041e-04,\n",
       "         2.4383e-04, 6.1780e-04, 2.7820e-04, 1.9485e-04, 1.1854e-03, 3.5538e-04,\n",
       "         8.5904e-04, 5.7093e-04, 4.3859e-04, 2.9702e-03, 6.7974e-05, 9.9731e-05,\n",
       "         3.7971e-04, 2.2991e-04, 9.7927e-04, 8.2664e-05, 1.1169e-04, 2.7098e-04,\n",
       "         4.0716e-03, 5.6486e-04, 4.6807e-04, 5.3110e-04, 2.6488e-04, 2.4528e-04,\n",
       "         9.2814e-05, 2.2889e-04, 9.2070e-04, 1.1989e-04, 1.0057e-04, 1.0465e-04,\n",
       "         2.9259e-04, 3.0471e-04, 8.1347e-05, 6.4251e-04, 2.5764e-04, 8.2611e-04,\n",
       "         3.5526e-04, 3.8992e-04, 5.9559e-03, 6.9779e-04, 1.8037e-04, 5.7722e-05,\n",
       "         7.3028e-04, 3.6261e-04, 5.5851e-04, 1.6697e-04, 2.3955e-04, 4.8859e-04,\n",
       "         5.5267e-04, 1.4114e-04, 3.1926e-04, 8.8796e-05, 8.9301e-04, 1.1922e-04,\n",
       "         2.8919e-04, 4.7343e-04, 3.5965e-04, 1.3451e-03, 5.2323e-04, 9.5772e-04,\n",
       "         2.9074e-04, 2.8644e-04, 1.1164e-04, 5.7249e-05, 8.7078e-05, 1.8983e-04,\n",
       "         2.0758e-04, 1.1704e-04, 1.4769e-04, 8.2131e-05, 7.6240e-05, 1.0100e-03,\n",
       "         1.4506e-04, 2.8448e-04, 8.8575e-04, 4.0608e-04, 7.9909e-04, 4.4076e-04,\n",
       "         2.6763e-04, 1.8194e-04, 6.0523e-04, 1.5038e-04, 1.8294e-04, 1.0566e-04,\n",
       "         9.0057e-04, 5.0780e-04, 1.3186e-04, 3.8269e-04, 1.6449e-04, 3.3369e-04,\n",
       "         4.9726e-04, 4.3032e-05, 3.8724e-04, 8.7258e-05, 2.7325e-04, 1.0301e-04,\n",
       "         4.0755e-04, 6.3598e-05, 5.5189e-04, 5.1002e-04, 1.4279e-04, 4.3609e-03,\n",
       "         4.5444e-04, 1.6953e-04, 1.5865e-04, 2.6000e-04, 2.2984e-04, 8.2543e-05,\n",
       "         1.7045e-04, 3.1150e-04, 1.3439e-03, 2.3331e-04, 2.5878e-04, 9.5557e-04,\n",
       "         1.9064e-04, 3.5507e-04, 1.3937e-03, 1.9321e-04, 8.6882e-04, 2.9139e-04,\n",
       "         6.5147e-05, 1.8472e-04, 4.1525e-04, 1.7743e-03, 2.6833e-04, 1.6731e-03,\n",
       "         2.2285e-04, 2.4121e-03, 4.6624e-03, 5.7436e-04, 4.2999e-04, 3.1256e-04,\n",
       "         9.3483e-04, 7.8207e-04, 1.7776e-04, 7.7978e-05, 5.1731e-04, 6.3629e-05,\n",
       "         3.1923e-04, 5.7504e-04, 3.9068e-04, 1.0194e-04, 1.6028e-03, 7.9976e-04,\n",
       "         4.1516e-04, 9.2373e-04, 8.3103e-04, 2.0110e-03, 1.4700e-04, 4.0702e-04,\n",
       "         1.0676e-03, 3.6283e-04, 5.4256e-04, 1.0058e-04, 9.2149e-04, 2.2651e-04,\n",
       "         2.6091e-03, 3.2081e-04, 1.1606e-04, 2.4401e-04, 9.8476e-04, 4.4304e-04,\n",
       "         8.6799e-04, 8.2043e-05, 7.7515e-05, 7.2110e-04, 9.4060e-04, 5.0259e-04,\n",
       "         1.1100e-04, 1.3360e-04, 1.0559e-02, 5.4590e-04, 2.4473e-03, 1.3267e-04,\n",
       "         5.5411e-03, 5.6301e-05, 1.1099e-04, 2.4903e-04, 3.5637e-04, 5.8017e-04,\n",
       "         2.1131e-04, 2.7603e-04, 3.3691e-04, 2.0356e-04, 1.9707e-04, 4.1596e-03,\n",
       "         1.8384e-04, 6.0827e-05, 8.2068e-05, 1.1304e-04, 8.0648e-04, 4.7268e-04,\n",
       "         5.2550e-04, 7.5733e-04, 5.3087e-05, 3.7970e-04, 4.2139e-04, 1.1986e-03,\n",
       "         3.4572e-04, 5.6010e-04, 1.5332e-04, 3.3955e-04, 2.0021e-04, 2.7162e-04,\n",
       "         1.6818e-03, 2.6984e-04, 1.3080e-04, 2.2821e-04, 2.1787e-04, 1.2267e-03,\n",
       "         1.6475e-04, 2.3934e-04, 1.6666e-04, 1.6122e-04, 4.5718e-04, 6.6733e-04,\n",
       "         2.2541e-04, 1.4025e-04, 7.3743e-04, 4.9027e-04, 3.2400e-04, 4.7839e-05,\n",
       "         4.0721e-04, 1.4029e-04, 3.5292e-04, 1.6408e-03, 1.9815e-04, 1.9762e-04,\n",
       "         1.4552e-03, 6.8552e-04, 1.7051e-04, 4.9925e-04, 1.5078e-04, 1.8011e-03,\n",
       "         3.1752e-04, 3.2659e-04, 9.9814e-05, 3.6730e-05, 6.9336e-05, 2.4699e-04,\n",
       "         7.6828e-05, 1.4817e-04, 4.3879e-04, 3.5162e-04, 4.9583e-05, 3.6201e-04,\n",
       "         3.8795e-04, 1.0529e-04, 1.1129e-04, 1.6153e-03, 6.8314e-04, 3.7397e-04,\n",
       "         3.1445e-05, 3.8103e-04, 1.1729e-04, 2.1632e-04, 2.6196e-04, 9.9794e-05,\n",
       "         2.5404e-04, 1.0069e-03, 2.6566e-04, 1.0362e-04, 1.0065e-04, 2.2737e-04,\n",
       "         1.9371e-03, 3.5347e-04, 1.5468e-04, 3.7406e-04, 1.1991e-04, 2.9334e-04,\n",
       "         2.8799e-04, 6.5158e-05, 2.0568e-04, 1.5717e-04, 3.0752e-04, 4.2385e-04,\n",
       "         5.3764e-04, 2.8571e-04, 5.9660e-04, 5.1815e-05, 2.5234e-03, 2.1624e-03,\n",
       "         3.2851e-04, 5.0832e-04, 2.0640e-04, 2.8087e-04, 4.6061e-05, 6.0036e-04,\n",
       "         1.5354e-04, 1.7941e-04, 3.3997e-04, 2.9910e-04, 8.0613e-04, 2.1423e-04,\n",
       "         8.1903e-05, 2.0485e-03, 2.7270e-03, 1.1411e-04, 1.4007e-04, 1.6559e-04,\n",
       "         4.7025e-04, 4.4222e-04, 2.2910e-04, 1.0535e-04, 6.2477e-04, 8.9977e-04,\n",
       "         1.0255e-03, 1.2907e-02, 4.0868e-04, 1.2718e-03, 1.9183e-04, 1.9230e-04,\n",
       "         2.6479e-04, 2.2278e-04, 1.9292e-04, 9.0382e-05, 6.4922e-04, 4.3702e-04,\n",
       "         4.1358e-05, 1.3883e-04, 4.3761e-04, 2.7194e-03, 2.2734e-04, 3.0257e-03,\n",
       "         4.4305e-04, 3.2125e-04, 3.5847e-04, 1.3629e-04, 5.2400e-05, 4.7113e-04,\n",
       "         7.2031e-04, 6.3339e-04, 3.2285e-02, 1.0272e-03, 2.7107e-03, 1.8038e-04,\n",
       "         5.5875e-04, 4.3101e-04, 3.0780e-04, 3.9397e-04, 3.0901e-04, 2.6582e-04,\n",
       "         1.5436e-04, 8.2271e-03, 1.2477e-04, 5.8515e-04, 8.4610e-04, 4.0614e-04,\n",
       "         3.2774e-04, 3.7413e-04, 4.5699e-04, 1.7168e-04, 1.3708e-04, 1.0633e-03,\n",
       "         1.9548e-04, 9.9353e-04, 9.2792e-05, 5.5017e-04, 2.0706e-04, 1.5965e-04,\n",
       "         1.7493e-04, 7.1669e-05, 6.3853e-04, 6.0657e-03, 5.6175e-04, 1.5340e-04,\n",
       "         6.2096e-05, 7.0977e-05, 1.1869e-03, 4.9520e-04, 3.9180e-05, 3.6834e-04,\n",
       "         2.3799e-04, 7.7704e-04, 1.6295e-04, 1.0380e-03, 3.7789e-04, 4.9094e-04,\n",
       "         7.2288e-04, 6.8439e-04, 1.8116e-04, 5.7216e-04, 5.0573e-05, 1.0316e-04,\n",
       "         1.7559e-04, 1.0316e-03, 2.5425e-04, 4.0956e-04, 2.8815e-04, 1.7292e-04,\n",
       "         1.3321e-04, 4.9162e-05, 1.4170e-04, 1.3038e-04, 4.8700e-04, 8.7184e-05,\n",
       "         3.3640e-04, 5.1935e-04, 9.3384e-05, 7.9493e-05, 6.5134e-04, 1.3705e-04,\n",
       "         9.8669e-03, 1.6579e-04, 3.3345e-04, 2.9599e-04, 1.0304e-04, 1.1377e-03,\n",
       "         2.3527e-04, 2.9376e-04, 7.7250e-04, 2.3960e-03, 2.4519e-03, 3.2700e-04,\n",
       "         3.9961e-04, 3.6552e-04, 4.7826e-04, 7.5288e-05, 5.9473e-04, 1.3564e-03,\n",
       "         6.4484e-05, 6.5854e-04], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.4.layer.0.SelfAttention.q.weight': tensor([[2.4107e-05, 5.4491e-05, 1.0501e-05,  ..., 1.3441e-05, 1.3987e-05,\n",
       "          2.6091e-05],\n",
       "         [5.2365e-05, 2.3328e-05, 2.7128e-05,  ..., 9.7084e-06, 1.9616e-05,\n",
       "          8.7455e-06],\n",
       "         [6.7446e-05, 4.7808e-05, 1.3511e-04,  ..., 1.1629e-05, 1.6573e-05,\n",
       "          1.2977e-05],\n",
       "         ...,\n",
       "         [9.6745e-05, 6.9263e-05, 8.9949e-05,  ..., 2.3806e-05, 3.8879e-05,\n",
       "          1.1103e-04],\n",
       "         [9.5384e-05, 4.8515e-05, 1.5100e-05,  ..., 3.4915e-06, 6.0540e-06,\n",
       "          1.9621e-05],\n",
       "         [1.1164e-04, 1.2856e-05, 8.7249e-06,  ..., 7.9062e-05, 2.0370e-05,\n",
       "          3.1859e-05]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.4.layer.0.SelfAttention.k.weight': tensor([[2.0350e-07, 2.2270e-06, 4.8320e-07,  ..., 1.7793e-07, 4.8857e-07,\n",
       "          3.2650e-07],\n",
       "         [1.0076e-06, 1.6728e-06, 5.0771e-07,  ..., 5.9067e-08, 6.7843e-07,\n",
       "          2.9218e-07],\n",
       "         [1.4099e-07, 1.7855e-07, 1.6936e-07,  ..., 5.5805e-07, 5.2269e-07,\n",
       "          2.5184e-07],\n",
       "         ...,\n",
       "         [1.0812e-06, 1.7687e-06, 5.9601e-07,  ..., 1.2569e-06, 4.7214e-07,\n",
       "          2.6381e-06],\n",
       "         [3.6317e-08, 7.5949e-07, 7.8753e-08,  ..., 4.3955e-08, 6.8202e-07,\n",
       "          7.0767e-07],\n",
       "         [1.3427e-07, 8.1336e-07, 3.7248e-07,  ..., 1.7195e-07, 1.2146e-07,\n",
       "          4.9669e-07]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.4.layer.0.SelfAttention.v.weight': tensor([[2.1607e-07, 6.9230e-07, 2.3935e-07,  ..., 6.2585e-07, 1.1177e-07,\n",
       "          2.0009e-07],\n",
       "         [3.8675e-07, 4.1978e-07, 4.9097e-07,  ..., 4.0625e-07, 3.5072e-07,\n",
       "          1.6727e-07],\n",
       "         [6.7064e-07, 1.5783e-06, 1.3525e-07,  ..., 6.7455e-07, 3.3668e-07,\n",
       "          6.4377e-08],\n",
       "         ...,\n",
       "         [5.2982e-07, 8.2818e-07, 1.7452e-07,  ..., 1.3340e-06, 1.9961e-07,\n",
       "          1.1632e-06],\n",
       "         [2.9721e-07, 3.1418e-07, 3.2057e-07,  ..., 4.1642e-07, 1.3655e-07,\n",
       "          2.0788e-07],\n",
       "         [7.9336e-08, 2.5926e-07, 1.7454e-07,  ..., 4.6834e-07, 3.9520e-07,\n",
       "          8.9800e-07]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.4.layer.0.SelfAttention.o.weight': tensor([[8.9240e-07, 1.4992e-07, 3.1812e-07,  ..., 1.9092e-07, 1.2292e-07,\n",
       "          4.4990e-07],\n",
       "         [1.7477e-06, 7.4810e-07, 3.7297e-07,  ..., 2.9042e-07, 1.9584e-08,\n",
       "          1.4502e-07],\n",
       "         [6.2170e-07, 1.2711e-07, 4.1599e-07,  ..., 2.7347e-07, 6.3374e-08,\n",
       "          2.8380e-08],\n",
       "         ...,\n",
       "         [3.7512e-07, 2.7302e-07, 6.7864e-08,  ..., 1.2759e-07, 8.6085e-08,\n",
       "          7.3914e-07],\n",
       "         [6.6845e-07, 1.4873e-07, 1.4476e-07,  ..., 1.6821e-07, 5.9346e-08,\n",
       "          1.2730e-07],\n",
       "         [1.2127e-07, 4.4412e-08, 1.1787e-07,  ..., 8.6892e-08, 7.6928e-08,\n",
       "          4.4303e-07]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.4.layer.0.layer_norm.weight': tensor([2.2037e-02, 1.0448e-02, 9.8758e-03, 2.3468e-02, 9.8593e-03, 2.4639e-02,\n",
       "         3.7809e-02, 1.1761e-02, 5.9215e-02, 2.9502e-02, 9.4934e-03, 2.5292e-02,\n",
       "         4.3100e-02, 8.9527e-03, 7.3649e-02, 1.2373e-02, 5.1204e-03, 1.4219e-02,\n",
       "         2.6899e-02, 9.5244e-03, 2.7951e-03, 6.6999e-03, 8.2160e-02, 3.2574e-02,\n",
       "         4.8037e-02, 1.5876e-02, 5.8383e-03, 4.3969e-02, 3.1827e-02, 1.6534e+01,\n",
       "         1.9972e-02, 1.6477e-02, 9.4901e-02, 1.0172e-02, 4.2365e-02, 3.2620e-02,\n",
       "         1.8370e-02, 2.5509e-02, 5.9290e-02, 3.0245e-02, 3.6827e-02, 2.4465e-02,\n",
       "         2.5818e-01, 3.4267e-02, 7.2679e-02, 1.3102e-02, 3.6724e-02, 9.1723e-03,\n",
       "         9.9186e-03, 4.9160e-03, 1.7539e-02, 8.4917e-03, 4.3439e-03, 1.2600e-02,\n",
       "         4.6888e-02, 9.8298e-03, 2.0883e-02, 1.9664e-02, 5.2506e-03, 1.9626e-02,\n",
       "         1.8232e-02, 6.5162e-01, 4.7835e-02, 1.6409e-02, 1.3990e-01, 4.8728e-03,\n",
       "         7.2819e-03, 1.5307e-02, 8.5305e-03, 2.3452e-02, 1.8111e-02, 1.8509e-02,\n",
       "         1.2067e-02, 2.0905e-02, 5.9574e-03, 3.0253e-02, 4.9621e-03, 1.1462e-02,\n",
       "         1.2686e-02, 8.4313e-02, 4.0474e-02, 1.9726e-02, 1.7133e-02, 2.0141e-02,\n",
       "         1.0851e-02, 2.2724e-02, 5.6059e-03, 2.0960e-02, 1.4025e-02, 1.4951e-02,\n",
       "         4.2232e-03, 7.6221e-03, 4.1480e-03, 9.5175e-03, 4.5334e-03, 2.8098e-03,\n",
       "         1.3046e-02, 9.9844e-03, 1.7184e-01, 1.4354e-02, 3.7038e-03, 2.1345e-02,\n",
       "         1.0268e-01, 1.0392e-02, 2.1019e-02, 9.5385e-03, 1.3038e-02, 5.6156e-03,\n",
       "         4.3063e-01, 7.1877e-03, 3.1954e-02, 4.5036e-02, 1.0234e-02, 4.1151e-02,\n",
       "         6.3612e-03, 3.1097e-02, 9.7929e-03, 4.7315e-03, 1.0959e-02, 9.0609e-03,\n",
       "         5.8937e-03, 2.1690e-02, 1.1236e-02, 7.7650e-03, 6.7074e-03, 1.8239e-02,\n",
       "         1.7806e-02, 5.0648e-03, 1.8442e+01, 1.6455e-02, 1.5878e-02, 2.7839e-02,\n",
       "         4.2080e-02, 1.2188e-01, 1.6117e-02, 1.0811e-02, 2.3431e+00, 4.4661e-02,\n",
       "         1.7566e-02, 4.0409e-03, 8.2644e-03, 4.5878e-03, 2.5369e-02, 3.0151e-02,\n",
       "         3.4366e-02, 2.2508e-02, 1.1733e-02, 2.5882e-01, 1.5990e-02, 3.7934e-01,\n",
       "         1.4047e-02, 1.2266e-02, 1.5637e-02, 1.0515e-02, 3.7451e-03, 3.0010e-02,\n",
       "         5.0458e-03, 1.6775e-02, 1.4151e-02, 1.8172e-02, 1.1248e-02, 3.7857e-02,\n",
       "         7.6110e-03, 1.5730e-02, 2.8419e-02, 9.3637e-03, 5.0945e-02, 1.8843e-02,\n",
       "         1.0774e-02, 4.5832e-03, 7.1652e-02, 2.7052e-02, 7.4873e-03, 9.3918e-03,\n",
       "         1.5805e-02, 1.7954e-02, 1.2562e-02, 7.3822e-02, 1.5473e-02, 1.7835e-03,\n",
       "         2.4641e-03, 4.4623e-03, 5.2062e-03, 8.0176e-03, 2.2158e-02, 3.7306e-02,\n",
       "         3.6800e-02, 6.5940e-03, 1.6581e-02, 4.9518e-03, 1.2552e-02, 1.0365e-01,\n",
       "         1.4168e-02, 2.4800e-02, 3.3138e-03, 6.2943e-03, 7.5661e-03, 3.7624e-02,\n",
       "         1.2559e-02, 1.2116e-02, 1.4043e-01, 2.3402e-02, 2.8340e-02, 1.5984e+00,\n",
       "         4.7235e-02, 1.1361e-02, 1.0180e-01, 2.1741e-02, 1.4027e-02, 3.1772e-03,\n",
       "         2.9995e-02, 1.6911e-02, 2.4914e-02, 2.7972e-02, 2.4163e-02, 4.6027e-02,\n",
       "         1.2142e-02, 4.2389e-02, 4.7711e-01, 2.5748e-02, 1.6996e-02, 1.5891e-02,\n",
       "         6.3490e-03, 1.0733e-02, 1.6187e-02, 1.5168e-02, 3.2570e-02, 1.1886e-02,\n",
       "         1.5771e-02, 1.2590e-02, 7.1822e-03, 1.7595e-02, 7.2660e-02, 1.8708e-02,\n",
       "         4.5021e-02, 9.0491e-02, 4.1489e-01, 2.6405e-02, 3.7115e-03, 1.6688e-02,\n",
       "         2.7699e-03, 1.5247e-01, 2.8583e-02, 3.8254e-03, 1.2792e-02, 1.4554e-02,\n",
       "         4.3473e-01, 7.1035e-02, 2.1834e-02, 1.9241e-02, 1.0635e-02, 4.5773e-02,\n",
       "         3.0955e-02, 6.0202e-03, 3.7648e-02, 2.2525e-02, 2.1364e-02, 1.2753e-02,\n",
       "         8.4123e-03, 7.4843e-03, 1.1474e+01, 9.5331e-03, 1.4364e-02, 2.5345e-02,\n",
       "         7.7074e-02, 4.8610e-03, 5.9642e-03, 1.6071e-02, 1.6286e-02, 1.5316e-02,\n",
       "         6.6692e-02, 3.4881e-02, 5.3074e-03, 1.3300e-02, 2.3975e-02, 4.1018e+00,\n",
       "         4.3603e-02, 8.8581e-03, 8.2104e-03, 5.7631e-03, 1.6719e-02, 3.1530e-02,\n",
       "         7.0423e-03, 2.0350e-02, 8.0536e-03, 1.7081e-02, 6.5812e-03, 4.3776e-03,\n",
       "         2.3440e-02, 1.6751e-02, 2.9961e-02, 1.0226e-02, 7.4263e-03, 1.0763e-02,\n",
       "         5.8279e-03, 3.9511e-02, 1.2428e-02, 7.0128e-03, 1.6976e-02, 1.7892e-02,\n",
       "         4.2474e-02, 2.2351e-02, 1.1798e-01, 5.0712e-03, 1.9511e-02, 5.6192e-03,\n",
       "         5.8621e-03, 1.8411e-02, 1.9272e-02, 3.4984e-02, 2.1221e-02, 7.9076e-03,\n",
       "         3.8629e-01, 3.2224e-03, 5.1790e-03, 3.4396e-03, 1.1381e-02, 5.2209e-03,\n",
       "         1.1201e-01, 1.6193e-01, 1.0915e-02, 8.0038e-03, 4.7133e-03, 3.3074e-02,\n",
       "         8.2762e-03, 2.9049e-03, 8.3072e-03, 2.7051e-02, 1.1600e-02, 9.0669e-03,\n",
       "         3.8329e-02, 3.0183e-02, 3.0417e-02, 2.0369e-02, 6.1406e-03, 1.0967e-02,\n",
       "         2.7364e-02, 8.0258e-03, 7.7456e-03, 7.1877e-01, 1.0834e-02, 7.0241e-03,\n",
       "         7.4269e-03, 1.5854e-02, 1.7563e-02, 3.5489e-01, 2.2723e-02, 1.3951e-02,\n",
       "         1.7074e-02, 2.4941e-02, 1.6998e-02, 2.1222e-02, 3.2340e-03, 8.3830e-03,\n",
       "         6.1697e-03, 2.7604e-02, 3.4912e-02, 7.0872e-03, 2.8036e-02, 5.3946e-02,\n",
       "         6.8610e-02, 2.7197e-03, 5.6712e-03, 1.4615e-02, 6.8077e-03, 4.2208e-02,\n",
       "         2.5902e-02, 2.2300e-02, 1.8985e-02, 5.7280e-03, 7.6676e-02, 6.7958e-02,\n",
       "         4.4786e-02, 2.0595e-03, 6.3084e-03, 2.2360e-02, 7.9714e-03, 3.5205e-02,\n",
       "         7.0069e-03, 3.4402e-02, 1.6367e-02, 2.0700e-02, 1.0254e-02, 4.0969e-03,\n",
       "         1.9628e-02, 2.0134e-02, 4.9614e-02, 2.1220e-02, 5.1001e-02, 1.1976e-02,\n",
       "         5.1280e-03, 4.4853e-02, 1.8849e-02, 4.9271e-03, 1.3877e-01, 4.1132e-02,\n",
       "         3.2756e-02, 2.3338e+00, 1.7335e-02, 3.0315e-02, 2.9791e-02, 3.3415e-02,\n",
       "         3.8487e-02, 1.0780e-02, 6.8099e-03, 5.4775e-02, 1.7985e-02, 1.4944e-02,\n",
       "         1.7314e-02, 7.2606e-03, 3.0696e-02, 4.2313e-02, 2.1775e-02, 6.5081e-03,\n",
       "         1.8470e-02, 6.0666e-02, 2.6768e-02, 1.8114e-02, 1.4594e-02, 2.2159e-03,\n",
       "         9.1705e-03, 1.5192e-02, 1.7589e+00, 2.9199e-02, 6.3435e-02, 4.2764e-02,\n",
       "         3.1281e-03, 5.5772e-03, 2.0352e-02, 2.8331e-02, 1.1647e-02, 1.1553e-02,\n",
       "         4.9523e-03, 2.1459e+01, 1.9898e-02, 3.3554e-03, 1.4416e-02, 6.6318e-02,\n",
       "         3.2905e-02, 2.3143e-02, 3.5071e-02, 7.6878e-03, 3.3285e-03, 3.6719e-02,\n",
       "         3.9819e-03, 6.9554e-03, 1.9366e-02, 2.2821e-02, 3.4137e-02, 5.0876e-03,\n",
       "         5.8186e-03, 4.6968e-03, 1.9295e-02, 5.7400e-01, 1.2968e-02, 1.3122e-02,\n",
       "         2.5113e-02, 4.5692e-03, 1.4520e-02, 1.2217e-02, 1.0866e-02, 8.9025e-02,\n",
       "         4.1998e-03, 2.7827e-02, 9.2953e-03, 1.7751e-02, 6.2857e-03, 2.7049e-02,\n",
       "         2.3778e-02, 8.7077e-03, 2.7950e-02, 1.2883e-02, 9.2365e-03, 6.9795e-03,\n",
       "         6.6233e-03, 1.1498e-01, 1.0733e-02, 4.4558e-02, 9.4973e-03, 5.9850e-03,\n",
       "         1.2613e-02, 3.8794e-02, 3.1595e-02, 1.7062e-02, 4.3104e-02, 1.3306e-02,\n",
       "         7.0166e-03, 4.2410e-03, 1.5413e-02, 1.9103e-02, 1.3217e-01, 3.1274e-02,\n",
       "         3.7809e+00, 5.1400e-03, 2.1077e-02, 5.9719e-03, 6.1026e-03, 4.5259e-02,\n",
       "         7.0378e-02, 1.3312e-02, 2.3274e-02, 1.1734e-01, 2.3130e-02, 2.3176e-02,\n",
       "         7.0860e-03, 7.6161e-02, 3.1890e-02, 7.4433e-03, 6.1434e-03, 9.5032e-03,\n",
       "         5.7414e-03, 1.7830e-02], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.4.layer.1.DenseReluDense.wi.weight': tensor([[4.0699e-11, 2.6062e-10, 1.5450e-11,  ..., 2.7958e-13, 4.4573e-12,\n",
       "          1.3637e-11],\n",
       "         [2.9533e-08, 2.5359e-08, 4.7604e-09,  ..., 1.2583e-08, 1.8780e-08,\n",
       "          2.1934e-08],\n",
       "         [1.2166e-10, 1.5798e-10, 3.6745e-11,  ..., 7.6186e-11, 5.2467e-12,\n",
       "          1.2189e-10],\n",
       "         ...,\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [4.5378e-09, 8.5908e-09, 1.1390e-08,  ..., 2.9576e-08, 6.0280e-09,\n",
       "          1.1493e-08],\n",
       "         [2.1456e-08, 8.2535e-09, 8.8031e-09,  ..., 8.1723e-09, 1.0061e-08,\n",
       "          3.1472e-08]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.4.layer.1.DenseReluDense.wo.weight': tensor([[2.1974e-11, 1.0265e-06, 8.7245e-10,  ..., 0.0000e+00, 8.7171e-09,\n",
       "          4.8954e-06],\n",
       "         [1.4812e-08, 2.9375e-08, 1.1080e-10,  ..., 0.0000e+00, 8.6193e-09,\n",
       "          1.0062e-06],\n",
       "         [1.7765e-08, 3.1364e-08, 8.1673e-11,  ..., 0.0000e+00, 6.5055e-08,\n",
       "          1.5111e-06],\n",
       "         ...,\n",
       "         [1.4486e-08, 5.4106e-07, 5.5335e-11,  ..., 0.0000e+00, 1.5099e-08,\n",
       "          6.5124e-08],\n",
       "         [4.3622e-08, 7.3501e-08, 6.9974e-11,  ..., 0.0000e+00, 1.9964e-08,\n",
       "          1.2080e-08],\n",
       "         [7.3217e-12, 1.3773e-07, 3.3917e-11,  ..., 0.0000e+00, 9.7574e-08,\n",
       "          1.7532e-08]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.4.layer.1.layer_norm.weight': tensor([1.9638e-04, 1.0931e-03, 1.3760e-03, 4.2833e-04, 4.8756e-04, 1.8939e-04,\n",
       "         1.3280e-04, 1.2298e-03, 1.1902e-04, 1.5307e-03, 7.4819e-05, 3.2952e-04,\n",
       "         5.2476e-04, 2.7139e-04, 2.0750e-04, 4.7987e-05, 1.6264e-04, 5.4594e-04,\n",
       "         1.2686e-04, 1.0857e-04, 1.6329e-04, 5.5836e-05, 9.4471e-04, 2.7730e-03,\n",
       "         1.9553e-05, 3.3047e-04, 1.7274e-04, 3.8447e-04, 2.9497e-04, 6.9871e-04,\n",
       "         2.1582e-04, 6.1925e-04, 9.8446e-04, 2.1949e-05, 3.4759e-04, 4.4381e-04,\n",
       "         2.2873e-04, 1.9114e-04, 1.3794e-03, 1.3262e-04, 1.6530e-04, 1.1411e-04,\n",
       "         4.0664e-04, 4.6486e-04, 1.7031e-03, 1.3601e-04, 3.5967e-04, 3.8920e-04,\n",
       "         1.3894e-04, 5.2666e-04, 3.0378e-04, 1.9421e-04, 7.1985e-04, 1.2785e-03,\n",
       "         1.5534e-03, 2.5644e-04, 9.1884e-05, 7.6615e-04, 8.6321e-04, 8.3214e-04,\n",
       "         1.1855e-04, 2.3703e-03, 4.3171e-04, 6.3882e-04, 9.4622e-04, 7.7295e-04,\n",
       "         1.1888e-03, 4.6950e-05, 1.1895e-03, 1.7194e-04, 1.2862e-03, 1.4559e-04,\n",
       "         6.6121e-05, 5.4852e-05, 2.1529e-04, 1.6171e-04, 1.4377e-05, 1.4423e-03,\n",
       "         2.3938e-04, 2.7041e-03, 4.1824e-04, 1.0207e-03, 9.6629e-05, 8.6479e-04,\n",
       "         2.5586e-04, 2.0847e-04, 4.1290e-05, 6.9740e-04, 9.1787e-05, 2.9614e-04,\n",
       "         3.0547e-04, 9.9289e-05, 1.1936e-04, 3.8347e-04, 2.5954e-04, 2.6692e-04,\n",
       "         6.3619e-05, 8.2688e-05, 3.9632e-04, 2.5970e-04, 4.3201e-04, 4.1278e-05,\n",
       "         1.1974e-03, 1.2145e-03, 2.2686e-04, 2.3241e-04, 1.0871e-04, 1.0481e-04,\n",
       "         8.5993e-04, 9.3341e-04, 9.4147e-04, 4.0064e-03, 8.1641e-05, 7.8206e-05,\n",
       "         4.5924e-04, 1.1486e-03, 9.1744e-04, 5.7430e-04, 2.4882e-04, 1.3533e-04,\n",
       "         4.0331e-04, 5.9482e-04, 6.7300e-05, 2.7107e-04, 1.9173e-04, 9.9130e-04,\n",
       "         7.5848e-04, 2.2312e-04, 5.5066e-03, 9.4390e-04, 2.4081e-04, 3.0734e-04,\n",
       "         4.6119e-04, 1.2263e-03, 2.8336e-04, 2.7439e-04, 1.9622e-04, 6.5641e-04,\n",
       "         1.4163e-04, 1.5167e-03, 1.8872e-04, 7.2203e-05, 3.6978e-03, 1.7700e-04,\n",
       "         2.2421e-04, 2.9005e-04, 3.4261e-04, 1.9755e-03, 1.8228e-04, 3.9224e-04,\n",
       "         3.9377e-05, 3.9505e-05, 4.4558e-04, 4.3943e-05, 5.2621e-05, 1.3928e-03,\n",
       "         5.2766e-05, 2.3495e-04, 1.0377e-03, 1.6114e-03, 7.1127e-05, 9.9936e-04,\n",
       "         2.5908e-05, 1.0575e-04, 2.2069e-04, 3.1547e-04, 4.2052e-03, 2.1377e-04,\n",
       "         7.8741e-05, 2.5316e-04, 9.0705e-05, 4.6862e-04, 6.4561e-04, 1.2135e-03,\n",
       "         3.4877e-04, 8.4487e-05, 1.3365e-04, 2.2947e-04, 2.2018e-04, 2.4719e-04,\n",
       "         5.2393e-05, 2.5341e-04, 8.9852e-04, 4.9380e-04, 1.1471e-03, 1.5256e-04,\n",
       "         3.5201e-04, 1.3862e-04, 6.0267e-04, 2.3885e-04, 5.5010e-04, 1.1044e-03,\n",
       "         1.0088e-03, 6.3749e-04, 3.8644e-04, 6.5589e-05, 7.0010e-05, 1.0613e-03,\n",
       "         1.4630e-04, 1.6104e-04, 5.6990e-04, 4.6383e-04, 5.1734e-04, 1.4368e-03,\n",
       "         1.8251e-04, 2.0249e-04, 2.1502e-03, 7.0971e-05, 4.5733e-04, 6.0378e-04,\n",
       "         1.7168e-04, 1.0314e-04, 9.8984e-04, 7.2459e-04, 1.9910e-04, 1.9573e-04,\n",
       "         7.3936e-04, 4.6284e-04, 5.1627e-03, 4.3276e-05, 6.1164e-05, 1.4667e-04,\n",
       "         1.1213e-03, 5.3138e-05, 3.8804e-04, 1.0025e-04, 5.4555e-04, 6.2374e-05,\n",
       "         1.5872e-03, 5.5552e-04, 1.9977e-04, 2.2127e-04, 4.7062e-04, 6.3376e-04,\n",
       "         1.6635e-03, 5.1967e-04, 2.8563e-04, 8.7350e-04, 1.2484e-04, 5.6963e-04,\n",
       "         3.1585e-04, 3.2796e-03, 4.4206e-04, 5.9177e-05, 1.1266e-04, 5.0085e-04,\n",
       "         9.2016e-03, 9.9968e-04, 3.6966e-04, 4.3419e-03, 5.4166e-04, 4.5405e-04,\n",
       "         1.0074e-03, 1.1855e-04, 9.5949e-04, 5.8509e-04, 1.0342e-03, 3.5754e-04,\n",
       "         8.5927e-04, 5.8103e-03, 4.4540e-03, 4.4713e-04, 1.9217e-04, 2.4893e-04,\n",
       "         1.0346e-03, 5.1348e-05, 7.1667e-05, 2.4314e-04, 7.7660e-05, 2.5072e-04,\n",
       "         2.4705e-04, 3.1604e-04, 3.4897e-04, 9.3251e-04, 8.4781e-05, 6.9839e-04,\n",
       "         1.8280e-04, 1.0656e-04, 2.5969e-04, 2.5750e-04, 1.9796e-04, 4.5050e-04,\n",
       "         1.0739e-04, 1.6380e-04, 3.2230e-04, 2.7400e-04, 5.6696e-04, 3.1815e-04,\n",
       "         6.5871e-05, 3.8624e-03, 3.9196e-04, 3.0031e-04, 1.7211e-04, 4.1935e-04,\n",
       "         3.3735e-04, 1.1254e-03, 1.2326e-03, 7.8052e-05, 1.7536e-04, 2.3571e-04,\n",
       "         3.4874e-04, 4.2579e-04, 6.5667e-04, 2.2752e-04, 5.7008e-04, 2.6138e-04,\n",
       "         2.3880e-03, 1.4194e-04, 1.4492e-03, 1.9139e-04, 4.2455e-04, 1.2239e-04,\n",
       "         1.1715e-03, 2.9175e-04, 4.9770e-04, 1.0471e-04, 4.6282e-05, 7.7189e-05,\n",
       "         1.3216e-03, 1.1861e-03, 2.2739e-04, 6.3760e-05, 3.2123e-04, 4.3549e-03,\n",
       "         1.1051e-03, 1.2275e-04, 3.3442e-04, 2.0468e-04, 4.7372e-05, 1.8280e-04,\n",
       "         1.6248e-04, 7.6832e-04, 4.1469e-04, 1.7440e-04, 1.4057e-04, 4.2572e-03,\n",
       "         6.8068e-04, 8.0717e-05, 4.7507e-05, 1.3211e-03, 7.8248e-04, 4.4872e-05,\n",
       "         8.9996e-04, 3.7274e-04, 1.5276e-04, 2.0081e-04, 8.7908e-04, 3.3105e-04,\n",
       "         1.9098e-04, 1.0455e-03, 6.1042e-04, 7.2434e-05, 1.3025e-04, 8.7727e-05,\n",
       "         8.7440e-04, 1.4676e-03, 5.9067e-05, 1.0324e-04, 8.4099e-05, 4.5157e-04,\n",
       "         7.1454e-04, 2.0317e-04, 4.8976e-04, 1.2656e-04, 1.8323e-04, 1.5469e-04,\n",
       "         5.4981e-04, 1.0898e-04, 3.8916e-04, 3.4021e-05, 1.4458e-04, 1.0071e-03,\n",
       "         3.7924e-05, 9.4015e-05, 8.1584e-04, 4.3946e-05, 4.1034e-04, 2.4103e-04,\n",
       "         1.6436e-04, 4.8734e-04, 2.6093e-04, 8.1365e-04, 6.2644e-04, 7.0398e-04,\n",
       "         6.1384e-04, 5.1703e-04, 4.9840e-04, 3.4240e-04, 4.0376e-03, 4.3617e-05,\n",
       "         2.3042e-04, 1.9402e-04, 7.3347e-04, 7.7189e-05, 9.8945e-05, 1.8447e-03,\n",
       "         7.4594e-04, 2.3978e-02, 8.2657e-05, 3.0305e-04, 8.5607e-04, 8.2317e-04,\n",
       "         4.0292e-04, 1.0671e-03, 1.8699e-04, 3.5871e-04, 2.3748e-04, 1.1286e-04,\n",
       "         6.3281e-05, 4.6797e-05, 4.8202e-03, 2.3327e-04, 4.3926e-04, 1.9270e-03,\n",
       "         2.4185e-04, 2.2006e-03, 1.3858e-04, 2.4923e-04, 2.7626e-04, 5.0487e-04,\n",
       "         2.4534e-04, 4.3344e-04, 2.8374e-02, 2.5349e-05, 7.4830e-04, 6.3003e-05,\n",
       "         4.5273e-05, 1.8045e-04, 1.1495e-04, 4.0234e-04, 3.5556e-04, 4.4452e-04,\n",
       "         6.7115e-05, 6.8710e-03, 7.1691e-05, 8.9234e-05, 6.8076e-04, 1.1798e-03,\n",
       "         1.1956e-04, 1.0936e-03, 7.4377e-05, 8.3396e-05, 5.3629e-04, 1.8209e-04,\n",
       "         1.6335e-04, 9.0028e-05, 1.2406e-04, 4.1641e-04, 8.6669e-05, 1.9440e-04,\n",
       "         4.4508e-04, 1.2642e-04, 1.0896e-03, 3.1101e-03, 4.3609e-04, 3.9673e-04,\n",
       "         1.7799e-04, 1.9120e-04, 4.2700e-04, 8.8556e-04, 5.9045e-04, 4.6022e-03,\n",
       "         1.2068e-04, 9.6361e-04, 3.8542e-04, 3.3814e-04, 3.8910e-05, 5.3586e-04,\n",
       "         3.4695e-04, 1.7244e-03, 3.6409e-04, 7.0803e-05, 5.7309e-04, 3.9122e-04,\n",
       "         3.7168e-04, 8.0742e-04, 1.2508e-04, 2.8093e-04, 8.1259e-05, 1.8081e-04,\n",
       "         1.5075e-03, 2.3569e-04, 9.6237e-05, 3.6639e-04, 5.2615e-04, 2.8850e-04,\n",
       "         6.3495e-04, 1.0402e-04, 1.9990e-04, 1.0999e-04, 9.9440e-04, 1.0240e-04,\n",
       "         2.4820e-02, 6.9660e-04, 5.4505e-05, 9.2616e-04, 2.7744e-05, 7.6371e-04,\n",
       "         4.6593e-04, 1.2660e-03, 2.2512e-02, 2.0590e-04, 1.5261e-03, 6.7304e-05,\n",
       "         6.8875e-05, 4.6374e-04, 2.6517e-03, 1.4618e-04, 3.1063e-04, 1.8333e-04,\n",
       "         1.6658e-04, 1.8889e-03], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.5.layer.0.SelfAttention.q.weight': tensor([[1.4229e-05, 7.0823e-05, 5.1923e-05,  ..., 1.8446e-05, 2.8529e-05,\n",
       "          2.4420e-05],\n",
       "         [2.8581e-05, 1.3444e-05, 1.4603e-05,  ..., 1.6300e-05, 2.1353e-05,\n",
       "          6.9565e-05],\n",
       "         [9.3171e-05, 1.1958e-04, 3.3512e-04,  ..., 2.4270e-04, 1.0590e-04,\n",
       "          4.4666e-04],\n",
       "         ...,\n",
       "         [1.5433e-04, 5.4465e-05, 1.0970e-05,  ..., 2.9898e-05, 2.1423e-05,\n",
       "          3.6022e-05],\n",
       "         [1.2828e-05, 2.2369e-05, 4.8216e-05,  ..., 3.6865e-05, 5.6802e-06,\n",
       "          6.2389e-05],\n",
       "         [1.4270e-04, 7.7788e-05, 8.4948e-06,  ..., 6.5440e-05, 1.4506e-05,\n",
       "          5.5020e-05]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.5.layer.0.SelfAttention.k.weight': tensor([[5.2349e-07, 4.3187e-07, 8.9297e-07,  ..., 9.3635e-07, 1.1095e-06,\n",
       "          4.4639e-07],\n",
       "         [1.9911e-07, 1.1986e-06, 1.6507e-07,  ..., 5.6012e-07, 1.7016e-07,\n",
       "          3.8127e-07],\n",
       "         [2.9211e-06, 2.6308e-06, 4.5946e-06,  ..., 7.6008e-06, 8.3934e-06,\n",
       "          2.0718e-06],\n",
       "         ...,\n",
       "         [4.6644e-06, 2.0091e-06, 1.7371e-07,  ..., 4.9263e-07, 9.9493e-07,\n",
       "          1.0756e-07],\n",
       "         [4.7235e-07, 1.0283e-06, 5.1704e-07,  ..., 3.4978e-07, 2.2807e-07,\n",
       "          1.2680e-07],\n",
       "         [6.4115e-07, 9.3283e-07, 3.3942e-06,  ..., 7.3107e-07, 1.9875e-07,\n",
       "          3.5959e-07]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.5.layer.0.SelfAttention.v.weight': tensor([[1.1145e-07, 2.7471e-07, 9.4587e-07,  ..., 5.8077e-08, 7.4217e-07,\n",
       "          1.2555e-06],\n",
       "         [2.9902e-07, 1.7900e-07, 1.0837e-07,  ..., 2.7458e-07, 3.8466e-07,\n",
       "          5.0198e-07],\n",
       "         [1.9814e-07, 2.4811e-07, 2.6873e-07,  ..., 8.0796e-08, 1.5823e-07,\n",
       "          5.8910e-07],\n",
       "         ...,\n",
       "         [2.3100e-07, 1.3764e-06, 4.3375e-07,  ..., 1.9342e-07, 8.0310e-08,\n",
       "          2.3740e-07],\n",
       "         [7.7652e-08, 2.7069e-06, 3.1469e-07,  ..., 1.4094e-06, 2.3299e-08,\n",
       "          1.6770e-06],\n",
       "         [1.2818e-07, 1.2333e-06, 6.2379e-08,  ..., 6.4727e-07, 1.1199e-07,\n",
       "          7.9464e-07]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.5.layer.0.SelfAttention.o.weight': tensor([[8.7376e-08, 1.4723e-07, 3.5612e-07,  ..., 1.4021e-07, 8.7072e-08,\n",
       "          3.5186e-07],\n",
       "         [1.5640e-07, 2.2579e-07, 1.6195e-06,  ..., 1.9605e-08, 1.8022e-07,\n",
       "          7.0426e-07],\n",
       "         [1.2111e-07, 1.2853e-07, 8.4824e-08,  ..., 1.7639e-08, 3.8524e-08,\n",
       "          9.6420e-08],\n",
       "         ...,\n",
       "         [3.1293e-07, 1.0724e-07, 1.7765e-06,  ..., 2.7927e-07, 5.8810e-07,\n",
       "          1.5863e-06],\n",
       "         [2.4068e-07, 1.2690e-07, 1.3082e-06,  ..., 1.3350e-07, 1.9097e-07,\n",
       "          5.5037e-07],\n",
       "         [4.1959e-08, 1.0087e-07, 2.9817e-07,  ..., 5.0462e-08, 4.9658e-08,\n",
       "          1.6556e-08]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.5.layer.0.layer_norm.weight': tensor([5.4316e-02, 1.7323e-02, 8.9836e-02, 8.5331e-02, 1.7445e-02, 1.9723e-02,\n",
       "         1.1895e-02, 3.5817e-02, 2.4415e-02, 1.1908e-02, 9.3767e-02, 1.1937e-01,\n",
       "         9.3830e-02, 4.9723e-03, 1.7965e-02, 9.3701e-03, 1.3870e-01, 1.8816e-01,\n",
       "         1.1036e-02, 1.4413e-02, 9.2730e-03, 2.8760e-02, 2.0877e-01, 2.5219e-02,\n",
       "         1.7248e-02, 2.2645e-02, 2.6289e-02, 2.2511e-02, 8.9439e-03, 5.3915e+01,\n",
       "         4.9661e-03, 5.6528e-02, 1.3382e-01, 2.6377e-02, 3.1052e-02, 2.3494e-01,\n",
       "         3.5144e-02, 2.8668e-02, 1.9771e-01, 6.3887e-02, 1.5278e-02, 7.8339e-03,\n",
       "         1.0714e+00, 8.4963e-02, 2.4717e-02, 8.3617e-03, 5.2484e-02, 3.1202e-03,\n",
       "         7.6354e-02, 4.3104e-02, 1.5427e-01, 2.4316e-02, 9.9315e-03, 9.7985e-02,\n",
       "         6.3325e-02, 2.1061e-02, 6.0085e-02, 3.9641e-02, 3.4771e-02, 4.6463e-03,\n",
       "         2.9615e-02, 1.7152e+00, 2.8611e-01, 3.5411e-02, 1.5987e-01, 9.5424e-02,\n",
       "         1.6140e-02, 1.8154e-02, 7.7386e-02, 4.4091e-02, 3.2518e-02, 1.9157e-02,\n",
       "         1.9600e-02, 1.5729e-02, 4.7943e-03, 1.4510e-02, 2.1923e-02, 2.6490e-02,\n",
       "         2.6931e-02, 1.1665e-01, 1.7209e-01, 1.9052e-01, 8.5965e-02, 2.9731e-03,\n",
       "         1.3812e-02, 1.9037e-02, 6.8752e-03, 1.1795e-01, 1.5286e-02, 3.8061e-02,\n",
       "         4.5379e-03, 2.6038e-02, 2.0082e-02, 3.1856e-02, 7.4281e-02, 9.2807e-03,\n",
       "         9.4074e-02, 1.3197e-02, 1.0212e-01, 3.3637e-02, 4.8046e-02, 2.1500e-02,\n",
       "         3.0959e-02, 1.5210e-02, 2.4268e-02, 5.0617e-02, 1.6932e-02, 3.5998e-02,\n",
       "         1.8528e-01, 3.9975e-02, 2.6572e-02, 5.8759e-02, 2.2146e-02, 2.5645e-03,\n",
       "         1.1889e-02, 1.2356e-01, 1.3648e-02, 4.3361e-02, 1.8831e-02, 8.0315e-02,\n",
       "         2.8248e-03, 1.8559e-02, 3.4160e-02, 3.4912e-02, 1.4844e-03, 3.0691e-02,\n",
       "         9.3667e-02, 1.7835e-02, 3.2795e+01, 3.4500e-02, 7.6416e-02, 5.4699e-02,\n",
       "         3.3596e-02, 2.7238e-01, 1.0467e-01, 1.1940e-01, 2.4649e+00, 1.2769e-02,\n",
       "         1.0527e-01, 9.2026e-03, 9.3841e-02, 4.6408e-03, 4.1179e-01, 5.8443e-02,\n",
       "         1.2461e-02, 5.9616e-02, 7.3071e-02, 7.6806e-01, 1.4772e-02, 2.7791e-01,\n",
       "         1.4777e-02, 1.1919e-02, 2.3423e-02, 4.3526e-03, 2.5645e-02, 9.7595e-03,\n",
       "         9.2520e-03, 1.1905e-02, 2.2700e-02, 8.0995e-02, 4.1558e-02, 5.6137e-02,\n",
       "         9.6925e-02, 8.5115e-02, 6.5949e-02, 2.5694e-03, 3.5496e-01, 1.0835e-02,\n",
       "         6.7813e-03, 3.2439e-02, 9.6587e-02, 2.8341e-02, 3.7183e-03, 1.8958e-02,\n",
       "         2.0313e-02, 1.7041e-02, 1.4453e-02, 1.6806e-01, 1.3134e-02, 3.2500e-03,\n",
       "         6.3729e-03, 4.7759e-02, 8.0207e-02, 1.2369e-01, 7.0616e-02, 7.7888e-03,\n",
       "         6.4204e-02, 1.2560e-02, 4.2296e-02, 1.6901e-02, 1.8290e-02, 3.7844e-01,\n",
       "         6.6693e-02, 3.0131e-02, 2.3261e-02, 1.7778e-02, 9.8878e-03, 2.8581e-02,\n",
       "         1.5242e-02, 6.4201e-03, 6.8830e-01, 7.0387e-02, 2.9820e-01, 4.3769e+00,\n",
       "         7.8534e-03, 3.2020e-02, 5.3151e-02, 4.1444e-02, 1.9892e-01, 5.7280e-02,\n",
       "         7.0557e-03, 1.4216e-02, 1.5167e-02, 1.2859e-02, 5.6892e-03, 1.8602e-02,\n",
       "         7.5568e-03, 1.2580e-01, 1.5082e-01, 2.5527e-02, 2.9381e-02, 6.3052e-03,\n",
       "         1.0548e-01, 2.0055e-01, 6.1275e-02, 4.9829e-02, 1.2978e-02, 2.4380e-02,\n",
       "         5.6313e-02, 4.4543e-02, 3.0387e-02, 2.1485e-02, 2.2416e-01, 2.1721e-01,\n",
       "         4.2893e-02, 6.9047e-02, 1.8293e-01, 2.2806e-02, 6.0104e-03, 1.9176e-02,\n",
       "         1.9085e-02, 2.1700e-02, 5.5778e-02, 1.5512e-02, 3.3699e-02, 4.5972e-02,\n",
       "         1.9807e-01, 5.5369e-02, 7.0655e-03, 4.3443e-02, 2.8102e-02, 8.4810e-03,\n",
       "         7.1386e-02, 4.5379e-02, 1.3693e-02, 4.1442e-02, 3.5205e-02, 5.1527e-02,\n",
       "         7.1721e-02, 3.2901e-02, 2.2869e+01, 3.0800e-02, 6.4207e-02, 7.6504e-02,\n",
       "         1.4203e-01, 6.7254e-03, 1.8779e-02, 4.6169e-03, 1.7464e-02, 7.3626e-03,\n",
       "         3.5458e-02, 5.7649e-02, 1.1323e-01, 2.4093e-02, 1.3743e-02, 1.4756e+01,\n",
       "         2.5530e-02, 4.9902e-03, 1.1531e-02, 2.5752e-02, 3.0335e-01, 3.1245e-02,\n",
       "         1.1987e-02, 5.2738e-02, 5.1218e-03, 1.6370e-02, 3.0270e-02, 3.2874e-02,\n",
       "         1.6190e-02, 1.6596e-01, 1.6341e-02, 4.0798e-03, 5.7013e-02, 1.3633e-01,\n",
       "         2.1151e-02, 2.3535e-02, 4.0404e-02, 2.1470e-02, 6.7902e-03, 1.1485e-01,\n",
       "         5.1370e-02, 3.3537e-02, 3.5906e-02, 2.6376e-02, 4.3671e-02, 5.3218e-02,\n",
       "         4.1251e-02, 2.6614e-02, 1.0694e-01, 1.7697e-02, 6.8748e-03, 6.1082e-03,\n",
       "         4.8303e-01, 2.3389e-02, 1.4162e-01, 1.1500e-02, 3.2429e-03, 5.9433e-02,\n",
       "         4.4610e-01, 6.1253e-02, 4.5239e-03, 1.9548e-02, 2.7228e-02, 2.7473e-01,\n",
       "         1.9540e-01, 2.0354e-03, 3.6300e-02, 1.0640e-02, 8.7927e-03, 1.2679e-02,\n",
       "         2.1516e-01, 6.9129e-02, 8.1329e-02, 1.7378e-02, 7.9014e-03, 4.3728e-02,\n",
       "         1.4129e-01, 2.3714e-02, 1.3666e-02, 2.3995e+00, 1.3059e-01, 2.4314e-02,\n",
       "         4.3257e-03, 1.8842e-01, 2.2030e-02, 4.9917e-02, 1.3548e-01, 9.8352e-03,\n",
       "         2.3178e-02, 8.7815e-02, 5.0806e-02, 1.5083e-02, 8.8395e-03, 2.3094e-02,\n",
       "         4.2288e-02, 1.6334e-01, 3.7394e-02, 1.0497e-02, 6.8353e-03, 2.5888e-02,\n",
       "         2.9748e-02, 4.4991e-03, 3.4918e-02, 1.6518e-02, 1.5376e-02, 8.9220e-02,\n",
       "         4.8015e-02, 1.0016e-02, 7.4016e-02, 8.2784e-03, 1.0565e-01, 2.2788e-01,\n",
       "         2.7200e-02, 2.3148e-02, 5.6871e-02, 1.6285e-02, 1.4401e-01, 1.6948e-02,\n",
       "         3.3017e-02, 5.4394e-02, 9.2913e-02, 5.9066e-02, 6.8578e-02, 8.9499e-03,\n",
       "         3.0133e-02, 7.8623e-03, 1.2009e-01, 8.1470e-03, 3.2220e-01, 7.5990e-02,\n",
       "         3.4146e-02, 1.0626e-01, 9.5950e-02, 7.3132e-02, 1.7354e-01, 6.0073e-02,\n",
       "         2.1795e-01, 7.0613e-01, 1.2395e-02, 7.2322e-02, 2.3829e-02, 2.9851e-02,\n",
       "         6.3737e-02, 7.2516e-03, 3.7316e-02, 2.9762e-01, 6.4400e-03, 7.2540e-02,\n",
       "         5.8406e-03, 1.5776e-02, 1.2072e-01, 4.2302e-02, 9.4041e-03, 4.6836e-01,\n",
       "         2.3012e-02, 2.3941e-01, 1.7781e-02, 1.1227e-02, 2.0983e-02, 4.3121e-03,\n",
       "         6.3220e-03, 1.4498e-02, 2.9933e+00, 6.0507e-03, 4.1962e-01, 1.8824e-03,\n",
       "         1.2488e-02, 8.1377e-02, 1.4604e-02, 1.8377e-01, 1.4570e-01, 1.5746e-02,\n",
       "         2.3453e-02, 3.3610e+01, 1.5310e-02, 2.1485e-02, 6.7423e-02, 4.1637e-02,\n",
       "         7.4243e-03, 2.0471e-02, 6.4779e-03, 1.6891e-02, 2.1239e-02, 4.1530e-02,\n",
       "         5.2100e-03, 1.1154e-01, 1.3908e-02, 2.0426e-01, 2.1793e-02, 5.6843e-03,\n",
       "         3.0488e-02, 3.0521e-02, 1.0687e-01, 1.4859e-01, 1.0107e-01, 1.4457e-01,\n",
       "         1.4910e-02, 1.2139e-01, 1.4772e-02, 6.3381e-02, 1.7113e-01, 5.9237e-02,\n",
       "         1.1300e-01, 3.3794e-02, 7.2198e-02, 1.3938e-02, 1.6754e-02, 7.6216e-03,\n",
       "         6.5117e-02, 1.1577e-01, 1.1312e-02, 4.3530e-02, 4.3354e-03, 3.4950e-02,\n",
       "         4.2263e-02, 1.5417e-01, 2.2262e-02, 5.3678e-02, 2.8120e-02, 7.2867e-02,\n",
       "         5.2506e-02, 1.2905e-02, 5.3278e-02, 1.8503e-02, 4.8151e-02, 9.6960e-03,\n",
       "         5.4868e-02, 1.1489e-01, 2.5502e-02, 1.4607e-02, 1.9526e-01, 5.7616e-03,\n",
       "         5.4265e+00, 1.6093e-02, 2.5155e-02, 7.7547e-02, 1.3398e-02, 4.9722e-02,\n",
       "         6.9529e-02, 7.6835e-03, 1.3198e+00, 1.2182e-01, 6.7405e-02, 2.3171e-01,\n",
       "         4.0663e-02, 2.2564e-01, 1.2842e-01, 6.5832e-03, 8.3053e-03, 1.1492e-02,\n",
       "         3.3964e-02, 1.4790e-02], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.5.layer.1.DenseReluDense.wi.weight': tensor([[1.9014e-07, 1.3998e-06, 5.6310e-08,  ..., 4.4960e-08, 1.7011e-07,\n",
       "          9.5814e-07],\n",
       "         [6.6683e-13, 4.6125e-12, 3.4546e-15,  ..., 1.4763e-11, 1.2938e-12,\n",
       "          7.2507e-13],\n",
       "         [5.8755e-08, 1.3137e-08, 2.0943e-08,  ..., 5.9168e-09, 7.0168e-09,\n",
       "          3.7132e-08],\n",
       "         ...,\n",
       "         [1.3885e-13, 3.9276e-14, 2.1410e-14,  ..., 7.3267e-14, 1.1925e-13,\n",
       "          2.0930e-12],\n",
       "         [7.1422e-09, 8.1360e-10, 2.1060e-10,  ..., 8.3775e-10, 1.6930e-10,\n",
       "          4.0705e-11],\n",
       "         [1.2887e-12, 3.8454e-11, 4.4608e-12,  ..., 7.1112e-13, 2.6761e-12,\n",
       "          4.8516e-12]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.5.layer.1.DenseReluDense.wo.weight': tensor([[4.0355e-09, 4.8674e-14, 1.2055e-09,  ..., 5.7460e-14, 5.3544e-10,\n",
       "          1.1166e-11],\n",
       "         [2.3550e-08, 8.2190e-17, 8.4484e-09,  ..., 3.6366e-16, 1.2247e-10,\n",
       "          2.9571e-13],\n",
       "         [2.4139e-07, 1.1503e-13, 2.7943e-08,  ..., 1.4558e-16, 7.8664e-10,\n",
       "          1.0634e-11],\n",
       "         ...,\n",
       "         [1.9581e-08, 3.2153e-15, 1.9256e-08,  ..., 9.9619e-14, 1.9105e-11,\n",
       "          6.9468e-15],\n",
       "         [5.7496e-08, 1.3445e-14, 8.9506e-10,  ..., 5.9581e-14, 8.7233e-11,\n",
       "          8.6249e-13],\n",
       "         [3.3980e-08, 3.3078e-14, 6.3644e-09,  ..., 3.9839e-14, 1.1071e-10,\n",
       "          3.8333e-13]], device='cuda:0', requires_grad=True),\n",
       " 'encoder.block.5.layer.1.layer_norm.weight': tensor([3.0242e-03, 2.7939e-03, 1.9748e-04, 1.0076e-02, 2.5104e-03, 8.8802e-05,\n",
       "         2.6864e-04, 5.9392e-03, 1.8317e-03, 7.4212e-05, 1.4050e-04, 2.0214e-04,\n",
       "         6.4814e-04, 3.6287e-04, 1.1727e-03, 3.2404e-04, 6.0191e-05, 4.9405e-03,\n",
       "         1.3047e-03, 6.6629e-04, 4.7687e-04, 1.9950e-04, 1.2260e-03, 1.7357e-03,\n",
       "         1.7644e-03, 9.8948e-04, 8.1632e-04, 9.7218e-04, 1.9121e-04, 6.7105e-03,\n",
       "         2.6941e-04, 6.1209e-04, 4.3759e-04, 5.3912e-05, 4.1873e-04, 2.4196e-04,\n",
       "         6.6464e-04, 2.2862e-04, 1.9059e-03, 6.1284e-04, 8.5225e-04, 2.6275e-04,\n",
       "         9.0847e-04, 1.6056e-03, 2.1891e-03, 2.1632e-03, 1.2692e-03, 1.0172e-03,\n",
       "         9.9447e-04, 9.9117e-05, 5.7570e-04, 1.0995e-03, 3.6004e-04, 1.0427e-02,\n",
       "         1.1331e-03, 6.8994e-05, 8.4640e-04, 2.1427e-04, 1.1422e-04, 2.9281e-03,\n",
       "         5.5867e-05, 2.0464e-03, 1.6060e-03, 1.3376e-04, 1.3775e-03, 2.8205e-04,\n",
       "         3.6310e-04, 3.0233e-04, 8.7626e-04, 4.1894e-03, 7.3608e-04, 4.0680e-04,\n",
       "         4.0526e-04, 3.8882e-04, 1.5897e-04, 8.0802e-04, 1.4803e-04, 2.1814e-04,\n",
       "         3.9002e-04, 3.2643e-03, 5.9125e-03, 4.8138e-04, 2.3524e-04, 3.3523e-04,\n",
       "         6.2171e-04, 1.9215e-03, 4.8172e-04, 1.1177e-03, 1.7155e-04, 9.4519e-04,\n",
       "         3.5033e-04, 6.1184e-04, 3.3527e-04, 3.4143e-04, 3.6841e-04, 1.0870e-04,\n",
       "         5.7001e-04, 9.9572e-04, 4.8789e-04, 3.6729e-04, 2.0446e-04, 1.3796e-03,\n",
       "         2.1223e-03, 3.1883e-04, 1.0323e-04, 3.8830e-04, 3.5087e-04, 1.9634e-04,\n",
       "         2.2618e-02, 7.4133e-04, 7.1157e-04, 4.3227e-04, 1.3779e-03, 1.0050e-04,\n",
       "         2.3950e-04, 1.1984e-03, 3.7297e-04, 2.2634e-04, 1.3099e-04, 2.1335e-04,\n",
       "         6.6534e-05, 1.6634e-04, 1.8769e-04, 1.4906e-04, 4.6886e-05, 8.3709e-04,\n",
       "         4.8963e-03, 7.3496e-05, 1.5948e-02, 2.0650e-04, 9.0144e-04, 2.3253e-04,\n",
       "         1.3666e-03, 1.6873e-03, 1.5521e-03, 8.4277e-05, 1.2779e-02, 1.5647e-03,\n",
       "         3.9419e-03, 4.9186e-04, 1.4304e-04, 2.3954e-04, 6.5360e-03, 4.7606e-04,\n",
       "         4.0928e-04, 6.1161e-04, 4.5653e-04, 7.9773e-03, 2.0320e-04, 2.9903e-04,\n",
       "         2.7827e-04, 2.9501e-05, 1.7012e-03, 1.2712e-04, 3.4123e-04, 4.3222e-04,\n",
       "         9.2504e-05, 2.9595e-03, 4.5119e-05, 1.8244e-03, 1.7642e-04, 2.0129e-03,\n",
       "         4.5993e-05, 2.1390e-04, 1.0945e-02, 1.0220e-03, 3.0176e-03, 9.3056e-05,\n",
       "         9.3699e-05, 1.0463e-04, 2.3050e-03, 1.5192e-04, 2.1654e-04, 1.7550e-04,\n",
       "         1.4085e-04, 9.8167e-04, 3.8935e-04, 1.3809e-03, 2.3335e-04, 1.0177e-04,\n",
       "         8.3495e-05, 1.0944e-04, 3.4617e-04, 1.2560e-03, 4.5047e-03, 2.4852e-03,\n",
       "         1.4284e-04, 1.6604e-03, 1.4916e-03, 1.7522e-03, 6.6272e-04, 2.4549e-02,\n",
       "         5.1672e-04, 6.2992e-04, 2.2709e-04, 6.9317e-05, 6.9668e-05, 4.1377e-03,\n",
       "         1.1837e-04, 2.0413e-04, 9.0416e-03, 7.3421e-04, 1.0919e-03, 1.2645e-03,\n",
       "         1.0777e-03, 2.8195e-04, 8.7863e-03, 5.6243e-04, 2.0904e-03, 2.3438e-04,\n",
       "         1.9695e-04, 1.7868e-04, 7.0825e-04, 3.5826e-03, 9.6422e-05, 3.1030e-04,\n",
       "         7.8524e-04, 4.0515e-04, 7.3156e-03, 1.6367e-04, 1.4317e-03, 8.8366e-05,\n",
       "         3.7320e-04, 3.4615e-04, 4.2558e-04, 1.5335e-04, 6.7689e-05, 7.0981e-05,\n",
       "         6.1422e-03, 4.7573e-04, 9.3261e-04, 1.7915e-04, 1.1202e-03, 3.2804e-04,\n",
       "         2.3302e-03, 8.0414e-04, 1.6570e-02, 2.3238e-04, 2.5258e-04, 1.0584e-03,\n",
       "         6.0083e-04, 2.7451e-03, 1.5576e-04, 6.8870e-05, 3.3892e-04, 3.4110e-03,\n",
       "         4.2464e-02, 7.3480e-03, 9.3264e-04, 2.7899e-04, 1.1763e-04, 2.7259e-04,\n",
       "         1.0613e-03, 3.7352e-04, 3.7767e-05, 1.8641e-03, 2.4162e-04, 2.2468e-04,\n",
       "         5.5030e-04, 1.4243e-03, 6.9801e-03, 3.0471e-05, 3.6506e-05, 4.2387e-04,\n",
       "         1.7664e-03, 8.4372e-05, 1.4004e-03, 1.5814e-04, 4.6203e-04, 8.9320e-04,\n",
       "         1.2768e-04, 4.7762e-03, 1.8924e-03, 2.8701e-03, 3.6616e-04, 6.9098e-04,\n",
       "         2.4251e-04, 1.3384e-04, 2.7973e-04, 2.0306e-04, 1.7628e-04, 4.7692e-04,\n",
       "         4.3224e-04, 7.9829e-04, 3.5112e-04, 7.5373e-04, 2.3654e-04, 5.7370e-03,\n",
       "         2.2764e-04, 5.6062e-04, 1.6087e-03, 1.9147e-04, 1.8263e-04, 3.6500e-04,\n",
       "         1.9534e-03, 1.7200e-04, 3.8458e-04, 4.0639e-04, 1.4010e-04, 6.6678e-04,\n",
       "         2.9673e-03, 1.1797e-03, 2.9543e-03, 3.2453e-04, 1.2561e-04, 1.6163e-04,\n",
       "         1.6353e-04, 4.9583e-03, 2.0417e-04, 1.5458e-03, 4.3133e-04, 2.8676e-04,\n",
       "         5.6936e-03, 8.2902e-05, 1.5259e-04, 2.8334e-04, 1.2097e-04, 1.2988e-04,\n",
       "         6.1069e-04, 5.4387e-03, 4.8355e-04, 3.3760e-04, 5.0823e-05, 1.8672e-03,\n",
       "         7.8529e-04, 9.7806e-05, 2.7660e-04, 2.6291e-04, 1.1231e-04, 3.1708e-04,\n",
       "         1.6044e-03, 2.6525e-03, 2.7942e-04, 5.4679e-04, 1.1713e-04, 7.5049e-04,\n",
       "         5.6931e-04, 4.1840e-05, 2.7001e-04, 2.2394e-03, 1.2126e-03, 1.9787e-04,\n",
       "         1.8411e-04, 3.9473e-03, 2.0455e-04, 2.7479e-04, 4.5324e-04, 1.7510e-04,\n",
       "         1.5597e-04, 1.1283e-03, 4.5990e-03, 1.0861e-04, 1.1449e-04, 3.6969e-04,\n",
       "         1.9482e-04, 3.0302e-03, 7.5732e-04, 1.3590e-04, 3.6630e-04, 1.2254e-04,\n",
       "         5.8312e-03, 1.4473e-04, 1.2905e-03, 1.9486e-04, 2.1310e-03, 3.4057e-04,\n",
       "         1.8139e-04, 1.0722e-03, 9.8192e-05, 1.8923e-04, 5.3769e-04, 4.7979e-03,\n",
       "         5.7940e-04, 2.0876e-04, 1.9377e-04, 1.0626e-04, 1.3643e-04, 4.0549e-04,\n",
       "         1.3528e-04, 9.1040e-04, 9.4512e-05, 2.7002e-03, 9.5280e-04, 3.9084e-04,\n",
       "         7.6738e-04, 5.6879e-04, 1.6047e-03, 1.1084e-04, 7.4564e-04, 1.3986e-04,\n",
       "         4.0954e-05, 2.8858e-03, 8.6685e-04, 1.0616e-04, 1.1328e-03, 2.3907e-03,\n",
       "         2.1314e-03, 6.4741e-03, 1.5133e-04, 3.3685e-03, 1.7321e-04, 3.0762e-04,\n",
       "         2.0433e-04, 2.8204e-04, 1.8481e-04, 7.9969e-04, 2.7849e-04, 6.8195e-05,\n",
       "         3.0824e-05, 4.5560e-04, 1.2246e-03, 1.9615e-03, 1.3056e-03, 9.7919e-03,\n",
       "         4.4115e-04, 9.3673e-04, 1.4007e-03, 4.3595e-04, 1.9497e-04, 3.1801e-04,\n",
       "         3.9953e-04, 4.0893e-04, 1.1520e-02, 1.2234e-04, 5.9312e-03, 5.4491e-05,\n",
       "         4.7777e-05, 1.0533e-04, 1.2599e-04, 2.4689e-03, 3.1305e-05, 1.3870e-04,\n",
       "         6.0669e-05, 1.0152e-02, 1.2074e-04, 2.5186e-04, 1.3783e-04, 5.8086e-04,\n",
       "         1.5556e-04, 6.1830e-04, 2.9456e-04, 1.3800e-04, 1.4962e-04, 2.7398e-04,\n",
       "         9.5418e-04, 3.4739e-04, 1.6423e-04, 5.9351e-03, 5.3727e-04, 1.8878e-04,\n",
       "         3.2073e-04, 1.6634e-04, 1.9111e-03, 1.2443e-03, 2.6802e-03, 6.4294e-04,\n",
       "         7.1736e-04, 1.0891e-03, 7.2762e-04, 1.3128e-04, 7.0081e-04, 7.4229e-03,\n",
       "         2.6836e-04, 8.1577e-05, 3.0515e-04, 7.8450e-04, 6.1089e-04, 8.0401e-04,\n",
       "         6.0952e-04, 6.4202e-04, 8.8272e-05, 3.7387e-04, 1.7841e-03, 1.3150e-03,\n",
       "         6.1206e-05, 4.4580e-04, 8.2228e-05, 9.7522e-04, 2.8045e-05, 1.3502e-04,\n",
       "         4.6740e-04, 1.7803e-04, 8.5075e-04, 7.2152e-04, 2.0950e-04, 3.1033e-04,\n",
       "         1.0654e-03, 1.2458e-03, 8.6355e-04, 5.4940e-04, 2.5694e-03, 3.1718e-05,\n",
       "         1.1157e-02, 1.4932e-04, 4.0286e-04, 9.9731e-04, 6.3615e-05, 1.9562e-04,\n",
       "         2.6539e-04, 1.3811e-03, 1.0605e-03, 4.2136e-04, 3.1761e-03, 1.7050e-04,\n",
       "         1.3836e-04, 1.3090e-03, 9.1546e-04, 1.8857e-04, 3.2785e-04, 3.1692e-04,\n",
       "         5.8004e-04, 2.3084e-03], device='cuda:0', requires_grad=True),\n",
       " 'encoder.final_layer_norm.weight': tensor([1.6140e-03, 1.2232e-02, 6.0374e-03, 3.1375e-02, 7.3157e-03, 3.5492e-03,\n",
       "         7.8779e-02, 1.9680e-02, 2.4806e-02, 1.5029e-02, 2.8464e-03, 2.4657e-02,\n",
       "         1.7949e-02, 2.7438e-03, 3.8960e-02, 5.3876e-03, 3.8026e-03, 3.4611e-01,\n",
       "         1.2923e-02, 1.7870e-02, 2.5105e-03, 8.6731e-03, 1.1080e-02, 1.8940e-01,\n",
       "         7.7110e-03, 6.1723e-03, 2.2325e-03, 2.3587e-03, 3.4774e-03, 4.2742e-01,\n",
       "         1.6612e-03, 2.0324e-02, 9.2123e-03, 4.1598e-03, 1.8321e-02, 3.5851e-02,\n",
       "         8.6605e-03, 8.4261e-03, 1.4179e-01, 3.5957e-03, 5.2589e-03, 3.4307e-03,\n",
       "         1.2785e-01, 4.3201e-02, 7.3882e-02, 1.9192e-02, 4.5359e-02, 3.1967e-03,\n",
       "         1.6416e-02, 1.2712e-03, 1.0922e-02, 7.8906e-03, 9.6791e-03, 4.6319e-02,\n",
       "         3.4612e-02, 6.0757e-03, 2.9661e-03, 2.6096e-02, 2.7553e-02, 3.3278e-03,\n",
       "         2.1281e-03, 6.4281e-02, 4.0634e-02, 2.8557e-03, 1.6231e-02, 7.6439e-03,\n",
       "         3.5249e-03, 1.3297e-03, 4.8062e-02, 1.1264e-01, 1.4948e-02, 9.5054e-03,\n",
       "         4.7762e-03, 7.8302e-03, 4.1562e-03, 3.9800e-03, 1.0575e-02, 8.4415e-03,\n",
       "         3.9061e-02, 3.2906e-02, 7.6727e-02, 9.8007e-03, 5.9507e-03, 1.7408e-02,\n",
       "         1.7644e-02, 6.4196e-02, 2.1313e-02, 7.0113e-03, 1.0054e-02, 9.4571e-03,\n",
       "         3.6893e-03, 3.4359e-02, 2.8687e-03, 4.8825e-03, 4.3823e-03, 5.3787e-03,\n",
       "         6.3964e-03, 6.2357e-03, 3.7321e-02, 1.0012e-02, 4.7359e-04, 1.9873e-03,\n",
       "         1.3120e-02, 4.5066e-02, 1.5219e-02, 3.0747e-03, 6.1087e-02, 8.2884e-02,\n",
       "         1.2187e-01, 3.2541e-02, 9.4349e-03, 1.4752e-01, 4.2578e-03, 1.4943e-02,\n",
       "         8.9144e-03, 4.4703e-02, 1.8843e-02, 6.8638e-03, 8.3990e-04, 5.6688e-03,\n",
       "         1.0503e-03, 1.1095e-02, 1.6113e-03, 7.7594e-03, 6.1415e-03, 1.5875e-02,\n",
       "         1.0886e-02, 3.0966e-03, 4.7964e-01, 3.9942e-03, 6.2055e-03, 4.5222e-03,\n",
       "         3.8659e-02, 4.8918e-02, 4.5966e-02, 1.3086e-02, 2.5430e-01, 1.4056e-02,\n",
       "         1.8779e-02, 4.8322e-03, 4.0313e-03, 1.0097e-02, 7.2679e-02, 2.0696e-03,\n",
       "         2.1348e-03, 9.4348e-03, 1.9831e-02, 1.6428e-01, 2.8634e-02, 3.0596e-02,\n",
       "         1.4111e-03, 1.8647e-03, 5.0126e-02, 6.0519e-03, 2.0870e-03, 3.0596e-02,\n",
       "         1.3303e-02, 3.9712e-03, 7.6810e-03, 1.4366e-02, 2.5393e-03, 4.0999e-03,\n",
       "         1.7629e-03, 6.7852e-03, 1.0888e-01, 6.5727e-03, 3.6929e-02, 9.5125e-03,\n",
       "         4.2300e-03, 3.2157e-03, 2.7540e-02, 3.5744e-03, 8.3121e-03, 4.3821e-03,\n",
       "         4.0501e-03, 3.2359e-03, 1.4159e-03, 5.4001e-02, 2.3223e-02, 1.9987e-02,\n",
       "         2.2088e-03, 1.9534e-02, 5.2481e-02, 6.7159e-02, 8.0283e-02, 4.1073e-02,\n",
       "         3.1640e-03, 1.5934e-02, 4.1236e-03, 3.0233e-02, 2.2170e-02, 9.6808e-02,\n",
       "         2.2204e-02, 1.0428e-02, 2.9500e-03, 3.8147e-03, 5.9280e-03, 1.3780e-01,\n",
       "         3.9670e-03, 1.6805e-03, 1.6739e-01, 6.8326e-03, 1.3021e-02, 7.5175e+00,\n",
       "         2.8669e-03, 8.7289e-03, 1.1885e-02, 3.7081e-02, 7.2042e-03, 2.4554e-03,\n",
       "         8.5092e-02, 2.7548e-03, 3.6539e-03, 1.3911e-01, 9.0567e-04, 2.1778e-02,\n",
       "         1.0169e-02, 2.4048e-02, 2.2071e-01, 1.0164e-02, 3.2784e-03, 6.1259e-03,\n",
       "         4.7516e-02, 4.0722e-03, 5.6367e-03, 3.2373e-03, 1.3298e-02, 2.3644e-03,\n",
       "         3.1302e-01, 5.9960e-02, 2.1032e-03, 1.6865e-03, 2.6623e-02, 5.3081e-02,\n",
       "         1.6209e-02, 1.2866e-02, 1.6730e-02, 3.4515e-02, 6.4035e-03, 2.7895e-02,\n",
       "         2.0852e-02, 1.1382e-01, 6.4082e-03, 4.4844e-03, 7.0198e-03, 1.1276e-02,\n",
       "         9.8596e-02, 1.0636e-01, 1.9557e-02, 6.4434e-02, 1.0641e-02, 6.2611e-03,\n",
       "         1.6143e-01, 8.6132e-03, 3.6831e-03, 1.8101e-02, 2.3805e-02, 9.2813e-03,\n",
       "         1.1083e-02, 2.5763e-02, 1.8716e+00, 2.8795e-02, 2.9688e-02, 8.2089e-02,\n",
       "         2.5317e-01, 2.7047e-03, 4.7340e-03, 3.1187e-04, 3.5199e-02, 3.0183e-02,\n",
       "         3.6381e-03, 2.5410e-02, 1.9312e-02, 1.0558e-01, 5.8482e-03, 4.0743e+00,\n",
       "         1.7067e-02, 2.3134e-03, 1.7499e-03, 1.1774e-02, 6.2350e-02, 2.0641e-02,\n",
       "         5.9141e-04, 7.9119e-03, 1.0863e-02, 1.0901e-01, 2.1186e-02, 1.2000e-02,\n",
       "         8.7378e-04, 4.8909e-02, 2.2869e-02, 7.7582e-03, 1.4667e-03, 2.4583e-03,\n",
       "         3.3827e-02, 1.4347e-02, 5.8648e-03, 3.7813e-03, 2.5313e-03, 1.3445e-01,\n",
       "         2.7856e-01, 1.2189e-02, 5.3530e-02, 6.2360e-03, 9.5993e-03, 7.1871e-03,\n",
       "         1.7467e-02, 8.1556e-02, 1.2547e-02, 1.8356e-02, 3.0349e-03, 1.9899e-02,\n",
       "         1.4632e-01, 3.2173e-03, 8.1552e-03, 2.0348e-02, 1.2096e-03, 5.1608e-03,\n",
       "         2.2347e-01, 4.5761e-01, 3.1311e-03, 2.3424e-03, 7.3119e-03, 5.6592e-02,\n",
       "         4.0552e-03, 6.4547e-03, 1.8307e-02, 1.4260e-02, 4.9951e-03, 8.4898e-03,\n",
       "         7.3086e-03, 5.6180e-02, 3.5242e-03, 9.2746e-03, 2.1311e-03, 5.6188e-03,\n",
       "         6.0386e-03, 3.0540e-03, 8.8951e-04, 1.4861e-01, 2.5824e-03, 6.4573e-03,\n",
       "         2.2038e-03, 2.3399e-02, 8.6816e-03, 8.0969e-02, 4.2521e-02, 8.0198e-03,\n",
       "         2.4896e-03, 2.1202e-02, 3.8260e-01, 2.5661e-03, 1.1105e-02, 1.0970e-02,\n",
       "         3.7963e-03, 2.1586e-01, 4.3511e-03, 6.4804e-03, 2.3019e-03, 4.3032e-02,\n",
       "         7.4469e-02, 4.2923e-03, 1.1366e-02, 2.2019e-03, 6.4122e-03, 5.7240e-02,\n",
       "         7.2507e-03, 2.4299e-02, 6.2566e-03, 3.1338e-03, 1.5289e-03, 9.5958e-02,\n",
       "         1.3536e-02, 1.0354e-02, 9.5292e-02, 1.8243e-02, 2.1646e-02, 1.5539e-02,\n",
       "         3.4489e-03, 1.5086e-03, 9.8333e-03, 2.4974e-03, 4.5462e-03, 1.5762e-02,\n",
       "         2.6660e-02, 2.5314e-03, 1.9621e-02, 8.6135e-03, 7.2783e-03, 8.6961e-03,\n",
       "         5.1877e-03, 7.3585e-02, 4.9811e-03, 2.8246e-03, 9.0127e-03, 1.2255e-01,\n",
       "         1.9779e-02, 1.8432e-01, 6.3628e-03, 7.0004e-02, 6.6449e-03, 1.2408e-02,\n",
       "         1.4465e-02, 1.6745e-02, 1.5951e-02, 1.0854e-02, 8.9002e-03, 9.2405e-03,\n",
       "         1.3225e-03, 5.1420e-03, 4.5972e-02, 8.9369e-02, 1.5565e-02, 1.7796e-02,\n",
       "         1.6405e-02, 3.8846e-02, 1.1273e-02, 5.0325e-02, 8.4991e-03, 2.8451e-03,\n",
       "         4.2661e-03, 5.5030e-03, 1.1811e-01, 1.2950e-02, 1.1807e-01, 2.3315e-03,\n",
       "         2.1495e-03, 4.7175e-03, 2.4625e-03, 6.9936e-03, 3.8709e-03, 1.7870e-02,\n",
       "         9.4511e-03, 3.9295e+00, 3.3159e-03, 4.3030e-03, 2.1309e-02, 1.3232e-02,\n",
       "         4.1812e-03, 9.0701e-03, 1.4791e-02, 1.5591e-03, 1.7137e-03, 9.7668e-03,\n",
       "         8.1650e-03, 6.0657e-03, 6.6160e-03, 1.7837e-02, 1.8227e-03, 2.7088e-02,\n",
       "         7.6027e-03, 2.4018e-02, 1.9067e-02, 7.3610e-02, 1.4935e-02, 3.8564e-02,\n",
       "         1.0299e-02, 1.2219e-02, 8.3535e-03, 9.1327e-03, 1.1587e-02, 1.3857e-01,\n",
       "         4.0127e-03, 2.6100e-03, 1.5207e-02, 2.0295e-02, 6.7796e-03, 5.7181e-03,\n",
       "         2.1162e-02, 1.3044e-02, 1.3115e-02, 1.2638e-02, 3.4046e-03, 2.0809e-02,\n",
       "         3.6166e-03, 1.1682e-02, 1.9414e-03, 4.5768e-02, 7.0908e-03, 5.7975e-03,\n",
       "         3.3274e-02, 3.7516e-03, 8.7490e-03, 4.5303e-03, 7.6246e-03, 1.2019e-02,\n",
       "         7.4557e-03, 2.2678e-03, 4.4877e-03, 2.0922e-02, 4.9851e-02, 3.0451e-03,\n",
       "         2.0515e+00, 2.4014e-03, 6.9535e-03, 1.4053e-02, 2.7307e-03, 2.8578e-02,\n",
       "         1.1982e-01, 1.5666e-02, 2.8936e-01, 1.5980e-02, 1.0159e-02, 5.4714e-03,\n",
       "         1.2332e-02, 1.6917e-01, 3.7547e-02, 3.2966e-03, 3.9925e-03, 4.2756e-02,\n",
       "         7.9000e-03, 1.4523e-02], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.0.layer.0.SelfAttention.q.weight': tensor([[2.3790e-07, 3.1155e-08, 1.6419e-08,  ..., 6.7006e-09, 8.2714e-09,\n",
       "          1.5672e-07],\n",
       "         [2.7417e-06, 3.4906e-07, 5.9169e-08,  ..., 4.5135e-08, 3.4079e-08,\n",
       "          1.0176e-06],\n",
       "         [4.1042e-08, 6.3963e-09, 2.3230e-09,  ..., 2.7409e-09, 1.3285e-09,\n",
       "          1.5585e-08],\n",
       "         ...,\n",
       "         [4.5354e-07, 8.7246e-08, 1.2436e-07,  ..., 9.8296e-09, 6.7739e-08,\n",
       "          2.6079e-07],\n",
       "         [1.5679e-05, 2.0106e-06, 4.6975e-07,  ..., 1.5654e-07, 6.7258e-08,\n",
       "          6.0993e-06],\n",
       "         [2.6927e-06, 3.3740e-07, 9.3319e-08,  ..., 3.1097e-08, 6.6168e-08,\n",
       "          1.0198e-06]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.0.layer.0.SelfAttention.k.weight': tensor([[2.6316e-09, 3.5598e-10, 2.0513e-10,  ..., 2.9693e-10, 2.6070e-10,\n",
       "          1.3258e-09],\n",
       "         [6.9934e-09, 9.3946e-10, 8.5078e-11,  ..., 4.0282e-10, 2.0768e-10,\n",
       "          3.2420e-09],\n",
       "         [1.1927e-10, 1.3799e-11, 3.5839e-11,  ..., 4.2914e-10, 1.1332e-10,\n",
       "          7.3437e-11],\n",
       "         ...,\n",
       "         [3.1482e-08, 4.3525e-09, 4.3999e-10,  ..., 4.5286e-10, 3.3055e-10,\n",
       "          1.4208e-08],\n",
       "         [1.8819e-07, 2.5518e-08, 1.4187e-09,  ..., 1.9537e-09, 1.7678e-09,\n",
       "          8.4414e-08],\n",
       "         [1.4782e-09, 2.2477e-10, 3.4700e-10,  ..., 1.1422e-10, 4.3889e-10,\n",
       "          9.1637e-10]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.0.layer.0.SelfAttention.v.weight': tensor([[8.2287e-07, 1.0011e-07, 6.8174e-08,  ..., 2.2382e-07, 9.4731e-08,\n",
       "          3.5194e-07],\n",
       "         [7.9816e-08, 1.0373e-08, 9.1503e-09,  ..., 7.0473e-08, 2.4204e-08,\n",
       "          4.9121e-08],\n",
       "         [2.8401e-07, 3.4796e-08, 4.6778e-08,  ..., 5.7622e-09, 1.8498e-08,\n",
       "          1.0336e-07],\n",
       "         ...,\n",
       "         [4.4449e-08, 1.9339e-09, 5.3649e-08,  ..., 9.1006e-10, 9.4594e-09,\n",
       "          2.6812e-09],\n",
       "         [8.7400e-09, 1.2338e-09, 2.2417e-08,  ..., 2.1732e-09, 1.2720e-08,\n",
       "          1.8661e-09],\n",
       "         [5.6990e-09, 1.0324e-09, 4.4219e-08,  ..., 1.6969e-09, 7.7279e-09,\n",
       "          8.3907e-10]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.0.layer.0.SelfAttention.o.weight': tensor([[7.6363e-09, 2.6303e-07, 4.6695e-09,  ..., 1.0988e-08, 7.3272e-09,\n",
       "          1.2460e-09],\n",
       "         [4.5676e-08, 5.2224e-07, 2.4506e-08,  ..., 4.3986e-08, 2.4704e-08,\n",
       "          5.9887e-10],\n",
       "         [1.1515e-08, 1.2389e-07, 5.8286e-09,  ..., 1.4560e-08, 8.8351e-09,\n",
       "          1.3540e-09],\n",
       "         ...,\n",
       "         [1.1517e-08, 1.4402e-07, 6.1948e-09,  ..., 1.2575e-08, 7.3915e-09,\n",
       "          2.8003e-09],\n",
       "         [4.4229e-08, 4.4079e-07, 1.8875e-08,  ..., 1.5414e-08, 8.0228e-09,\n",
       "          1.5256e-09],\n",
       "         [8.8707e-09, 9.4108e-08, 4.0992e-09,  ..., 1.7069e-09, 1.3330e-09,\n",
       "          1.3249e-09]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.0.layer.0.SelfAttention.relative_attention_bias.weight': tensor([[5.9146e-03, 3.7308e-03, 9.6963e-04, 6.5851e-04, 2.4319e-07, 3.5144e-04,\n",
       "          1.7663e-06, 1.1570e-04],\n",
       "         [5.9038e-03, 3.7949e-03, 9.5188e-04, 6.5959e-04, 7.0570e-06, 3.5786e-04,\n",
       "          1.5002e-05, 1.3620e-04],\n",
       "         [1.2927e-06, 3.2780e-05, 2.4062e-05, 1.3705e-05, 1.2142e-05, 2.3752e-06,\n",
       "          3.0555e-06, 9.2261e-06],\n",
       "         [4.2214e-07, 6.3256e-06, 4.0464e-07, 1.9707e-06, 1.9443e-05, 1.0737e-06,\n",
       "          2.3242e-06, 6.8434e-06],\n",
       "         [1.0352e-05, 3.2072e-06, 2.4947e-06, 9.4456e-06, 1.5692e-05, 4.8575e-06,\n",
       "          6.8118e-06, 8.3287e-06],\n",
       "         [5.2110e-06, 1.4846e-05, 4.3013e-06, 1.1733e-05, 5.7604e-07, 3.1336e-06,\n",
       "          2.3967e-06, 1.1691e-06],\n",
       "         [7.4678e-06, 1.2022e-05, 1.2903e-07, 1.9149e-05, 6.6608e-06, 1.9997e-06,\n",
       "          4.5485e-06, 2.7320e-06],\n",
       "         [4.2254e-08, 1.3235e-07, 8.5285e-09, 1.3879e-06, 9.3712e-07, 2.5844e-08,\n",
       "          9.4647e-08, 1.5846e-08],\n",
       "         [4.2925e-09, 5.1782e-08, 2.0653e-09, 4.6223e-09, 3.0571e-07, 8.5851e-10,\n",
       "          1.2686e-09, 1.2473e-08],\n",
       "         [4.5144e-07, 1.0719e-06, 1.2838e-09, 1.0019e-06, 2.0227e-06, 2.3587e-07,\n",
       "          8.4277e-09, 5.6618e-09],\n",
       "         [3.0704e-08, 1.7861e-06, 1.8968e-09, 8.7908e-07, 3.8579e-06, 5.0802e-07,\n",
       "          4.6036e-07, 2.0647e-09],\n",
       "         [9.4313e-09, 6.4019e-08, 5.0809e-09, 3.3738e-07, 2.5392e-07, 6.3809e-09,\n",
       "          5.3337e-08, 3.3879e-10],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00, 0.0000e+00]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.0.layer.0.layer_norm.weight': tensor([8.8088e-03, 3.0430e-05, 8.2188e-04, 1.7688e-03, 5.7157e-05, 2.0727e-03,\n",
       "         1.8720e-04, 1.1588e-03, 3.5393e-05, 1.1690e-03, 5.3918e-04, 9.0287e-04,\n",
       "         2.0699e-05, 1.5877e-03, 3.5980e-03, 2.2973e-04, 8.5918e-04, 8.0294e-04,\n",
       "         2.5522e-03, 1.8990e-04, 5.2182e-04, 9.2670e-03, 1.0151e-04, 5.4710e-03,\n",
       "         3.7398e-04, 3.7956e-04, 1.3895e-02, 6.0389e-04, 7.9337e-05, 7.0931e-05,\n",
       "         8.9087e-04, 1.8662e-04, 8.5247e-04, 1.1319e-03, 8.9688e-04, 1.7486e-03,\n",
       "         3.1883e-04, 2.6603e-03, 9.8217e-04, 1.8171e-04, 5.6279e-03, 1.0122e-02,\n",
       "         1.7288e-02, 6.5985e-04, 4.2041e-03, 5.7634e-04, 2.5633e-01, 1.3480e-03,\n",
       "         4.4601e-03, 1.0912e-03, 7.4166e-03, 3.9844e-03, 1.6016e-04, 3.5886e-04,\n",
       "         1.0358e-04, 3.4580e-04, 6.6157e-04, 1.9516e-04, 2.6367e-03, 1.8289e-04,\n",
       "         4.0029e-04, 2.2505e-04, 5.4075e-04, 6.5509e-05, 2.4528e-03, 6.1217e-05,\n",
       "         5.6417e-05, 9.8025e-05, 3.0169e-04, 7.2566e-04, 1.0198e-04, 6.5976e-04,\n",
       "         5.6059e-05, 8.3332e-04, 1.8075e-02, 1.1747e-04, 9.8170e-04, 1.2711e-03,\n",
       "         6.9947e-04, 4.4505e-04, 1.1049e-04, 1.0660e-03, 1.4133e-04, 9.5940e-04,\n",
       "         2.4057e-04, 1.5588e-04, 9.6137e-04, 8.2698e-04, 4.5125e-04, 2.9052e-03,\n",
       "         2.0067e-04, 1.0460e-03, 3.4235e-03, 8.0666e-05, 5.4178e-04, 1.5142e-04,\n",
       "         4.4045e-03, 2.6318e-03, 3.2826e-01, 6.5929e-05, 6.7506e-04, 7.1172e-03,\n",
       "         8.4915e-05, 8.2544e-04, 1.6205e-02, 2.9599e-03, 2.1802e-03, 1.2588e-04,\n",
       "         5.7003e-03, 2.0704e-05, 1.6246e-04, 2.1340e-04, 4.2395e-02, 9.8249e-03,\n",
       "         2.1296e-03, 2.4232e-04, 2.5840e-03, 7.0515e-05, 2.1002e-03, 1.6489e-03,\n",
       "         1.5862e-03, 7.2933e-05, 1.9632e-03, 7.5539e-02, 8.6235e-05, 1.0490e-03,\n",
       "         1.8793e-04, 7.8251e-03, 1.0875e-04, 4.5947e-04, 3.3172e-04, 8.6079e-04,\n",
       "         8.4559e-05, 4.0525e-04, 4.0864e-05, 7.3470e-04, 3.2678e-03, 1.3360e-02,\n",
       "         8.4988e-04, 1.6175e-03, 8.0352e-03, 3.1583e-04, 1.2630e-04, 4.2758e-03,\n",
       "         2.3577e-03, 3.1674e-04, 1.6354e-03, 1.8770e-04, 1.3620e-03, 4.3187e-03,\n",
       "         1.6562e-03, 5.3036e-04, 1.7458e-03, 9.9064e-03, 6.0279e-04, 7.6479e-04,\n",
       "         2.0019e-03, 4.3557e-05, 4.8661e-03, 3.7840e-03, 1.0315e-03, 8.0894e-04,\n",
       "         6.5660e-03, 2.5847e-03, 9.2486e-04, 1.5487e-05, 2.7890e-03, 4.2689e-05,\n",
       "         8.6129e-04, 1.9677e-04, 8.6594e-04, 6.4456e-04, 5.2848e-03, 4.9790e-04,\n",
       "         8.3950e-03, 2.3365e-04, 1.8509e-04, 3.5199e-04, 3.0460e-03, 1.3992e-04,\n",
       "         3.9999e-02, 1.4567e-04, 3.0636e-04, 9.0026e-04, 1.1920e-03, 5.0353e-03,\n",
       "         2.8122e-03, 1.5617e-04, 2.7291e-04, 2.2000e-03, 1.9062e-02, 9.2141e-04,\n",
       "         1.0007e-03, 1.2671e-04, 8.0092e-05, 6.9913e-03, 9.3458e-05, 1.5972e-04,\n",
       "         2.3076e-04, 3.5223e-05, 1.6090e-03, 4.7403e-04, 8.9174e-06, 8.9126e-04,\n",
       "         1.1862e-03, 2.0992e-04, 1.4055e-03, 4.7687e-03, 1.1567e-04, 1.8101e-04,\n",
       "         1.1359e-04, 1.0111e-04, 6.6697e-04, 1.8880e-04, 1.4492e-03, 4.8919e-03,\n",
       "         2.5271e-04, 1.3006e-04, 7.4796e-05, 9.5079e-04, 3.3906e-03, 2.6833e-03,\n",
       "         1.1269e-03, 1.7416e-04, 1.3347e-03, 1.0168e-03, 2.2686e-04, 1.8379e-03,\n",
       "         8.8175e-05, 2.1765e-04, 8.1714e-05, 4.5963e-04, 2.1398e-04, 1.0140e-03,\n",
       "         3.2453e-04, 3.7717e-03, 2.0428e-03, 4.0985e-03, 1.5279e-03, 5.4806e-04,\n",
       "         5.2629e-04, 2.2651e-04, 6.5936e-04, 6.9029e-04, 1.6611e-03, 5.6237e-04,\n",
       "         6.3650e-05, 1.0898e-03, 1.3054e-04, 3.5219e-04, 2.8536e-03, 8.5158e-04,\n",
       "         1.6381e-03, 4.7236e-03, 9.7709e-05, 4.4109e-04, 1.0511e-03, 7.1638e-03,\n",
       "         9.9461e-04, 1.4701e-03, 5.1014e-04, 2.2494e-02, 3.6060e-04, 1.5774e-04,\n",
       "         7.9836e-04, 1.0890e-03, 5.9088e-05, 2.0037e-02, 9.9925e-03, 8.3499e-04,\n",
       "         1.2787e-02, 8.1437e-05, 1.0905e-04, 1.0160e-03, 9.8732e-03, 1.2168e-03,\n",
       "         3.3222e-03, 2.3068e-03, 4.3327e-05, 5.6830e-05, 1.7806e-04, 4.1997e-05,\n",
       "         7.2637e-03, 7.0351e-04, 2.6009e-03, 2.8349e-04, 1.4422e-03, 4.7834e-04,\n",
       "         6.7533e-05, 9.8575e-05, 1.4041e-04, 2.3334e-03, 1.8114e-03, 8.8658e-04,\n",
       "         6.9659e-04, 6.0128e-05, 1.5840e-04, 2.1446e-04, 1.4775e-03, 4.5805e-02,\n",
       "         2.4844e-04, 1.2096e-04, 7.2521e-05, 4.7617e-03, 2.8887e-04, 1.5005e-03,\n",
       "         5.6585e-04, 7.3439e-05, 2.6084e-03, 2.0720e-04, 9.4610e-04, 1.1411e-03,\n",
       "         3.2341e-03, 1.4150e-03, 2.0992e-03, 2.0018e-03, 1.7666e-04, 1.5937e-04,\n",
       "         8.1705e-02, 1.8024e-04, 1.3579e-03, 4.8110e-04, 5.2919e-03, 8.0691e-05,\n",
       "         3.3519e-03, 9.9407e-04, 3.2176e-03, 9.3612e-05, 7.8509e-05, 6.1986e-04,\n",
       "         3.5447e-04, 2.5809e-03, 8.7273e-04, 1.1955e-03, 5.4798e-05, 6.4034e-03,\n",
       "         3.2600e-04, 1.2207e-02, 2.6081e-03, 1.5965e-04, 5.6948e-05, 1.4303e-04,\n",
       "         7.1219e-05, 5.5890e-04, 1.4542e-04, 1.8520e-04, 6.1287e-03, 6.3050e-04,\n",
       "         9.9148e-03, 3.8666e-03, 1.0330e-02, 1.3172e-03, 4.8387e-04, 1.5993e-04,\n",
       "         2.3919e-04, 4.4226e-03, 1.4729e-03, 1.0440e-04, 3.1724e-04, 6.0724e-04,\n",
       "         4.6326e-04, 2.4203e-03, 7.7447e-04, 3.5183e-03, 1.0359e-03, 2.6323e-04,\n",
       "         4.5354e-04, 3.6367e-05, 7.4239e-04, 2.9116e-03, 4.9691e-03, 5.7799e-03,\n",
       "         3.9409e-03, 2.5702e-03, 4.7082e-04, 1.8722e-04, 7.6655e-04, 5.0897e-03,\n",
       "         3.6979e-03, 1.8644e-03, 3.6257e-03, 1.6717e-03, 2.7273e-04, 2.2033e-04,\n",
       "         1.5841e-03, 7.8586e-03, 4.4816e-03, 1.6184e-03, 6.8800e-05, 1.1020e-03,\n",
       "         2.5613e-04, 2.8315e-03, 7.6448e-02, 1.8345e-04, 7.9391e-04, 1.7935e-03,\n",
       "         4.2646e-04, 3.2221e-05, 1.2906e-03, 5.1160e-03, 2.9833e-03, 2.2741e-04,\n",
       "         5.9689e-04, 9.3609e-06, 2.2321e-03, 3.9399e-03, 1.4472e-02, 6.6108e-04,\n",
       "         9.7954e-05, 3.0956e-03, 5.4812e-04, 1.6657e-04, 3.6737e-05, 1.6003e-03,\n",
       "         1.4402e-03, 5.2138e-04, 8.0607e-03, 1.3938e-04, 3.2023e-03, 2.3358e-04,\n",
       "         3.5486e-03, 8.5254e-05, 8.3092e-05, 1.3612e-02, 4.9415e-03, 1.1899e-03,\n",
       "         3.4100e-04, 3.2756e-03, 1.6612e-03, 4.7674e-03, 2.6850e-04, 1.1843e-03,\n",
       "         4.3046e-03, 2.6239e-05, 4.0549e-04, 5.2342e-03, 2.5543e-03, 2.2124e-04,\n",
       "         1.0207e-03, 1.0035e-03, 2.6651e-03, 4.2859e-03, 3.6411e-04, 1.0341e-03,\n",
       "         1.0945e-02, 1.2048e-04, 1.4225e-02, 9.0484e-05, 6.8810e-04, 8.2978e-04,\n",
       "         5.2562e-03, 1.1009e-04, 4.4659e-02, 4.2033e-03, 5.3604e-05, 1.0018e-04,\n",
       "         2.3081e-04, 2.8880e-04, 3.5695e-04, 2.6434e-02, 2.6931e-03, 1.3357e-03,\n",
       "         5.3740e-03, 6.5827e-04, 6.8160e-05, 1.3761e-04, 1.0072e-03, 9.2155e+00,\n",
       "         1.2794e-03, 5.6951e-04, 1.8299e-03, 1.6531e-02, 6.2598e-03, 1.7366e-03,\n",
       "         4.6563e-03, 1.4694e-03, 1.5925e-02, 1.2835e-04, 6.1952e-03, 1.4971e-01,\n",
       "         2.2886e-04, 1.0965e-04, 7.0097e-03, 4.0988e-03, 1.6453e-04, 7.6845e-05,\n",
       "         5.0085e-04, 2.1849e-04, 1.2747e-04, 2.9891e-04, 1.3909e-04, 3.3087e-04,\n",
       "         2.5002e-03, 3.5991e-04, 3.3350e-03, 4.6004e-03, 2.4286e-03, 1.6740e-03,\n",
       "         1.0428e-03, 1.4826e-04, 1.2040e-04, 3.4350e-04, 1.5159e-03, 2.9874e-03,\n",
       "         7.0210e-05, 2.2268e-03, 9.9844e-05, 5.5758e-04, 9.7390e-05, 2.1374e-04,\n",
       "         3.2014e-04, 2.6371e-03], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.0.layer.1.EncDecAttention.q.weight': tensor([[4.0666e-07, 2.7739e-07, 8.6511e-07,  ..., 2.5194e-07, 5.7388e-07,\n",
       "          8.6388e-07],\n",
       "         [1.1880e-06, 1.6569e-07, 5.2206e-07,  ..., 8.0941e-07, 9.5155e-07,\n",
       "          1.5002e-06],\n",
       "         [5.5785e-07, 3.9251e-07, 2.0336e-07,  ..., 4.2163e-08, 5.0402e-07,\n",
       "          9.0285e-07],\n",
       "         ...,\n",
       "         [7.6774e-05, 7.4705e-06, 4.8583e-06,  ..., 2.2133e-06, 3.2863e-06,\n",
       "          1.4425e-04],\n",
       "         [2.0548e-05, 1.2541e-05, 2.0564e-06,  ..., 6.3999e-07, 1.0490e-06,\n",
       "          3.4088e-05],\n",
       "         [6.6248e-06, 1.8432e-07, 1.3364e-06,  ..., 6.4746e-06, 1.3085e-06,\n",
       "          6.9821e-06]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.0.layer.1.EncDecAttention.k.weight': tensor([[1.0294e-07, 2.4265e-08, 1.0394e-08,  ..., 1.6715e-07, 2.3188e-08,\n",
       "          1.2961e-07],\n",
       "         [1.5063e-07, 3.0756e-08, 1.2629e-08,  ..., 2.9657e-07, 3.8034e-08,\n",
       "          1.6946e-07],\n",
       "         [3.2615e-08, 1.1980e-08, 1.0255e-08,  ..., 3.9358e-08, 4.6773e-09,\n",
       "          7.3853e-08],\n",
       "         ...,\n",
       "         [5.0106e-08, 4.2500e-09, 3.8610e-07,  ..., 2.8861e-08, 1.2064e-08,\n",
       "          9.5198e-08],\n",
       "         [4.9341e-07, 2.7446e-08, 2.5676e-07,  ..., 2.0362e-07, 4.7458e-07,\n",
       "          5.9092e-08],\n",
       "         [1.8705e-08, 4.8066e-10, 1.2882e-08,  ..., 2.6143e-08, 1.8700e-08,\n",
       "          9.2591e-09]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.0.layer.1.EncDecAttention.v.weight': tensor([[5.2033e-08, 2.6385e-08, 9.2208e-08,  ..., 2.7422e-07, 1.2043e-08,\n",
       "          3.8614e-08],\n",
       "         [9.9337e-08, 5.0895e-08, 9.5177e-08,  ..., 5.8190e-07, 3.5087e-09,\n",
       "          9.2750e-08],\n",
       "         [4.1781e-07, 3.4083e-08, 3.9419e-07,  ..., 9.1138e-07, 6.5261e-08,\n",
       "          5.6701e-07],\n",
       "         ...,\n",
       "         [2.5364e-07, 2.8421e-08, 2.2398e-07,  ..., 5.1570e-07, 6.4875e-08,\n",
       "          4.7027e-08],\n",
       "         [5.2919e-07, 4.8304e-08, 7.9728e-07,  ..., 1.0508e-06, 2.3121e-07,\n",
       "          6.8618e-08],\n",
       "         [2.7608e-07, 6.4539e-08, 3.3872e-07,  ..., 7.5082e-07, 1.1204e-07,\n",
       "          1.3649e-07]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.0.layer.1.EncDecAttention.o.weight': tensor([[4.0811e-08, 1.1246e-06, 3.7827e-08,  ..., 9.9570e-08, 5.0965e-08,\n",
       "          3.3615e-08],\n",
       "         [3.0006e-07, 1.1558e-06, 2.1016e-07,  ..., 4.2378e-07, 4.0234e-07,\n",
       "          8.1152e-08],\n",
       "         [9.4929e-08, 2.4908e-07, 1.5694e-08,  ..., 2.5643e-07, 6.0409e-08,\n",
       "          4.6983e-08],\n",
       "         ...,\n",
       "         [1.5022e-07, 4.6458e-07, 5.0521e-08,  ..., 2.8823e-07, 9.3478e-08,\n",
       "          4.7398e-08],\n",
       "         [5.1203e-08, 2.2571e-07, 3.0655e-07,  ..., 6.6034e-07, 4.9626e-08,\n",
       "          9.1016e-08],\n",
       "         [6.3597e-08, 2.5767e-07, 1.1501e-07,  ..., 4.7456e-08, 1.0743e-07,\n",
       "          7.3299e-09]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.0.layer.1.layer_norm.weight': tensor([3.6826e-03, 2.4399e-04, 9.8429e-04, 8.9962e-04, 5.1322e-03, 5.2612e-04,\n",
       "         9.4052e-05, 1.5156e-04, 5.0958e-03, 6.9887e-04, 1.8130e-05, 2.9460e-04,\n",
       "         1.5150e-04, 1.3924e-03, 1.3540e-03, 3.9816e-03, 2.8944e-04, 4.6516e-05,\n",
       "         4.5243e-04, 1.4310e-04, 5.4481e-04, 5.9058e-04, 3.3718e-04, 5.6024e-03,\n",
       "         1.9277e-04, 1.3824e-03, 1.1665e-03, 4.7828e-04, 3.0213e-05, 1.4813e-04,\n",
       "         3.9912e-04, 2.9465e-04, 1.2691e-05, 4.5227e-04, 4.0945e-04, 1.2570e-04,\n",
       "         3.4664e-05, 6.1714e-04, 5.0745e-03, 3.6658e-05, 1.6889e-04, 4.3745e-05,\n",
       "         1.4078e-04, 6.9167e-04, 4.4603e-03, 1.7193e-04, 2.8547e-03, 8.8667e-06,\n",
       "         7.3289e-04, 1.1380e-03, 1.6216e-03, 5.2382e-04, 4.5875e-04, 3.4366e-02,\n",
       "         1.0296e-04, 3.1307e-05, 1.1540e-03, 5.2032e-05, 1.5355e-04, 1.6459e-05,\n",
       "         4.7560e-04, 4.2214e-04, 3.7588e-04, 1.8736e-04, 3.6507e-03, 1.7596e-03,\n",
       "         5.8010e-05, 4.3286e-04, 1.1663e-03, 6.1187e-04, 3.0514e-04, 5.6535e-04,\n",
       "         1.0504e-04, 1.4005e-04, 1.7914e-03, 5.6713e-04, 1.1037e-03, 4.8844e-05,\n",
       "         3.3700e-05, 1.3353e-04, 6.7638e-05, 1.8866e-03, 2.7492e-04, 2.5820e-04,\n",
       "         1.1746e-03, 1.1423e-04, 9.5941e-03, 7.9410e-03, 1.0035e-03, 4.1608e-05,\n",
       "         2.3495e-04, 2.7132e-05, 1.8354e-04, 8.8409e-05, 1.2177e-04, 6.0911e-04,\n",
       "         2.3671e-02, 4.3208e-04, 1.2918e-02, 2.1244e-05, 6.2280e-04, 2.9778e-04,\n",
       "         5.2302e-05, 4.8292e-03, 3.5437e-03, 1.7112e-03, 3.8015e-04, 9.6284e-06,\n",
       "         3.7456e-03, 1.1709e-04, 1.5899e-04, 2.7450e-04, 1.3984e-02, 1.9266e-04,\n",
       "         2.1149e-04, 5.6324e-04, 3.0378e-04, 4.2848e-04, 1.9334e-03, 3.5955e-04,\n",
       "         5.1504e-04, 2.6877e-05, 5.7061e-04, 1.2301e-03, 1.1865e-04, 3.0788e-05,\n",
       "         1.7289e-04, 5.5204e-04, 3.8414e-04, 1.2964e-04, 4.2021e-05, 3.0886e-04,\n",
       "         4.5576e-05, 3.4676e-04, 6.4693e-03, 3.6836e-04, 7.0900e-04, 1.5964e-04,\n",
       "         4.6644e-03, 1.2118e-04, 6.6607e-04, 4.3593e-03, 1.2661e-03, 8.8707e-03,\n",
       "         3.1947e-03, 5.0083e-04, 7.3517e-04, 1.4312e-03, 2.5638e-05, 3.6480e-02,\n",
       "         9.5001e-04, 1.3955e-04, 2.3811e-04, 1.1800e-03, 3.5625e-04, 2.6599e-04,\n",
       "         4.8264e-04, 3.4290e-05, 7.7188e-05, 9.6566e-04, 3.4034e-04, 4.7144e-03,\n",
       "         1.2616e-03, 1.6074e-04, 5.7284e-05, 3.6504e-05, 3.0979e-03, 2.1185e-05,\n",
       "         3.2456e-04, 3.9056e-04, 5.3469e-04, 3.9985e-04, 1.3829e-04, 5.9330e-05,\n",
       "         1.7628e-03, 1.9871e-04, 3.6518e-04, 1.4809e-04, 8.2230e-06, 9.1670e-04,\n",
       "         5.4765e-03, 8.7966e-05, 4.7273e-03, 1.0130e-04, 8.2650e-03, 1.1782e-03,\n",
       "         1.7138e-04, 2.2106e-03, 4.1308e-04, 3.9327e-04, 8.9973e-04, 1.2143e-03,\n",
       "         3.8158e-04, 1.5288e-04, 7.8243e-05, 6.0072e-04, 5.7450e-05, 1.6596e-05,\n",
       "         3.1272e-04, 3.8825e-03, 1.5984e-04, 1.5889e-03, 1.5277e-04, 3.3011e-05,\n",
       "         2.4567e-03, 3.2334e-05, 1.1441e-03, 3.4632e-04, 7.2321e-04, 4.2928e-04,\n",
       "         4.9077e-04, 1.4386e-04, 1.2575e-04, 6.8461e-04, 4.1421e-03, 7.8857e-03,\n",
       "         2.4047e-04, 1.5319e-03, 6.0517e-05, 1.7415e-04, 1.9766e-03, 4.4442e-04,\n",
       "         5.6604e-05, 2.4552e-04, 2.6620e-04, 2.1662e-03, 2.3959e-03, 2.1682e-04,\n",
       "         4.2041e-04, 3.0944e-04, 6.7217e-04, 4.5915e-05, 4.1499e-02, 8.2946e-05,\n",
       "         8.1553e-04, 1.0918e-03, 3.4899e-03, 3.2255e-03, 5.8758e-03, 2.1290e-03,\n",
       "         1.9343e-04, 4.1839e-04, 2.4370e-04, 1.0564e-04, 1.2608e-02, 4.6551e-03,\n",
       "         9.4815e-05, 3.7375e-04, 1.0972e-04, 1.8465e-05, 6.8047e-03, 2.4953e-03,\n",
       "         4.3916e-04, 4.6606e-05, 1.1341e-04, 1.1381e-03, 3.4625e-04, 8.9776e-04,\n",
       "         4.8428e-04, 1.7110e-04, 1.2552e-03, 1.1506e-03, 7.3080e-05, 2.5524e-03,\n",
       "         2.0074e-04, 1.0105e-03, 8.7241e-04, 1.6666e-04, 3.1257e-03, 1.6964e-04,\n",
       "         1.0152e-03, 6.6040e-05, 5.2730e-05, 8.8590e-04, 4.5287e-05, 1.2668e-04,\n",
       "         1.4219e-03, 1.8361e-03, 8.6808e-05, 1.8555e-03, 5.7808e-03, 3.4927e-04,\n",
       "         5.6163e-04, 4.9332e-04, 3.4311e-04, 7.4641e-05, 6.0095e-04, 1.0607e-03,\n",
       "         5.6232e-04, 9.7144e-04, 2.3086e-03, 1.4888e-03, 1.9280e-03, 1.8566e-03,\n",
       "         2.4959e-05, 1.1900e-03, 8.9462e-04, 6.5149e-05, 2.3471e-04, 7.9049e-03,\n",
       "         7.6756e-05, 1.8367e-04, 9.8728e-05, 9.8240e-04, 2.9242e-02, 8.5856e-05,\n",
       "         2.9005e-04, 1.8085e-03, 3.3719e-04, 3.9136e-05, 1.5503e-04, 4.0958e-04,\n",
       "         6.2677e-04, 1.6226e-03, 2.4016e-04, 1.7616e-03, 9.6614e-04, 1.6630e-04,\n",
       "         1.3964e-03, 9.4253e-05, 7.4617e-04, 4.3634e-04, 2.9282e-03, 1.2546e-03,\n",
       "         2.7503e-03, 4.9742e-03, 1.1021e-04, 2.0699e-03, 6.3289e-05, 8.3080e-05,\n",
       "         3.6657e-04, 7.4703e-05, 9.2418e-04, 1.3577e-03, 1.0709e-03, 7.1716e-04,\n",
       "         7.9418e-05, 1.8989e-03, 2.2240e-04, 7.1995e-03, 2.6621e-05, 5.2645e-04,\n",
       "         2.7884e-05, 6.3043e-04, 1.4409e-05, 1.1755e-03, 6.6659e-05, 2.1648e-04,\n",
       "         2.2591e-03, 1.3289e-04, 2.7106e-04, 1.8696e-03, 2.6144e-03, 1.6026e-04,\n",
       "         6.4820e-05, 1.9607e-04, 2.7108e-04, 4.8841e-03, 2.0392e-03, 3.2949e-04,\n",
       "         1.3377e-05, 2.4532e-03, 5.8525e-04, 3.0135e-04, 2.1478e-03, 4.5338e-04,\n",
       "         1.3810e-04, 1.2254e-01, 3.9996e-05, 4.0326e-03, 3.6687e-04, 1.7113e-04,\n",
       "         1.0739e-03, 5.6213e-03, 1.2016e-03, 3.8540e-04, 1.2473e-04, 2.7516e-03,\n",
       "         4.4990e-04, 1.0556e-04, 2.5384e-04, 7.1760e-04, 1.3793e-04, 1.9914e-03,\n",
       "         5.5411e-03, 3.6952e-04, 1.8143e-04, 2.3768e-04, 5.5837e-04, 1.3960e-04,\n",
       "         8.4070e-03, 6.2473e-05, 5.4839e-02, 1.2962e-03, 8.2030e-05, 3.5196e-04,\n",
       "         1.0512e-03, 5.6252e-05, 3.3676e-04, 2.3473e-03, 2.3515e-04, 1.9051e-03,\n",
       "         4.4148e-04, 2.0688e-02, 1.7701e-04, 2.5819e-04, 1.0470e-03, 2.0766e-05,\n",
       "         1.7871e-04, 2.0107e-03, 2.9349e-05, 8.1862e-04, 2.0387e-04, 1.7652e-04,\n",
       "         1.4931e-03, 1.4223e-04, 5.8295e-04, 2.0855e-02, 7.5023e-04, 2.4207e-04,\n",
       "         1.5562e-04, 5.9918e-03, 6.4506e-04, 8.3002e-03, 8.4230e-04, 3.8614e-04,\n",
       "         1.8753e-03, 9.8333e-04, 9.4090e-04, 5.8236e-03, 2.0606e-04, 4.0463e-04,\n",
       "         1.7736e-03, 5.4025e-04, 8.7889e-04, 1.0362e-03, 2.6983e-04, 5.2102e-04,\n",
       "         4.7713e-04, 2.1116e-04, 2.0824e-04, 1.4084e-02, 1.6110e-04, 5.9769e-04,\n",
       "         3.5219e-03, 5.7771e-04, 6.6310e-04, 1.7966e-05, 1.3232e-04, 1.0236e-03,\n",
       "         1.3092e-03, 2.4622e-04, 3.3568e-03, 9.3689e-03, 2.6570e-05, 3.1902e-04,\n",
       "         4.4626e-03, 6.1890e-04, 7.4908e-04, 8.7103e-04, 6.9236e-04, 2.5499e-03,\n",
       "         1.4156e-03, 5.0940e-04, 7.7091e-05, 3.7222e-04, 6.0044e-04, 6.6253e-02,\n",
       "         6.2395e-05, 3.0587e-04, 7.5134e-03, 1.0420e-02, 1.1146e-03, 9.8918e-04,\n",
       "         6.4670e-04, 5.7276e-04, 8.8223e-04, 4.5931e-02, 1.8222e-03, 2.7694e-03,\n",
       "         8.4841e-04, 6.3616e-04, 3.6365e-03, 1.0565e-02, 2.2616e-03, 1.7975e-05,\n",
       "         9.2241e-04, 4.5460e-03, 2.6239e-04, 8.1747e-04, 9.9666e-05, 1.0834e-04,\n",
       "         6.0972e-04, 2.6301e-03, 7.7048e-04, 3.0961e-05, 4.0752e-04, 1.1480e-04,\n",
       "         6.2538e-05, 5.0604e-05, 3.5146e-04, 1.1844e-03, 9.6545e-05, 8.4086e-04,\n",
       "         1.6720e-04, 3.1136e-03, 1.2032e-03, 1.1819e-04, 5.1329e-04, 5.7129e-03,\n",
       "         5.6477e-04, 2.3449e-03], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.0.layer.2.DenseReluDense.wi.weight': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [6.2791e-06, 9.6141e-07, 3.2138e-07,  ..., 5.0691e-07, 2.3222e-06,\n",
       "          4.1907e-06],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         ...,\n",
       "         [3.3158e-13, 2.0532e-13, 1.0810e-13,  ..., 1.5500e-12, 1.3377e-13,\n",
       "          1.0392e-11],\n",
       "         [2.9022e-09, 4.0597e-10, 9.4172e-10,  ..., 2.1621e-10, 3.3599e-09,\n",
       "          8.3291e-10],\n",
       "         [2.6777e-06, 3.8460e-07, 1.3435e-07,  ..., 3.3471e-07, 7.3875e-07,\n",
       "          1.7444e-06]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.0.layer.2.DenseReluDense.wo.weight': tensor([[0.0000e+00, 9.0133e-07, 0.0000e+00,  ..., 1.7959e-12, 9.2254e-10,\n",
       "          1.9983e-06],\n",
       "         [0.0000e+00, 4.7436e-07, 0.0000e+00,  ..., 1.5659e-12, 4.2034e-09,\n",
       "          9.3261e-07],\n",
       "         [0.0000e+00, 4.5106e-07, 0.0000e+00,  ..., 2.1959e-13, 2.5063e-10,\n",
       "          1.0244e-06],\n",
       "         ...,\n",
       "         [0.0000e+00, 8.2498e-07, 0.0000e+00,  ..., 5.9780e-14, 5.7642e-10,\n",
       "          1.8616e-06],\n",
       "         [0.0000e+00, 1.8097e-06, 0.0000e+00,  ..., 6.2025e-16, 4.4226e-10,\n",
       "          4.1247e-06],\n",
       "         [0.0000e+00, 5.2257e-07, 0.0000e+00,  ..., 6.0830e-14, 8.7566e-11,\n",
       "          1.1761e-06]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.0.layer.2.layer_norm.weight': tensor([4.3213e-04, 3.3001e-05, 7.4192e-05, 3.8918e-05, 8.3335e-03, 1.1546e-04,\n",
       "         3.1353e-05, 1.0865e-05, 3.7867e-04, 1.7582e-05, 9.9346e-05, 8.4208e-05,\n",
       "         3.5198e-05, 4.6102e-06, 1.1173e-04, 3.5136e-04, 2.1340e-05, 1.7288e-06,\n",
       "         4.6250e-06, 1.5647e-05, 6.7817e-05, 1.9759e-04, 1.2242e-05, 9.4469e-04,\n",
       "         8.9398e-05, 2.1807e-05, 1.1815e-05, 9.6227e-05, 1.2496e-04, 9.6608e-05,\n",
       "         7.8650e-06, 1.1422e-05, 1.3137e-06, 3.3849e-04, 2.0962e-05, 7.1449e-05,\n",
       "         1.4491e-04, 1.6939e-05, 2.4401e-04, 1.2616e-04, 1.4920e-05, 1.5591e-04,\n",
       "         4.7944e-04, 1.4038e-04, 3.6365e-05, 1.2904e-04, 5.0568e-03, 9.2275e-05,\n",
       "         1.5327e-05, 2.3622e-05, 1.2460e-04, 2.0943e-05, 6.8511e-05, 8.8421e-03,\n",
       "         4.2143e-05, 8.4580e-04, 1.9838e-04, 1.0178e-04, 3.6758e-06, 7.1546e-06,\n",
       "         1.6483e-05, 8.5182e-06, 5.9844e-06, 1.5996e-04, 4.4658e-06, 4.6695e-05,\n",
       "         5.9775e-05, 3.3407e-05, 1.8161e-04, 2.2269e-04, 6.6585e-05, 2.7018e-05,\n",
       "         1.2325e-05, 4.3858e-06, 5.7324e-05, 1.5956e-04, 5.1046e-06, 8.5150e-06,\n",
       "         1.0347e-05, 2.6757e-06, 2.1903e-04, 5.8033e-05, 9.5518e-06, 3.5521e-05,\n",
       "         6.6451e-05, 2.6566e-05, 1.3389e-05, 2.0120e-05, 1.1057e-05, 8.7066e-05,\n",
       "         4.3810e-05, 4.4115e-05, 1.9770e-04, 2.2876e-05, 8.8041e-06, 9.0796e-06,\n",
       "         3.1396e-04, 1.3728e-04, 4.6228e-04, 5.6739e-06, 4.5638e-05, 3.7467e-06,\n",
       "         4.5500e-05, 3.7930e-04, 7.5208e-05, 1.4191e-05, 4.6898e-06, 2.0028e-05,\n",
       "         8.9323e-06, 1.0961e-04, 7.1918e-06, 7.9080e-06, 4.3225e-04, 2.9463e-05,\n",
       "         9.0334e-05, 1.5469e-04, 3.6612e-05, 9.1954e-05, 1.5108e-04, 8.5551e-05,\n",
       "         8.1155e-05, 6.9948e-05, 1.6314e-05, 4.9348e-04, 3.4210e-05, 3.6491e-04,\n",
       "         6.2063e-06, 9.0978e-05, 2.0219e-05, 3.7403e-06, 7.3477e-06, 2.0425e-05,\n",
       "         9.9954e-06, 1.6852e-04, 5.8038e-05, 1.3906e-04, 7.9936e-05, 1.1793e-05,\n",
       "         4.2401e-05, 3.7902e-06, 1.5864e-05, 2.9844e-04, 8.9711e-05, 6.0907e-05,\n",
       "         6.7234e-05, 1.4316e-05, 1.0164e-04, 6.4082e-05, 4.6987e-06, 3.1624e-02,\n",
       "         6.3708e-06, 6.1335e-06, 2.7636e-05, 6.3134e-04, 2.8641e-04, 2.5541e-04,\n",
       "         1.4598e-04, 4.2630e-06, 9.2599e-06, 3.6231e-03, 5.6415e-06, 1.3493e-05,\n",
       "         8.9951e-05, 1.6707e-05, 7.0728e-06, 2.3764e-06, 2.5210e-05, 1.2081e-05,\n",
       "         2.5436e-04, 8.3835e-06, 9.6094e-05, 7.4391e-05, 3.1481e-05, 9.8331e-06,\n",
       "         2.7767e-05, 5.7706e-05, 1.4935e-05, 2.3184e-04, 4.8578e-05, 2.5791e-04,\n",
       "         8.4929e-05, 9.9817e-05, 3.6957e-04, 1.2917e-04, 1.1575e-04, 1.6129e-05,\n",
       "         1.7722e-05, 1.1224e-05, 7.4137e-06, 1.3533e-05, 6.6051e-06, 6.7311e-04,\n",
       "         3.7926e-04, 4.1111e-06, 1.0798e-05, 1.7082e-05, 1.2923e-05, 3.3161e-05,\n",
       "         9.9383e-05, 3.2764e-06, 5.7498e-06, 1.2310e-04, 8.5443e-07, 1.7067e-04,\n",
       "         2.8237e-06, 5.1101e-06, 4.3140e-04, 2.9209e-06, 7.4893e-07, 4.2277e-05,\n",
       "         1.0150e-05, 9.5608e-07, 3.0622e-05, 3.6698e-05, 5.7295e-04, 7.2041e-04,\n",
       "         2.1485e-05, 9.8318e-05, 9.6543e-07, 3.8181e-04, 5.5364e-05, 4.4342e-04,\n",
       "         2.1722e-05, 3.3015e-05, 9.5761e-05, 3.5939e-04, 1.0582e-04, 1.7930e-04,\n",
       "         4.3002e-05, 1.3470e-06, 2.3990e-05, 2.3714e-06, 2.5456e-03, 1.4789e-05,\n",
       "         8.7862e-05, 1.0148e-05, 3.4449e-05, 4.0896e-04, 7.3191e-05, 2.6390e-04,\n",
       "         1.2104e-04, 1.3428e-04, 2.5137e-05, 3.8369e-06, 1.5770e-03, 3.0641e-03,\n",
       "         1.3813e-06, 2.0127e-06, 1.4407e-04, 1.4167e-06, 3.4415e-04, 3.2828e-04,\n",
       "         6.5321e-05, 1.9232e-05, 4.2984e-06, 1.9398e-04, 1.5525e-05, 4.2986e-05,\n",
       "         1.2363e-05, 7.5111e-06, 8.0361e-05, 1.4307e-04, 2.5444e-05, 4.6221e-05,\n",
       "         3.9007e-06, 5.6190e-05, 5.3929e-05, 6.1021e-05, 2.4684e-04, 2.1300e-05,\n",
       "         3.7866e-04, 9.6809e-06, 1.1520e-05, 4.9562e-05, 2.8033e-06, 1.9247e-04,\n",
       "         2.3838e-04, 4.0666e-04, 4.2154e-05, 3.8946e-06, 1.0658e-03, 2.8194e-05,\n",
       "         8.6722e-05, 3.7923e-05, 1.1760e-04, 4.1023e-06, 8.9321e-05, 7.9543e-05,\n",
       "         6.9147e-05, 6.9227e-05, 5.7675e-04, 1.8848e-05, 1.0828e-05, 3.7085e-05,\n",
       "         2.3526e-05, 1.5409e-04, 5.8134e-05, 1.0719e-06, 7.5508e-05, 4.8888e-04,\n",
       "         5.8068e-05, 1.0370e-05, 2.8771e-05, 7.1680e-05, 1.5965e-04, 1.2962e-05,\n",
       "         5.1206e-04, 6.0527e-04, 3.8505e-05, 2.7069e-04, 4.5796e-06, 9.6017e-05,\n",
       "         1.8353e-04, 4.6264e-05, 3.0011e-05, 3.3352e-05, 9.2045e-05, 1.0810e-04,\n",
       "         2.8468e-04, 1.0291e-05, 1.0841e-05, 6.5262e-04, 7.3910e-05, 3.3837e-03,\n",
       "         4.5489e-03, 1.7458e-05, 2.8189e-05, 8.5715e-06, 4.3017e-05, 1.6909e-04,\n",
       "         4.6609e-05, 5.2260e-05, 2.4317e-04, 1.4789e-05, 4.2718e-05, 1.0860e-05,\n",
       "         1.1304e-06, 2.6998e-04, 2.2088e-04, 2.6112e-06, 2.3875e-04, 5.8933e-06,\n",
       "         5.1019e-06, 7.4666e-05, 8.3167e-05, 3.9071e-04, 1.3249e-05, 4.2179e-05,\n",
       "         1.6010e-05, 7.5442e-06, 1.7528e-05, 1.5821e-06, 4.1938e-05, 1.7008e-05,\n",
       "         4.0298e-06, 2.6173e-06, 2.8849e-05, 7.2089e-05, 1.4812e-04, 1.1428e-05,\n",
       "         4.2063e-06, 7.1250e-05, 5.3353e-06, 7.2755e-05, 6.2834e-04, 1.7374e-05,\n",
       "         1.2921e-04, 4.4171e-03, 1.1611e-04, 1.7398e-04, 1.9486e-05, 6.7039e-05,\n",
       "         1.2934e-04, 7.6813e-05, 1.7483e-04, 1.5314e-04, 1.7030e-06, 8.2665e-05,\n",
       "         1.2834e-05, 2.3240e-04, 2.6829e-06, 2.2550e-03, 7.2787e-05, 2.1691e-04,\n",
       "         2.8386e-03, 2.2084e-04, 1.4438e-04, 1.5918e-04, 1.0508e-05, 1.2649e-04,\n",
       "         2.1065e-04, 2.0151e-04, 2.9455e-04, 3.2636e-05, 1.7107e-05, 2.7951e-06,\n",
       "         2.3007e-03, 2.1466e-05, 1.5797e-05, 2.0963e-05, 1.0637e-04, 7.1129e-04,\n",
       "         3.6531e-05, 3.1641e-02, 7.1389e-06, 1.0105e-04, 2.2049e-04, 3.7678e-05,\n",
       "         6.5574e-06, 1.6942e-05, 2.8255e-05, 1.5564e-04, 1.0220e-05, 1.4840e-04,\n",
       "         1.4311e-05, 2.8002e-05, 9.3054e-06, 1.6721e-03, 1.4085e-05, 1.0377e-04,\n",
       "         4.4438e-05, 4.4988e-04, 1.7736e-06, 3.3309e-04, 8.1552e-05, 1.0692e-05,\n",
       "         5.3870e-05, 3.3813e-05, 2.8716e-05, 1.3692e-03, 6.8786e-05, 9.6520e-05,\n",
       "         1.8917e-04, 3.2386e-05, 5.2978e-05, 5.5868e-05, 2.8500e-05, 9.7494e-06,\n",
       "         6.8911e-06, 9.7634e-06, 1.8968e-05, 5.4066e-05, 1.7598e-05, 1.4758e-04,\n",
       "         5.1210e-06, 5.5544e-06, 3.6189e-06, 2.0684e-05, 1.8916e-05, 1.7316e-05,\n",
       "         1.6756e-04, 4.5580e-04, 6.5160e-05, 4.6477e-04, 1.2890e-05, 2.2054e-05,\n",
       "         1.5511e-06, 6.9138e-05, 3.1977e-05, 2.8248e-04, 9.1447e-06, 1.2261e-04,\n",
       "         2.1079e-04, 1.3489e-05, 4.5868e-06, 4.3971e-05, 3.0261e-04, 2.3575e-02,\n",
       "         6.3656e-05, 5.3993e-04, 5.4257e-05, 1.9217e-05, 1.0067e-05, 2.8333e-03,\n",
       "         3.4475e-05, 5.2168e-04, 2.0010e-05, 3.0142e-04, 2.7610e-05, 1.7192e-03,\n",
       "         1.0954e-04, 2.4109e-05, 8.0169e-06, 3.1345e-04, 2.1365e-05, 2.5940e-05,\n",
       "         4.6200e-05, 4.7192e-05, 2.5922e-05, 7.1724e-06, 1.3604e-05, 4.0968e-05,\n",
       "         1.3145e-05, 5.0354e-05, 7.6766e-05, 1.9847e-05, 2.6462e-05, 3.2505e-05,\n",
       "         7.8612e-06, 1.9741e-05, 4.8420e-06, 5.2472e-04, 7.5756e-05, 3.0431e-05,\n",
       "         4.3261e-06, 1.8028e-05, 5.3727e-06, 5.0332e-06, 6.0358e-05, 1.0114e-04,\n",
       "         3.4407e-05, 2.1365e-05], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.1.layer.0.SelfAttention.q.weight': tensor([[6.0110e-06, 3.0363e-06, 1.9918e-07,  ..., 2.3418e-06, 3.2816e-07,\n",
       "          1.6967e-07],\n",
       "         [2.0394e-08, 6.5653e-09, 3.9025e-08,  ..., 3.4202e-09, 4.4194e-08,\n",
       "          1.3566e-09],\n",
       "         [1.4645e-07, 2.0000e-08, 9.7073e-08,  ..., 4.7762e-08, 6.3318e-07,\n",
       "          1.6679e-08],\n",
       "         ...,\n",
       "         [3.8728e-07, 1.5981e-07, 6.9882e-08,  ..., 1.1949e-07, 4.8463e-07,\n",
       "          3.2133e-08],\n",
       "         [5.3841e-07, 2.1862e-07, 1.3354e-07,  ..., 2.4214e-07, 4.2126e-07,\n",
       "          3.8734e-08],\n",
       "         [1.1466e-07, 4.8612e-08, 5.7680e-07,  ..., 3.5628e-08, 3.3817e-07,\n",
       "          3.6057e-08]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.1.layer.0.SelfAttention.k.weight': tensor([[4.3936e-09, 2.9139e-09, 1.7895e-10,  ..., 2.1009e-09, 7.1396e-10,\n",
       "          4.1880e-10],\n",
       "         [5.4937e-08, 3.7245e-08, 8.3182e-10,  ..., 2.5580e-08, 3.1963e-09,\n",
       "          3.9908e-09],\n",
       "         [1.8881e-09, 7.3837e-10, 1.0987e-10,  ..., 9.9250e-11, 6.6042e-10,\n",
       "          3.0853e-10],\n",
       "         ...,\n",
       "         [1.8187e-09, 1.1187e-09, 1.1170e-10,  ..., 1.0635e-09, 3.2071e-10,\n",
       "          2.0256e-10],\n",
       "         [1.0545e-09, 2.1403e-09, 5.7031e-10,  ..., 1.8035e-09, 5.6759e-10,\n",
       "          3.9620e-10],\n",
       "         [2.2813e-09, 1.5486e-09, 4.0556e-10,  ..., 8.2161e-10, 1.2503e-09,\n",
       "          4.1656e-10]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.1.layer.0.SelfAttention.v.weight': tensor([[3.6993e-08, 1.4607e-08, 1.2415e-09,  ..., 1.3649e-08, 5.0888e-09,\n",
       "          1.0916e-09],\n",
       "         [6.0587e-09, 9.8568e-10, 1.4623e-09,  ..., 3.7030e-09, 3.9820e-09,\n",
       "          1.3272e-09],\n",
       "         [1.3665e-07, 4.9583e-08, 4.5278e-09,  ..., 4.5942e-08, 9.0741e-09,\n",
       "          1.4666e-09],\n",
       "         ...,\n",
       "         [6.6746e-09, 6.6333e-09, 3.6760e-09,  ..., 7.0154e-09, 1.7766e-08,\n",
       "          9.2757e-09],\n",
       "         [1.5450e-09, 1.0015e-09, 3.9083e-10,  ..., 6.2789e-10, 4.1866e-09,\n",
       "          1.3096e-09],\n",
       "         [3.4224e-10, 8.1998e-10, 4.0197e-09,  ..., 1.3959e-09, 7.9358e-09,\n",
       "          1.7070e-09]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.1.layer.0.SelfAttention.o.weight': tensor([[1.8081e-08, 9.9771e-09, 5.4081e-09,  ..., 3.4779e-08, 1.1909e-09,\n",
       "          1.3280e-08],\n",
       "         [2.3906e-09, 2.4069e-09, 4.4157e-09,  ..., 8.5427e-09, 6.3284e-10,\n",
       "          3.8857e-09],\n",
       "         [2.3342e-08, 4.1620e-08, 1.5206e-09,  ..., 7.2916e-09, 8.0702e-10,\n",
       "          2.6831e-09],\n",
       "         ...,\n",
       "         [4.2523e-08, 6.3756e-08, 8.0702e-09,  ..., 4.2947e-08, 2.5329e-09,\n",
       "          2.3289e-08],\n",
       "         [6.2026e-08, 1.2449e-07, 5.7566e-09,  ..., 2.5876e-08, 3.6960e-09,\n",
       "          1.0322e-08],\n",
       "         [1.2054e-08, 1.8454e-08, 1.4117e-09,  ..., 1.0332e-08, 1.3231e-09,\n",
       "          1.9391e-09]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.1.layer.0.layer_norm.weight': tensor([4.8511e-04, 8.3770e-06, 2.0014e-05, 7.0042e-05, 9.7584e-01, 1.7102e-04,\n",
       "         2.5916e-05, 4.6702e-05, 2.5980e-04, 2.5846e-05, 8.1002e-05, 3.2673e-04,\n",
       "         2.6927e-04, 3.7954e-04, 2.1436e-04, 4.0603e-05, 1.4095e-04, 3.5781e-05,\n",
       "         3.1533e-05, 6.4924e-04, 1.6429e-04, 2.9898e-05, 4.1034e-05, 6.6917e-03,\n",
       "         1.3951e-05, 1.0415e-04, 6.9686e-05, 3.8376e-04, 1.4010e-04, 3.7831e-05,\n",
       "         1.7750e-05, 3.8224e-05, 2.6193e-05, 4.9858e-05, 2.9360e-04, 8.9020e-04,\n",
       "         8.1417e-05, 4.3368e-05, 1.2351e-05, 1.2354e-04, 7.7152e-05, 2.9915e-05,\n",
       "         1.7159e-04, 8.2892e-05, 8.7343e-05, 2.8561e-04, 4.7410e-02, 9.4922e-05,\n",
       "         3.5267e-04, 8.5932e-04, 6.9470e-05, 4.0706e-05, 1.9718e-03, 6.9391e-04,\n",
       "         4.1935e-05, 7.3711e-05, 1.2520e-04, 8.1417e-06, 2.7177e-04, 7.9861e-05,\n",
       "         8.7697e-05, 2.5777e-04, 2.5314e-05, 9.0872e-06, 1.0137e-04, 1.0514e-04,\n",
       "         1.1233e-04, 2.0153e-04, 2.3732e-03, 2.7701e-04, 3.1787e-05, 8.4281e-06,\n",
       "         4.7070e-05, 2.0000e-05, 3.3119e-04, 5.5541e-05, 2.5121e-04, 1.2376e-03,\n",
       "         1.8332e-04, 1.3803e-04, 1.1058e-04, 9.3457e-04, 1.8905e-05, 2.2741e-05,\n",
       "         7.5280e-05, 4.7576e-04, 1.1047e-04, 8.0690e-05, 2.5399e-05, 1.2593e-03,\n",
       "         7.2525e-04, 9.3094e-05, 1.0536e-03, 7.4261e-05, 6.9602e-05, 9.5781e-06,\n",
       "         1.1527e-02, 5.4322e-04, 7.4429e-05, 3.1030e-04, 3.8510e-05, 3.3244e-05,\n",
       "         1.2225e-04, 1.2629e-04, 4.2524e-05, 1.5889e-05, 9.2151e-04, 2.6979e-06,\n",
       "         1.0848e-04, 1.9075e-04, 1.0530e-05, 2.7017e-04, 1.0466e-05, 6.3746e-05,\n",
       "         9.1288e-05, 1.2655e-04, 9.8566e-05, 5.1278e-05, 3.9686e-04, 2.2620e-05,\n",
       "         4.1436e-05, 1.6820e-04, 1.0646e-05, 7.9086e-04, 1.2186e-04, 1.5140e-04,\n",
       "         1.0569e-04, 1.2045e-04, 3.3489e-05, 2.8084e-05, 5.3384e-04, 4.6277e-05,\n",
       "         2.2953e-04, 9.5630e-05, 5.0516e-05, 9.2545e-05, 5.3366e-06, 1.1050e-04,\n",
       "         6.4574e-05, 3.3316e-05, 1.3734e-04, 4.8530e-04, 2.4197e-05, 6.4722e-04,\n",
       "         3.2393e-04, 5.1894e-05, 1.2905e-03, 7.2371e-04, 1.1238e-04, 1.3843e-01,\n",
       "         5.8810e-05, 4.2130e-05, 1.2153e-04, 8.1490e-04, 1.6250e-04, 1.1437e-03,\n",
       "         7.6639e-04, 7.6107e-05, 2.8138e-05, 1.0155e-03, 2.4513e-04, 6.5399e-05,\n",
       "         4.5346e-04, 1.4127e-04, 3.0468e-05, 3.5192e-05, 6.4440e-04, 2.3036e-04,\n",
       "         1.6479e-04, 7.2155e-05, 2.2851e-04, 1.8111e-04, 5.9685e-04, 3.9025e-05,\n",
       "         1.3371e-04, 9.9615e-05, 3.5801e-04, 1.5743e-04, 3.9427e-05, 6.6139e-05,\n",
       "         2.1563e-05, 6.2110e-05, 4.1242e-03, 1.0953e-05, 3.0657e-04, 3.0873e-04,\n",
       "         1.2608e-04, 1.0473e-04, 3.8269e-05, 4.8763e-05, 3.1349e-04, 1.3306e-04,\n",
       "         1.3338e-04, 1.5175e-04, 2.7104e-04, 3.8632e-05, 6.5427e-05, 2.7039e-05,\n",
       "         8.6307e-05, 6.2723e-05, 2.3468e-05, 4.9108e-05, 5.1083e-05, 2.0104e-03,\n",
       "         3.3593e-05, 1.1210e-04, 3.3451e-04, 3.8128e-05, 1.8763e-05, 5.5865e-05,\n",
       "         2.7361e-04, 3.3220e-06, 1.4446e-04, 3.1502e-04, 1.8218e-05, 1.2653e-04,\n",
       "         1.0831e-04, 1.2002e-05, 1.0055e-04, 5.0296e-04, 1.9649e-04, 1.9791e-04,\n",
       "         4.5901e-05, 7.0712e-05, 1.0391e-03, 6.9533e-05, 7.3273e-04, 2.6396e-04,\n",
       "         2.8177e-04, 1.4673e-04, 8.5021e-06, 1.3778e-04, 4.5677e-02, 1.0671e-04,\n",
       "         9.1763e-04, 3.3859e-05, 2.1861e-04, 2.0364e-04, 5.1307e-05, 1.6327e-03,\n",
       "         4.3029e-04, 1.5404e-05, 7.7064e-05, 4.8769e-04, 9.4212e-05, 9.5182e-02,\n",
       "         3.9359e-05, 2.8274e-04, 3.5529e-03, 1.2310e-04, 9.6345e-04, 4.2500e-05,\n",
       "         3.9276e-05, 2.2200e-04, 2.7516e-05, 7.2106e-05, 1.9465e-05, 2.8961e-04,\n",
       "         2.9055e-04, 9.1422e-05, 3.0514e-05, 5.1854e-04, 1.3647e-04, 1.8533e-03,\n",
       "         1.3436e-05, 3.1061e-05, 1.5654e-04, 1.2239e-04, 9.3838e-05, 9.1068e-05,\n",
       "         4.1140e-04, 5.3052e-05, 1.8028e-04, 1.1116e-03, 2.5753e-05, 2.4775e-04,\n",
       "         3.6675e-04, 2.0080e-04, 7.1985e-05, 7.1313e-05, 5.0525e-05, 9.6208e-05,\n",
       "         1.3559e-04, 1.3073e-04, 1.0466e-04, 5.7549e-05, 7.4498e-04, 8.3463e-05,\n",
       "         1.5955e-03, 1.9589e-04, 2.6143e-04, 3.5575e-05, 4.2161e-04, 1.7886e-05,\n",
       "         3.2069e-05, 1.7616e-03, 1.5095e-05, 1.1080e-04, 1.4826e-05, 2.6578e-05,\n",
       "         7.5417e-06, 5.8192e-06, 5.2380e-06, 6.9465e-05, 2.8614e-04, 7.0737e-06,\n",
       "         8.8883e-05, 1.0873e-02, 9.0025e-05, 1.6301e-04, 1.3606e-05, 1.2114e-04,\n",
       "         8.9866e-04, 5.3712e-05, 1.2173e-05, 2.9226e-05, 9.7806e-05, 1.4933e-04,\n",
       "         3.9695e-03, 7.7540e-05, 3.1816e-05, 2.8462e-05, 6.9447e-04, 9.2051e-03,\n",
       "         4.4107e-03, 2.3612e-05, 4.2151e-05, 8.7054e-06, 6.9558e-05, 1.7996e-04,\n",
       "         7.7898e-04, 2.4223e-05, 2.7353e-04, 2.5310e-04, 3.7363e-04, 8.8204e-05,\n",
       "         7.5120e-05, 4.3586e-04, 7.1233e-04, 9.6961e-05, 9.8889e-05, 4.8931e-05,\n",
       "         8.6995e-06, 6.8361e-05, 1.0574e-05, 1.7753e-03, 2.9729e-05, 1.2211e-04,\n",
       "         3.5024e-05, 1.9016e-06, 9.0455e-05, 1.4588e-03, 9.5072e-05, 4.7253e-05,\n",
       "         2.3256e-04, 2.6315e-05, 8.4393e-06, 7.2141e-06, 1.0295e-04, 4.1979e-05,\n",
       "         9.0441e-05, 8.8213e-04, 2.2375e-05, 4.4962e-05, 6.0440e-05, 1.3156e-04,\n",
       "         2.0672e-04, 9.2737e-02, 1.3262e-04, 8.2986e-04, 1.0814e-04, 4.1340e-04,\n",
       "         9.0419e-05, 1.8250e-04, 9.1638e-04, 1.2880e-04, 1.7701e-05, 1.9603e-04,\n",
       "         1.0407e-04, 6.0926e-05, 2.8091e-05, 2.1284e-03, 2.3197e-04, 4.6499e-05,\n",
       "         4.1972e-05, 3.4992e-05, 3.5072e-04, 1.0456e-04, 1.2795e-04, 2.5961e-04,\n",
       "         2.2365e-04, 1.7590e-04, 1.1119e-03, 3.4287e-04, 8.4677e-05, 5.4949e-05,\n",
       "         4.0868e-04, 6.5750e-05, 9.8483e-05, 2.6943e-05, 1.8297e-04, 5.4092e-05,\n",
       "         3.2835e-04, 3.1267e-02, 3.6742e-05, 2.1508e-05, 1.5723e-04, 9.0445e-05,\n",
       "         8.0468e-05, 6.7144e-04, 1.9560e-04, 5.9993e-04, 2.1310e-04, 1.0811e-03,\n",
       "         1.2710e-04, 1.4741e-04, 6.6820e-04, 1.5164e-04, 4.6952e-05, 1.2592e-05,\n",
       "         8.5589e-05, 1.6498e-03, 2.4113e-05, 2.7624e-05, 1.1998e-04, 1.8108e-04,\n",
       "         2.4229e-04, 2.1643e-04, 3.0305e-04, 2.7172e-05, 4.8896e-04, 2.8641e-04,\n",
       "         4.6041e-05, 1.4984e-04, 1.0743e-04, 3.0912e-05, 2.5111e-04, 2.8850e-04,\n",
       "         2.1391e-04, 2.6639e-05, 2.1754e-04, 1.7189e-05, 2.7949e-05, 2.9284e-05,\n",
       "         7.6824e-05, 6.8732e-06, 6.1844e-05, 1.8163e-05, 1.1235e-04, 3.9747e-05,\n",
       "         2.1220e-05, 1.1265e-04, 4.6586e-04, 5.9989e-04, 2.0692e-04, 1.3162e-04,\n",
       "         1.1801e-04, 2.1229e-04, 3.3058e-05, 1.3521e-04, 5.6295e-05, 4.2601e-04,\n",
       "         3.0864e-05, 6.8331e-05, 2.1508e-05, 4.8292e-05, 4.0704e-05, 9.8628e-03,\n",
       "         2.0659e-04, 1.0519e-03, 1.1125e-05, 1.1439e-04, 4.7843e-05, 2.2716e-04,\n",
       "         4.2370e-05, 1.5281e-02, 2.1150e-04, 2.5671e-04, 3.0108e-05, 9.3554e-04,\n",
       "         4.8693e-05, 3.6952e-05, 2.7840e-04, 1.9320e-04, 2.8987e-04, 1.5884e-04,\n",
       "         1.6963e-04, 3.3758e-04, 4.2136e-05, 9.1499e-05, 7.0598e-06, 3.4637e-04,\n",
       "         2.2231e-04, 4.3420e-05, 4.2811e-04, 1.6994e-05, 7.2654e-06, 4.8908e-04,\n",
       "         1.4854e-04, 9.9766e-04, 2.0053e-05, 2.1608e-03, 8.1371e-05, 2.7991e-05,\n",
       "         5.0126e-05, 3.2834e-05, 7.8927e-06, 6.9320e-05, 3.3201e-04, 5.3829e-05,\n",
       "         2.2299e-04, 8.5952e-04], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.1.layer.1.EncDecAttention.q.weight': tensor([[1.7514e-07, 2.8291e-07, 4.1732e-08,  ..., 7.2292e-08, 2.1450e-07,\n",
       "          8.6590e-08],\n",
       "         [5.2155e-06, 5.0122e-06, 2.3240e-07,  ..., 2.6855e-06, 4.8992e-07,\n",
       "          4.2686e-07],\n",
       "         [6.7656e-07, 1.5312e-06, 7.5837e-08,  ..., 4.2025e-07, 4.3601e-07,\n",
       "          1.2503e-07],\n",
       "         ...,\n",
       "         [9.4463e-06, 8.2467e-06, 4.2821e-07,  ..., 4.4109e-06, 6.5469e-07,\n",
       "          6.2246e-07],\n",
       "         [9.7691e-07, 9.7314e-07, 2.4723e-07,  ..., 1.5993e-08, 1.4881e-06,\n",
       "          9.4366e-07],\n",
       "         [7.7587e-07, 4.7926e-07, 1.1724e-07,  ..., 7.9928e-08, 6.9850e-07,\n",
       "          3.9041e-07]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.1.layer.1.EncDecAttention.k.weight': tensor([[6.9455e-08, 3.4699e-08, 1.3662e-08,  ..., 1.8912e-08, 4.3604e-08,\n",
       "          6.1903e-08],\n",
       "         [1.7362e-08, 2.5249e-08, 7.9959e-09,  ..., 2.3128e-08, 1.1521e-08,\n",
       "          1.3309e-08],\n",
       "         [7.1974e-08, 3.5468e-08, 8.9017e-09,  ..., 1.7608e-08, 1.7334e-08,\n",
       "          9.4688e-08],\n",
       "         ...,\n",
       "         [5.9736e-09, 1.5891e-08, 1.8327e-08,  ..., 1.0684e-07, 1.2448e-08,\n",
       "          5.1948e-08],\n",
       "         [1.8592e-08, 5.3791e-08, 6.8000e-08,  ..., 3.1490e-07, 1.0411e-08,\n",
       "          6.0142e-08],\n",
       "         [3.0331e-08, 8.7451e-08, 1.1111e-07,  ..., 5.7177e-07, 1.3676e-08,\n",
       "          7.1581e-09]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.1.layer.1.EncDecAttention.v.weight': tensor([[4.2887e-09, 9.7530e-09, 5.9022e-09,  ..., 1.1288e-08, 3.3326e-09,\n",
       "          1.0410e-08],\n",
       "         [2.1960e-08, 8.9891e-08, 5.6974e-09,  ..., 8.8856e-09, 7.1215e-09,\n",
       "          7.2920e-08],\n",
       "         [2.1474e-08, 4.4508e-08, 7.1482e-08,  ..., 2.3722e-07, 2.9962e-08,\n",
       "          1.0043e-07],\n",
       "         ...,\n",
       "         [7.9957e-07, 6.7895e-08, 3.2547e-08,  ..., 5.7764e-07, 4.2370e-08,\n",
       "          1.3790e-07],\n",
       "         [1.3635e-06, 9.1543e-08, 2.7005e-08,  ..., 5.6784e-07, 1.6018e-08,\n",
       "          2.2907e-08],\n",
       "         [6.3532e-07, 4.4220e-08, 2.5205e-08,  ..., 4.2920e-07, 1.2676e-08,\n",
       "          4.8234e-08]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.1.layer.1.EncDecAttention.o.weight': tensor([[1.4857e-07, 2.4386e-08, 5.9855e-08,  ..., 2.2572e-08, 8.2305e-08,\n",
       "          2.5063e-08],\n",
       "         [3.8196e-08, 8.1289e-09, 4.9339e-08,  ..., 5.1829e-08, 1.2011e-07,\n",
       "          5.4458e-08],\n",
       "         [3.8883e-08, 9.4526e-09, 2.9578e-08,  ..., 8.9544e-08, 2.7459e-07,\n",
       "          1.1825e-07],\n",
       "         ...,\n",
       "         [1.3847e-07, 2.2461e-08, 1.8395e-07,  ..., 2.1952e-07, 4.2075e-07,\n",
       "          1.9034e-07],\n",
       "         [2.7868e-07, 2.6169e-08, 2.3595e-07,  ..., 6.5063e-07, 1.8069e-06,\n",
       "          5.9531e-07],\n",
       "         [9.7399e-08, 2.2154e-08, 4.2949e-08,  ..., 1.3202e-07, 5.4902e-07,\n",
       "          1.9258e-07]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.1.layer.1.layer_norm.weight': tensor([7.4992e-03, 3.7295e-04, 2.3112e-05, 1.3125e-03, 7.8625e-01, 6.3987e-03,\n",
       "         1.5955e-03, 1.1569e-03, 3.6972e-03, 8.5113e-04, 1.0866e-04, 1.3129e-03,\n",
       "         1.2120e-03, 1.0290e-04, 2.2723e-03, 4.1645e-04, 4.2434e-05, 3.1388e-05,\n",
       "         1.5522e-03, 5.5460e-05, 7.5757e-03, 4.3256e-05, 2.5931e-04, 4.5413e-03,\n",
       "         7.6481e-05, 3.8738e-04, 1.9654e-03, 1.4589e-03, 6.0965e-04, 3.2218e-04,\n",
       "         3.3994e-04, 5.9070e-04, 7.6922e-05, 5.8036e-04, 6.0314e-03, 4.7375e-03,\n",
       "         3.7450e-04, 8.4000e-04, 3.2377e-04, 4.0235e-03, 1.1183e-03, 2.5880e-04,\n",
       "         1.7476e-02, 3.1696e-03, 3.0538e-03, 8.0827e-03, 2.8482e-02, 3.7384e-03,\n",
       "         6.4419e-05, 1.1865e-04, 1.7899e-03, 4.0961e-04, 3.2335e-03, 1.6807e-02,\n",
       "         3.4616e-04, 8.3698e-03, 5.7698e-03, 4.2652e-03, 4.7844e-05, 1.0875e-04,\n",
       "         3.1574e-03, 1.0628e-04, 1.0758e-04, 4.8096e-05, 1.2149e-03, 1.0366e-03,\n",
       "         3.5873e-03, 4.4776e-03, 1.0809e-02, 2.5884e-03, 1.8431e-03, 4.5057e-04,\n",
       "         4.3581e-04, 2.1068e-04, 1.5297e-04, 5.2677e-04, 1.3512e-03, 1.3028e-04,\n",
       "         1.9102e-04, 4.9504e-04, 3.6342e-03, 8.3266e-04, 2.3146e-04, 2.2937e-03,\n",
       "         8.1362e-05, 1.4710e-02, 4.6387e-02, 4.0288e-03, 1.0592e-03, 8.1223e-05,\n",
       "         5.0374e-03, 6.1358e-04, 1.3704e-04, 1.3325e-04, 5.0940e-05, 4.0690e-05,\n",
       "         5.0391e-03, 3.1071e-04, 1.8335e-02, 5.1749e-04, 1.3566e-04, 4.3789e-04,\n",
       "         1.0097e-03, 5.0896e-03, 5.8438e-04, 4.0322e-05, 1.0782e-03, 1.4291e-03,\n",
       "         1.2118e-03, 1.1124e-02, 1.1615e-03, 4.8288e-05, 7.0810e-04, 7.5877e-05,\n",
       "         5.5806e-04, 2.9931e-04, 1.2939e-03, 7.8505e-04, 3.4442e-03, 5.4370e-04,\n",
       "         3.4475e-05, 1.3598e-03, 9.3012e-05, 4.7427e-03, 7.0403e-04, 7.1042e-04,\n",
       "         1.1237e-04, 9.0139e-05, 7.6472e-04, 1.2812e-04, 7.9502e-05, 1.6628e-04,\n",
       "         6.0482e-05, 1.1396e-02, 7.0621e-04, 1.2838e-03, 4.4744e-04, 1.0095e-03,\n",
       "         2.1891e-04, 7.8309e-03, 7.6349e-04, 2.4772e-04, 1.2542e-03, 3.0360e-05,\n",
       "         5.3799e-05, 2.3109e-05, 1.7741e-03, 2.0630e-03, 8.7349e-04, 3.4399e-02,\n",
       "         1.5455e-03, 5.6872e-05, 2.9474e-04, 4.1305e-03, 2.6708e-03, 4.2402e-04,\n",
       "         2.5045e-03, 3.8355e-04, 1.8463e-03, 1.0080e-03, 2.6086e-04, 4.1306e-04,\n",
       "         4.1015e-03, 1.8519e-04, 2.8881e-04, 9.3042e-05, 4.9738e-03, 7.5577e-05,\n",
       "         2.0311e-03, 8.9354e-05, 7.1763e-04, 7.0081e-04, 3.9577e-04, 2.1171e-04,\n",
       "         4.8823e-03, 2.8996e-03, 1.6696e-03, 3.4749e-03, 1.7954e-03, 2.8596e-03,\n",
       "         7.7491e-03, 4.8270e-04, 1.2453e-02, 5.2452e-06, 5.9784e-04, 5.3854e-05,\n",
       "         2.0958e-04, 8.6532e-05, 1.9334e-04, 7.4242e-05, 2.5397e-04, 1.0989e-02,\n",
       "         7.2335e-04, 1.2507e-03, 2.3142e-04, 4.8008e-05, 2.3722e-03, 5.4201e-05,\n",
       "         1.6146e-03, 1.2255e-03, 1.1578e-02, 2.0570e-03, 4.7857e-04, 1.1056e-04,\n",
       "         1.0705e-03, 9.0916e-04, 2.2530e-03, 9.6643e-05, 1.6252e-04, 5.1762e-04,\n",
       "         8.9940e-04, 3.2801e-04, 1.9594e-04, 5.9497e-04, 6.7650e-04, 2.1072e-02,\n",
       "         9.7603e-05, 2.3469e-04, 2.8171e-03, 6.1227e-05, 9.9437e-04, 1.5364e-03,\n",
       "         2.0378e-03, 6.4208e-03, 4.9648e-03, 1.7649e-03, 5.6051e-04, 8.1857e-03,\n",
       "         1.9930e-03, 6.8733e-05, 2.9888e-05, 6.1457e-03, 1.6421e-02, 1.5300e-04,\n",
       "         1.4936e-04, 1.6508e-03, 1.3099e-03, 2.6195e-03, 5.9018e-03, 6.8071e-04,\n",
       "         1.1635e-02, 7.2571e-04, 2.4007e-04, 3.5770e-04, 6.6736e-03, 4.9569e-02,\n",
       "         1.3363e-04, 2.3180e-03, 4.2611e-03, 1.1961e-04, 1.2104e-03, 9.2503e-04,\n",
       "         5.4677e-04, 8.0468e-04, 1.3042e-04, 7.4868e-04, 3.4240e-05, 5.7554e-04,\n",
       "         1.7450e-04, 2.1491e-03, 1.8398e-04, 2.7233e-03, 2.1725e-03, 2.2910e-02,\n",
       "         1.3687e-04, 1.9993e-03, 6.4318e-03, 6.4142e-04, 2.2424e-03, 2.0010e-04,\n",
       "         6.3370e-04, 6.0175e-05, 7.9273e-05, 7.0595e-03, 8.0462e-05, 2.5486e-03,\n",
       "         6.9429e-03, 7.7878e-05, 7.6942e-04, 1.7801e-03, 1.0351e-02, 1.1064e-04,\n",
       "         1.5404e-03, 2.8208e-03, 1.7714e-03, 6.3513e-05, 4.7017e-04, 6.3882e-04,\n",
       "         2.9926e-02, 2.6813e-04, 5.7334e-03, 6.2853e-04, 2.2327e-03, 1.5647e-05,\n",
       "         5.1707e-04, 8.0500e-04, 8.0362e-04, 3.3799e-05, 1.1211e-03, 2.6481e-03,\n",
       "         3.9236e-05, 2.2066e-03, 3.1332e-04, 4.2065e-04, 3.1207e-03, 2.6811e-03,\n",
       "         1.4071e-03, 1.0474e-01, 5.6691e-04, 2.4765e-03, 2.6737e-04, 1.3743e-04,\n",
       "         1.1896e-03, 2.1976e-04, 1.1883e-03, 6.2048e-03, 1.1568e-02, 3.7547e-04,\n",
       "         1.8617e-04, 3.4417e-04, 2.0726e-03, 1.0882e-03, 7.0490e-03, 6.7968e-03,\n",
       "         2.7538e-03, 3.5504e-03, 3.9879e-04, 1.0691e-05, 1.0676e-03, 1.0090e-03,\n",
       "         9.1657e-04, 7.5035e-04, 6.2662e-04, 1.8971e-04, 1.3047e-03, 6.2562e-04,\n",
       "         4.0281e-05, 2.7390e-04, 4.7173e-03, 4.4618e-04, 6.4271e-03, 6.3276e-04,\n",
       "         5.4278e-05, 3.7799e-03, 2.2031e-04, 8.5464e-04, 4.5637e-05, 7.7838e-04,\n",
       "         7.6711e-04, 6.5411e-05, 6.5991e-05, 6.9938e-03, 1.8039e-03, 1.3240e-04,\n",
       "         7.6708e-04, 3.7118e-04, 2.6703e-04, 1.6906e-04, 1.4573e-02, 6.3153e-05,\n",
       "         7.0679e-04, 3.9619e-04, 5.2634e-04, 8.1990e-05, 9.0076e-04, 1.0581e-03,\n",
       "         1.6214e-03, 1.1370e-01, 1.9153e-04, 7.3713e-03, 5.4014e-03, 3.0532e-03,\n",
       "         2.7540e-04, 6.0992e-03, 4.7283e-03, 3.2217e-03, 8.7056e-05, 7.0502e-03,\n",
       "         1.2082e-03, 5.0802e-02, 1.8640e-04, 1.4708e-02, 2.2273e-03, 1.5611e-04,\n",
       "         4.5308e-04, 4.7571e-04, 4.2675e-03, 1.7727e-04, 5.3796e-04, 8.7806e-03,\n",
       "         3.0376e-05, 4.4501e-03, 5.8019e-04, 1.7098e-03, 9.1539e-04, 3.0451e-04,\n",
       "         1.3336e-02, 7.7897e-04, 3.9651e-04, 2.3844e-05, 1.0502e-03, 1.6457e-02,\n",
       "         1.8594e-03, 3.3206e-02, 1.1375e-03, 9.5016e-04, 6.9335e-03, 2.8718e-04,\n",
       "         1.9138e-03, 2.3242e-04, 3.0576e-04, 7.3120e-03, 8.4361e-03, 1.3996e-04,\n",
       "         1.3948e-04, 1.7341e-04, 5.7706e-04, 3.6035e-03, 6.5962e-04, 2.8976e-03,\n",
       "         4.7812e-04, 1.4102e-02, 1.3550e-04, 2.9454e-04, 7.0111e-03, 3.8821e-04,\n",
       "         5.3021e-03, 2.1366e-03, 1.1715e-02, 1.9225e-02, 7.6001e-03, 1.5089e-03,\n",
       "         1.5451e-03, 2.4732e-04, 3.0278e-03, 9.7830e-04, 9.6690e-05, 2.4497e-04,\n",
       "         5.5627e-05, 2.7955e-04, 8.0671e-04, 1.3360e-03, 7.6607e-05, 1.1121e-03,\n",
       "         5.2029e-05, 8.0373e-05, 5.6838e-04, 4.7832e-04, 2.3355e-05, 3.3643e-03,\n",
       "         1.5657e-04, 1.2357e-02, 1.0273e-03, 6.6850e-04, 2.2589e-03, 4.4483e-04,\n",
       "         1.5151e-03, 4.5548e-03, 9.3748e-04, 1.5756e-03, 2.0737e-03, 1.8655e-04,\n",
       "         1.1734e-02, 1.8053e-04, 6.2819e-06, 6.6503e-04, 5.7324e-04, 3.8160e-02,\n",
       "         1.4134e-03, 4.0582e-04, 7.6662e-04, 1.1571e-03, 1.1898e-04, 2.2374e-02,\n",
       "         5.6030e-03, 1.0202e-03, 1.1405e-02, 1.8261e-03, 7.2984e-04, 2.7203e-03,\n",
       "         1.1589e-03, 1.8662e-03, 2.7803e-03, 3.7659e-03, 1.2943e-04, 2.9251e-03,\n",
       "         2.0534e-04, 4.3331e-04, 5.9966e-04, 2.0677e-03, 4.1260e-05, 5.6273e-04,\n",
       "         6.8189e-04, 1.7100e-03, 1.1644e-03, 1.5401e-03, 7.4450e-04, 1.3360e-03,\n",
       "         7.6924e-04, 2.8442e-04, 4.5122e-04, 1.6368e-01, 6.6406e-04, 8.1284e-03,\n",
       "         1.9890e-04, 2.0777e-03, 1.4125e-03, 6.5709e-05, 9.7716e-03, 6.3480e-04,\n",
       "         6.3067e-04, 1.9176e-03], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.1.layer.2.DenseReluDense.wi.weight': tensor([[0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.8069e-08, 1.4579e-09, 9.3010e-09,  ..., 6.6850e-10, 1.1600e-09,\n",
       "          1.1556e-08],\n",
       "         [4.9473e-10, 1.3606e-09, 2.7960e-09,  ..., 5.7419e-09, 2.7788e-11,\n",
       "          2.8252e-09],\n",
       "         ...,\n",
       "         [2.5847e-13, 3.7524e-13, 2.0353e-11,  ..., 9.4657e-14, 1.4573e-12,\n",
       "          5.8160e-12],\n",
       "         [1.0677e-15, 4.7907e-14, 3.2738e-14,  ..., 1.0755e-14, 1.0480e-13,\n",
       "          1.5254e-14],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.1.layer.2.DenseReluDense.wo.weight': tensor([[0.0000e+00, 1.4969e-08, 1.4260e-11,  ..., 9.9260e-12, 1.2854e-14,\n",
       "          0.0000e+00],\n",
       "         [0.0000e+00, 2.5413e-08, 4.4715e-09,  ..., 1.1555e-10, 1.7150e-14,\n",
       "          0.0000e+00],\n",
       "         [0.0000e+00, 2.9698e-08, 8.9494e-09,  ..., 1.3498e-10, 4.2939e-14,\n",
       "          0.0000e+00],\n",
       "         ...,\n",
       "         [0.0000e+00, 3.7882e-08, 2.7351e-10,  ..., 3.2398e-10, 1.2581e-14,\n",
       "          0.0000e+00],\n",
       "         [0.0000e+00, 3.4704e-08, 2.0669e-08,  ..., 1.6669e-10, 9.8226e-13,\n",
       "          0.0000e+00],\n",
       "         [0.0000e+00, 5.9443e-09, 1.8588e-08,  ..., 1.1472e-11, 1.0293e-14,\n",
       "          0.0000e+00]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.1.layer.2.layer_norm.weight': tensor([2.4905e-06, 8.1773e-07, 8.3169e-06, 2.0742e-05, 8.1962e-03, 3.5956e-05,\n",
       "         7.8631e-06, 2.6932e-05, 4.6777e-05, 2.2243e-06, 1.8224e-06, 1.4992e-05,\n",
       "         2.0459e-06, 3.0822e-06, 2.2660e-06, 4.7614e-05, 8.8101e-06, 6.5323e-06,\n",
       "         1.6374e-06, 1.0065e-04, 1.6132e-06, 6.7521e-06, 1.3520e-06, 2.4740e-04,\n",
       "         7.8644e-06, 2.6844e-05, 8.1712e-06, 2.6850e-05, 2.1923e-06, 9.3467e-05,\n",
       "         2.5526e-06, 5.2880e-05, 3.3209e-07, 6.1840e-06, 1.4281e-06, 2.5599e-05,\n",
       "         2.8877e-05, 4.0051e-06, 5.8500e-06, 1.0805e-05, 2.9606e-06, 2.1480e-06,\n",
       "         9.3913e-06, 6.9161e-06, 3.6039e-06, 8.6471e-06, 4.9189e-03, 3.2524e-06,\n",
       "         6.2772e-06, 1.7806e-05, 3.9531e-05, 5.9013e-06, 1.6611e-05, 1.7415e-04,\n",
       "         2.6802e-05, 7.9909e-05, 1.0608e-05, 6.4337e-05, 1.8523e-07, 4.3250e-07,\n",
       "         5.2915e-06, 2.1524e-05, 8.5568e-06, 4.1366e-07, 6.6744e-06, 1.9547e-05,\n",
       "         5.2758e-06, 1.2598e-06, 1.6999e-05, 1.4957e-05, 1.9242e-05, 4.7282e-07,\n",
       "         1.1034e-05, 2.0902e-05, 5.3234e-06, 7.1529e-06, 1.1861e-05, 3.2303e-06,\n",
       "         6.6810e-06, 2.3773e-05, 1.2600e-05, 7.8700e-06, 4.2162e-06, 6.0179e-06,\n",
       "         3.1104e-05, 7.2086e-06, 1.3956e-04, 4.4777e-06, 2.8318e-05, 2.7043e-06,\n",
       "         5.9587e-06, 5.7369e-06, 6.7775e-06, 4.2517e-05, 2.7318e-06, 3.2040e-06,\n",
       "         1.1750e-04, 2.2374e-04, 1.1130e-05, 1.9560e-06, 1.8224e-05, 2.2339e-06,\n",
       "         6.3917e-05, 3.1324e-04, 6.1895e-06, 3.4725e-06, 3.9425e-05, 1.1426e-06,\n",
       "         5.5991e-06, 8.7412e-05, 1.8919e-05, 5.7479e-06, 3.8107e-05, 1.6221e-05,\n",
       "         6.9798e-06, 8.8050e-05, 5.1647e-06, 5.6006e-06, 1.8606e-05, 7.0260e-06,\n",
       "         3.0631e-07, 5.5856e-06, 1.1900e-06, 4.9695e-05, 1.0020e-05, 4.6308e-06,\n",
       "         5.5254e-05, 1.3093e-05, 4.2224e-06, 1.0788e-05, 3.0961e-06, 7.2211e-05,\n",
       "         7.0241e-06, 1.2651e-05, 2.6736e-06, 1.8969e-05, 1.2604e-05, 2.7130e-05,\n",
       "         2.4071e-06, 1.9375e-06, 7.5530e-06, 5.4045e-05, 1.5386e-06, 4.2221e-05,\n",
       "         3.6024e-05, 2.8139e-06, 9.3157e-07, 1.0050e-04, 1.2129e-05, 1.1309e-03,\n",
       "         1.1869e-05, 1.1024e-05, 1.0733e-06, 4.1513e-05, 3.2768e-05, 1.6667e-04,\n",
       "         7.7356e-07, 7.1861e-05, 1.3435e-05, 5.6865e-04, 2.4654e-06, 9.1409e-06,\n",
       "         2.5013e-04, 2.0801e-05, 4.2161e-06, 2.5094e-06, 2.4372e-05, 5.7438e-06,\n",
       "         2.3017e-06, 2.8579e-06, 3.8131e-05, 8.4187e-06, 1.4136e-05, 4.3003e-05,\n",
       "         8.8350e-07, 3.7101e-05, 1.0500e-05, 8.6344e-06, 3.4885e-06, 1.3961e-05,\n",
       "         3.6023e-06, 9.3056e-07, 3.0966e-03, 2.2327e-05, 4.1020e-05, 1.1890e-04,\n",
       "         1.4617e-05, 1.8003e-06, 1.2741e-05, 1.1084e-05, 2.5114e-05, 1.3985e-05,\n",
       "         9.6565e-06, 3.0614e-06, 5.0302e-05, 1.8172e-05, 9.5173e-05, 4.7353e-06,\n",
       "         5.8700e-05, 4.6550e-05, 4.8270e-05, 2.6184e-06, 3.1231e-05, 2.2254e-05,\n",
       "         1.2386e-05, 3.4075e-06, 4.5204e-06, 4.1491e-05, 7.0060e-06, 1.1391e-05,\n",
       "         1.1684e-04, 1.5423e-06, 1.1287e-05, 3.8877e-05, 4.0519e-06, 7.4753e-06,\n",
       "         8.5281e-07, 3.2891e-05, 1.8458e-06, 1.5139e-05, 2.3509e-06, 1.1732e-05,\n",
       "         4.1520e-05, 1.0104e-05, 2.8808e-05, 3.8237e-05, 5.0178e-05, 6.3941e-06,\n",
       "         5.0442e-05, 1.5655e-05, 1.8334e-05, 2.3269e-05, 3.0173e-04, 2.9596e-06,\n",
       "         3.3896e-05, 8.0833e-06, 7.2902e-05, 1.2946e-06, 7.8398e-06, 7.9327e-05,\n",
       "         2.5636e-05, 1.5159e-06, 1.6863e-05, 8.6353e-06, 4.7480e-05, 2.5534e-03,\n",
       "         1.5222e-06, 5.5677e-06, 3.3529e-05, 3.9437e-06, 1.2780e-05, 8.2936e-06,\n",
       "         7.3254e-07, 1.5715e-05, 3.4826e-06, 1.6919e-05, 1.1154e-05, 1.5565e-06,\n",
       "         1.5549e-06, 7.3599e-06, 8.7725e-06, 1.6950e-05, 9.8832e-06, 1.1774e-05,\n",
       "         4.1915e-07, 2.8401e-06, 2.8573e-05, 1.0008e-06, 1.3539e-04, 3.2344e-06,\n",
       "         2.5336e-05, 1.7692e-05, 1.0568e-05, 1.6538e-04, 2.2096e-06, 4.9542e-06,\n",
       "         2.8477e-05, 4.9848e-05, 2.8999e-06, 6.1951e-05, 1.0957e-05, 2.2010e-05,\n",
       "         3.9788e-06, 3.4654e-06, 9.1354e-07, 5.5483e-07, 4.2035e-06, 5.9220e-06,\n",
       "         8.4124e-05, 5.3521e-06, 5.4364e-05, 4.8942e-05, 3.5011e-05, 1.5701e-06,\n",
       "         9.6188e-06, 4.2313e-05, 9.3561e-06, 1.6067e-05, 2.5743e-06, 3.3012e-06,\n",
       "         8.6202e-06, 1.0776e-06, 1.4545e-05, 1.1912e-06, 1.2455e-05, 6.3145e-07,\n",
       "         2.2302e-05, 4.5357e-04, 2.5294e-06, 1.2901e-05, 3.6340e-06, 3.6986e-05,\n",
       "         4.3509e-04, 8.5490e-06, 5.3518e-06, 1.5814e-06, 9.2357e-06, 2.5510e-06,\n",
       "         4.9992e-05, 6.2781e-06, 9.4905e-06, 3.9529e-05, 3.5804e-05, 1.1684e-04,\n",
       "         1.1105e-04, 1.0864e-05, 2.1873e-07, 1.0399e-05, 2.8097e-05, 5.7200e-05,\n",
       "         9.8237e-05, 5.1018e-05, 3.9646e-05, 5.0737e-07, 3.1170e-05, 4.4718e-06,\n",
       "         4.9071e-06, 6.3216e-06, 4.0663e-05, 1.4449e-06, 9.2800e-05, 3.0872e-06,\n",
       "         1.3174e-06, 8.0663e-05, 1.3201e-05, 1.0031e-05, 1.5278e-05, 8.2958e-06,\n",
       "         7.9832e-06, 2.6199e-06, 1.0441e-06, 5.3611e-05, 6.5862e-05, 2.2689e-06,\n",
       "         3.9956e-06, 1.1080e-05, 1.5993e-05, 3.7402e-06, 5.3300e-05, 3.0024e-05,\n",
       "         7.8931e-07, 7.3968e-06, 2.7602e-06, 2.9944e-06, 8.0636e-06, 8.6449e-06,\n",
       "         6.8607e-05, 1.6500e-03, 4.6762e-06, 6.3033e-05, 2.1123e-05, 1.7000e-06,\n",
       "         3.8595e-06, 7.1283e-06, 5.5021e-04, 1.7481e-05, 3.3946e-06, 1.0342e-05,\n",
       "         1.1061e-05, 3.1790e-04, 1.0499e-06, 3.1779e-04, 9.6266e-06, 1.0068e-06,\n",
       "         1.5866e-06, 1.8355e-05, 7.1677e-05, 2.6734e-05, 3.7871e-05, 2.0838e-05,\n",
       "         3.8062e-06, 4.4034e-06, 8.1702e-04, 4.4461e-05, 6.5247e-06, 9.4665e-06,\n",
       "         1.5389e-05, 4.1458e-06, 7.8138e-06, 4.0425e-07, 1.4223e-06, 1.8474e-05,\n",
       "         2.5657e-05, 5.6005e-03, 1.1859e-05, 6.2872e-05, 9.0066e-06, 6.7592e-07,\n",
       "         6.3447e-06, 9.8658e-06, 4.1424e-06, 1.8931e-05, 3.4971e-06, 1.2868e-05,\n",
       "         3.6252e-06, 3.6856e-06, 1.5472e-06, 2.9070e-05, 2.2033e-06, 3.4253e-06,\n",
       "         2.3592e-06, 4.7409e-05, 6.1897e-06, 8.2187e-05, 1.9510e-06, 4.4621e-06,\n",
       "         1.7806e-05, 3.4745e-05, 1.1896e-04, 1.4796e-05, 6.7382e-06, 1.5236e-05,\n",
       "         1.5008e-06, 2.9224e-07, 4.5081e-06, 2.2805e-05, 5.0015e-05, 2.3761e-06,\n",
       "         3.6570e-06, 3.9940e-06, 1.5079e-05, 9.5406e-06, 6.7976e-06, 6.7211e-06,\n",
       "         5.4578e-07, 8.0231e-06, 3.3047e-05, 2.9612e-06, 1.5344e-06, 4.2528e-06,\n",
       "         3.3928e-05, 1.7408e-05, 4.5570e-06, 1.1096e-04, 4.9024e-06, 1.2269e-05,\n",
       "         9.8890e-07, 1.1829e-04, 4.9021e-05, 7.3821e-07, 1.4149e-06, 6.0978e-06,\n",
       "         5.3155e-05, 5.7698e-05, 3.3081e-07, 1.6080e-06, 2.6827e-06, 4.1069e-04,\n",
       "         3.0804e-06, 8.2260e-06, 1.6029e-06, 1.1527e-06, 2.9694e-06, 2.9641e-04,\n",
       "         1.2319e-05, 2.8610e-04, 8.5931e-05, 1.3576e-04, 5.7830e-06, 4.6909e-04,\n",
       "         3.2452e-07, 7.7753e-06, 1.0511e-05, 1.6439e-05, 7.3441e-06, 4.6438e-05,\n",
       "         4.9908e-05, 5.2430e-06, 9.1546e-05, 5.5383e-06, 3.0737e-06, 4.9676e-06,\n",
       "         7.6144e-06, 8.8322e-06, 5.6823e-06, 1.3910e-04, 1.0431e-05, 4.1016e-05,\n",
       "         2.2193e-05, 5.7152e-05, 2.3119e-06, 3.9039e-05, 5.7222e-06, 1.1901e-05,\n",
       "         5.7274e-06, 3.0975e-05, 2.6149e-06, 4.0365e-07, 6.9286e-05, 9.2443e-05,\n",
       "         1.2678e-05, 5.5063e-05], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.2.layer.0.SelfAttention.q.weight': tensor([[2.2781e-06, 4.8235e-07, 5.7974e-07,  ..., 8.5698e-08, 3.6006e-07,\n",
       "          3.3354e-07],\n",
       "         [3.1143e-07, 1.3044e-07, 1.0994e-07,  ..., 3.6860e-08, 1.4021e-07,\n",
       "          5.4380e-08],\n",
       "         [6.4029e-08, 7.5920e-08, 5.0959e-08,  ..., 3.7169e-08, 1.1170e-07,\n",
       "          2.0572e-08],\n",
       "         ...,\n",
       "         [2.7624e-09, 4.8125e-09, 4.5043e-08,  ..., 5.6883e-09, 2.6390e-08,\n",
       "          3.6936e-09],\n",
       "         [2.2000e-09, 9.0115e-09, 3.0728e-08,  ..., 4.5331e-09, 2.5560e-08,\n",
       "          1.4725e-09],\n",
       "         [2.0004e-09, 5.9071e-09, 4.2842e-08,  ..., 4.1732e-09, 2.7034e-08,\n",
       "          3.8564e-09]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.2.layer.0.SelfAttention.k.weight': tensor([[9.6645e-09, 3.0011e-09, 3.3447e-09,  ..., 1.5588e-09, 1.6807e-09,\n",
       "          2.2886e-09],\n",
       "         [4.5109e-09, 1.5185e-09, 1.2522e-09,  ..., 7.8769e-10, 1.1133e-09,\n",
       "          1.0938e-09],\n",
       "         [2.4869e-09, 5.8785e-10, 2.5646e-09,  ..., 4.0497e-09, 1.1174e-09,\n",
       "          1.0478e-09],\n",
       "         ...,\n",
       "         [4.0468e-10, 8.8329e-11, 2.9207e-10,  ..., 1.5622e-09, 7.7113e-10,\n",
       "          4.9703e-10],\n",
       "         [9.1741e-10, 1.1925e-10, 6.6603e-10,  ..., 1.2503e-09, 9.3068e-10,\n",
       "          5.9229e-10],\n",
       "         [1.7280e-11, 1.9073e-11, 1.8937e-11,  ..., 3.0404e-10, 8.8335e-11,\n",
       "          2.7118e-11]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.2.layer.0.SelfAttention.v.weight': tensor([[7.6395e-08, 1.8059e-09, 1.8169e-08,  ..., 2.1207e-09, 3.6663e-09,\n",
       "          2.9666e-09],\n",
       "         [4.2343e-08, 2.2215e-09, 9.9994e-09,  ..., 4.6015e-09, 4.7868e-09,\n",
       "          3.7937e-09],\n",
       "         [6.3696e-09, 6.0261e-10, 2.4309e-09,  ..., 4.1563e-09, 6.1198e-09,\n",
       "          5.4807e-09],\n",
       "         ...,\n",
       "         [4.1110e-10, 4.6102e-10, 9.3724e-10,  ..., 3.2429e-09, 2.8039e-09,\n",
       "          4.8465e-09],\n",
       "         [3.9605e-09, 8.3246e-10, 4.0534e-10,  ..., 1.8466e-09, 7.8215e-10,\n",
       "          1.8238e-09],\n",
       "         [6.6526e-09, 3.4786e-09, 2.4360e-09,  ..., 2.6982e-08, 1.2631e-08,\n",
       "          1.9295e-08]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.2.layer.0.SelfAttention.o.weight': tensor([[8.2803e-09, 1.0720e-09, 6.3201e-09,  ..., 6.6333e-09, 7.4827e-09,\n",
       "          1.6959e-08],\n",
       "         [1.7525e-09, 1.9710e-10, 1.4603e-09,  ..., 1.3880e-09, 4.4960e-10,\n",
       "          4.3842e-09],\n",
       "         [2.0182e-09, 1.9403e-09, 7.0853e-10,  ..., 6.6090e-09, 8.6633e-09,\n",
       "          1.6673e-08],\n",
       "         ...,\n",
       "         [2.6106e-09, 2.4807e-09, 4.5079e-09,  ..., 5.7651e-09, 7.4834e-09,\n",
       "          1.5817e-08],\n",
       "         [3.9940e-09, 3.9893e-09, 4.7252e-08,  ..., 1.5431e-09, 2.3767e-09,\n",
       "          7.3189e-09],\n",
       "         [9.1715e-10, 1.9614e-09, 7.1765e-09,  ..., 1.1884e-09, 1.6647e-09,\n",
       "          4.3765e-09]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.2.layer.0.layer_norm.weight': tensor([8.5690e-04, 4.1804e-04, 1.8229e-04, 4.0421e-05, 5.6492e-01, 6.0547e-04,\n",
       "         4.1950e-05, 7.1943e-05, 1.3996e-03, 5.1521e-05, 1.9232e-05, 2.0571e-03,\n",
       "         3.6517e-05, 4.9400e-05, 9.1035e-06, 2.7448e-04, 1.9903e-04, 6.4361e-05,\n",
       "         5.6330e-04, 2.9695e-04, 1.5941e-04, 5.3833e-04, 1.1858e-05, 3.4659e-02,\n",
       "         6.4018e-05, 7.6996e-04, 4.0998e-04, 1.6976e-04, 1.6289e-04, 2.6103e-03,\n",
       "         2.1413e-04, 2.1699e-03, 8.0593e-05, 1.5693e-04, 7.1634e-04, 2.7683e-04,\n",
       "         7.6444e-05, 3.8215e-04, 1.1219e-03, 1.5787e-04, 2.3103e-03, 3.9884e-04,\n",
       "         1.0591e-04, 1.9849e-04, 6.3396e-05, 2.2412e-04, 5.3002e-02, 1.2889e-04,\n",
       "         5.9658e-04, 2.4802e-04, 1.1208e-03, 1.1777e-04, 1.7792e-03, 6.3117e-04,\n",
       "         8.2018e-04, 6.5464e-04, 1.2230e-03, 1.2710e-04, 9.8435e-05, 1.5191e-04,\n",
       "         9.7230e-05, 3.0379e-03, 1.0803e-04, 8.3230e-05, 1.6400e-04, 4.1076e-04,\n",
       "         3.4740e-03, 1.2956e-04, 2.9752e-03, 8.3377e-04, 6.8744e-05, 1.1018e-04,\n",
       "         5.2441e-04, 1.7153e-04, 3.2633e-04, 1.0662e-04, 1.4782e-04, 1.8022e-04,\n",
       "         1.0332e-04, 1.1227e-03, 1.2360e-03, 1.2341e-04, 1.4876e-05, 5.5456e-04,\n",
       "         7.9176e-04, 1.5962e-03, 3.9100e-04, 1.7332e-03, 1.0564e-04, 6.2749e-05,\n",
       "         8.8427e-04, 9.1868e-04, 1.6579e-04, 8.2210e-04, 1.4426e-04, 2.8672e-05,\n",
       "         5.8516e-03, 6.3777e-03, 9.3790e-04, 1.0072e-03, 4.6350e-04, 1.8956e-04,\n",
       "         4.3772e-05, 1.1396e-04, 1.6157e-04, 5.4497e-04, 4.6316e-04, 2.3695e-04,\n",
       "         1.7881e-04, 2.2429e-03, 4.7849e-04, 1.3160e-03, 3.9693e-03, 9.4747e-05,\n",
       "         8.6121e-04, 3.8007e-03, 1.9737e-05, 1.1231e-04, 7.8953e-04, 1.8498e-04,\n",
       "         1.0407e-04, 2.2850e-04, 4.3810e-04, 6.0235e-04, 8.8279e-05, 4.2790e-03,\n",
       "         3.5192e-04, 1.3486e-03, 4.1804e-04, 3.1597e-04, 3.1968e-04, 7.4816e-04,\n",
       "         6.3779e-04, 2.7223e-03, 1.3540e-03, 5.1252e-05, 2.9735e-04, 2.0221e-03,\n",
       "         1.0202e-04, 3.4326e-04, 7.4914e-05, 4.2235e-03, 1.5189e-04, 1.4417e-03,\n",
       "         7.1943e-04, 2.1447e-04, 1.0041e-04, 3.2128e-04, 4.5038e-04, 1.6839e-02,\n",
       "         3.1938e-04, 3.4191e-04, 5.0568e-04, 1.0431e-03, 9.4265e-04, 8.3170e-04,\n",
       "         3.1798e-04, 1.7832e-04, 2.6179e-04, 7.5329e-02, 5.4716e-05, 2.8240e-04,\n",
       "         3.8659e-04, 1.9971e-04, 2.3292e-04, 8.8765e-05, 2.3105e-03, 2.6127e-05,\n",
       "         1.1118e-04, 1.5309e-04, 1.6256e-03, 4.3848e-04, 5.1769e-03, 4.1255e-04,\n",
       "         3.5270e-04, 1.6831e-04, 1.5150e-03, 5.8101e-04, 1.0704e-04, 4.0315e-05,\n",
       "         3.4228e-05, 1.4620e-04, 2.1140e-03, 8.1107e-05, 2.6114e-03, 5.5694e-04,\n",
       "         3.6513e-03, 3.5222e-04, 1.7657e-04, 2.8035e-04, 9.7466e-04, 2.7040e-03,\n",
       "         1.8766e-05, 6.4668e-05, 3.5885e-04, 2.9818e-04, 8.6196e-04, 8.4363e-05,\n",
       "         1.1342e-03, 6.8503e-04, 2.6124e-04, 2.2508e-04, 1.1445e-03, 1.1874e-03,\n",
       "         1.9980e-04, 1.0543e-04, 1.0292e-03, 7.4249e-04, 1.7130e-04, 1.1651e-03,\n",
       "         4.8797e-03, 3.5098e-04, 2.7963e-05, 4.1644e-04, 1.7045e-04, 4.8003e-04,\n",
       "         1.8230e-04, 1.9593e-03, 8.2839e-04, 8.3729e-05, 3.3635e-05, 3.7566e-04,\n",
       "         1.7348e-04, 2.0066e-03, 6.2436e-04, 4.8579e-04, 2.0446e-03, 2.9275e-03,\n",
       "         4.8998e-04, 2.4840e-04, 1.8269e-04, 9.9963e-04, 3.9511e-02, 1.1368e-03,\n",
       "         2.4032e-03, 1.6847e-04, 2.3046e-04, 1.7413e-04, 1.1516e-03, 6.7490e-03,\n",
       "         5.9231e-03, 4.6859e-05, 1.7648e-04, 1.2549e-04, 7.4347e-04, 7.3885e-02,\n",
       "         8.7780e-05, 3.8570e-04, 2.7870e-03, 4.7438e-05, 3.0486e-03, 4.7685e-05,\n",
       "         6.1951e-04, 8.6579e-04, 7.2570e-05, 3.0362e-04, 9.6432e-04, 2.9261e-04,\n",
       "         5.9618e-04, 1.5333e-03, 1.4482e-03, 3.5204e-04, 8.2347e-04, 8.4352e-04,\n",
       "         1.4214e-04, 8.3092e-05, 2.2526e-03, 1.2448e-04, 2.0105e-02, 2.9021e-04,\n",
       "         1.9015e-04, 1.0663e-04, 3.4837e-04, 1.7848e-03, 1.4177e-04, 1.3095e-04,\n",
       "         2.0352e-03, 5.2235e-04, 3.1231e-04, 1.8698e-04, 3.2751e-03, 3.4252e-04,\n",
       "         3.6778e-04, 9.0292e-04, 1.4989e-03, 2.2013e-04, 7.2403e-04, 1.7006e-04,\n",
       "         3.4464e-04, 2.6693e-04, 9.1542e-04, 2.8781e-04, 2.6897e-03, 1.1095e-04,\n",
       "         1.4379e-04, 1.4341e-03, 1.2820e-04, 7.4337e-04, 2.1215e-05, 3.5145e-04,\n",
       "         4.4119e-04, 1.5597e-04, 8.2743e-04, 6.3866e-04, 3.7410e-03, 1.7540e-04,\n",
       "         1.6090e-03, 3.6162e-03, 4.6733e-05, 3.7223e-03, 6.1196e-04, 1.0186e-04,\n",
       "         6.9934e-03, 1.6404e-03, 2.0540e-04, 3.7380e-05, 4.5393e-04, 2.4746e-04,\n",
       "         9.2946e-04, 3.2087e-04, 3.1434e-04, 5.3611e-04, 9.8856e-04, 3.3433e-02,\n",
       "         3.7362e-02, 3.4478e-04, 7.6529e-05, 4.5989e-05, 4.6781e-04, 5.6006e-04,\n",
       "         6.5488e-04, 1.3052e-03, 1.7118e-04, 9.5842e-05, 5.1138e-04, 9.7465e-05,\n",
       "         2.5095e-04, 2.2133e-03, 1.4667e-03, 1.7718e-04, 1.2402e-03, 1.2346e-04,\n",
       "         3.3165e-04, 8.6132e-05, 4.9088e-04, 2.9023e-03, 6.5698e-04, 5.6078e-04,\n",
       "         1.1715e-04, 1.9033e-04, 2.8735e-05, 8.1773e-04, 2.2995e-04, 4.6490e-04,\n",
       "         4.1755e-04, 6.4714e-04, 4.5340e-04, 4.1412e-04, 2.0756e-03, 3.8682e-04,\n",
       "         3.1151e-05, 1.6168e-03, 2.8526e-04, 9.7221e-05, 5.5380e-04, 1.0059e-03,\n",
       "         8.3539e-05, 7.3747e-01, 3.0118e-04, 8.7910e-04, 9.4519e-05, 5.2006e-05,\n",
       "         8.2082e-05, 5.1437e-04, 4.7287e-03, 3.8259e-04, 3.5586e-05, 1.0773e-04,\n",
       "         2.7625e-05, 4.4304e-03, 7.0351e-05, 4.5763e-02, 3.5230e-04, 1.2178e-04,\n",
       "         3.8729e-04, 1.8978e-04, 2.1268e-03, 1.3019e-04, 7.0238e-03, 2.2412e-04,\n",
       "         5.5889e-04, 6.2663e-05, 2.1109e-02, 2.0122e-04, 3.3005e-04, 7.8829e-05,\n",
       "         6.1252e-04, 1.0672e-04, 1.5817e-04, 9.5315e-05, 4.1101e-03, 3.3771e-04,\n",
       "         6.7607e-04, 2.5232e-02, 3.2285e-05, 4.7432e-03, 4.9596e-04, 8.9470e-05,\n",
       "         2.9900e-04, 2.3331e-04, 1.6727e-04, 5.6323e-05, 8.2831e-04, 1.9176e-03,\n",
       "         2.1167e-04, 2.5438e-04, 5.8933e-04, 1.3856e-02, 1.2749e-04, 1.1926e-04,\n",
       "         5.8981e-05, 1.2822e-03, 1.2243e-04, 9.6412e-04, 2.7206e-04, 1.1320e-04,\n",
       "         1.5052e-03, 3.1050e-03, 6.9819e-05, 3.2446e-04, 7.8968e-04, 1.4861e-04,\n",
       "         2.2432e-04, 1.5499e-04, 1.3625e-04, 1.8358e-04, 7.5741e-04, 1.5146e-04,\n",
       "         1.3162e-04, 1.0912e-04, 6.3437e-04, 2.6322e-04, 1.0757e-04, 1.1467e-03,\n",
       "         3.0245e-05, 2.2212e-04, 9.9525e-05, 5.9991e-05, 1.2300e-04, 4.4947e-05,\n",
       "         1.2217e-03, 1.6415e-04, 6.5270e-05, 9.4927e-03, 1.1285e-04, 6.4412e-05,\n",
       "         7.3135e-04, 2.0145e-04, 3.6629e-04, 6.7791e-04, 3.5242e-04, 5.1428e-04,\n",
       "         1.0648e-03, 1.4539e-04, 1.5678e-04, 1.2865e-04, 6.5232e-05, 7.5042e-03,\n",
       "         1.0174e-03, 2.8762e-04, 5.9338e-04, 7.2144e-05, 5.5887e-04, 5.8481e-03,\n",
       "         4.4614e-05, 1.2562e-02, 1.8882e-04, 7.8573e-03, 1.9405e-04, 2.1196e-03,\n",
       "         8.7629e-05, 3.0960e-04, 1.1974e-04, 1.3887e-03, 1.5102e-03, 3.3562e-04,\n",
       "         2.7364e-04, 2.2709e-04, 2.6882e-04, 1.4009e-04, 1.3299e-04, 1.5045e-04,\n",
       "         4.7321e-04, 2.5946e-04, 8.0015e-04, 1.2578e-03, 3.0147e-04, 8.1494e-03,\n",
       "         1.4607e-03, 2.3797e-04, 8.5672e-05, 5.1617e-03, 3.4811e-05, 2.9392e-04,\n",
       "         6.3387e-04, 3.6522e-04, 3.6931e-05, 4.4969e-04, 3.7230e-04, 1.0932e-04,\n",
       "         5.5710e-04, 1.1404e-03], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.2.layer.1.EncDecAttention.q.weight': tensor([[4.0923e-07, 9.0658e-07, 6.9877e-07,  ..., 2.9815e-07, 1.6063e-06,\n",
       "          1.0578e-07],\n",
       "         [3.0218e-07, 1.9461e-07, 1.9439e-06,  ..., 3.0959e-07, 1.8736e-07,\n",
       "          1.2193e-07],\n",
       "         [1.2293e-06, 4.0113e-07, 2.3448e-06,  ..., 4.3951e-07, 4.1815e-07,\n",
       "          1.1962e-07],\n",
       "         ...,\n",
       "         [2.3639e-06, 7.9766e-07, 1.8938e-06,  ..., 2.0956e-07, 9.3080e-07,\n",
       "          2.4065e-07],\n",
       "         [8.0236e-07, 1.0669e-05, 7.4173e-06,  ..., 3.1000e-06, 8.3088e-06,\n",
       "          6.7113e-07],\n",
       "         [1.4561e-06, 1.4623e-06, 1.3421e-06,  ..., 5.1705e-07, 7.0504e-07,\n",
       "          2.9162e-07]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.2.layer.1.EncDecAttention.k.weight': tensor([[7.3354e-08, 7.9888e-08, 4.3623e-08,  ..., 6.3522e-08, 1.9472e-08,\n",
       "          4.3287e-08],\n",
       "         [1.0072e-07, 3.1797e-08, 1.6659e-08,  ..., 2.2871e-08, 3.9864e-09,\n",
       "          1.3212e-07],\n",
       "         [5.0064e-08, 9.8560e-08, 5.2629e-08,  ..., 5.1842e-08, 1.8256e-08,\n",
       "          7.0754e-08],\n",
       "         ...,\n",
       "         [4.1571e-08, 1.4014e-07, 1.0118e-07,  ..., 9.6402e-08, 7.6005e-08,\n",
       "          1.2474e-07],\n",
       "         [6.4760e-08, 1.5463e-07, 1.1583e-08,  ..., 2.2447e-08, 3.2111e-08,\n",
       "          3.2649e-08],\n",
       "         [4.3850e-07, 3.1381e-07, 1.9282e-07,  ..., 2.6727e-07, 4.6474e-08,\n",
       "          7.6563e-07]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.2.layer.1.EncDecAttention.v.weight': tensor([[1.1712e-07, 1.8205e-08, 6.8896e-08,  ..., 3.3463e-08, 2.9105e-08,\n",
       "          1.7924e-07],\n",
       "         [2.0861e-08, 1.2096e-08, 4.6610e-08,  ..., 8.2449e-08, 2.2586e-09,\n",
       "          2.7379e-08],\n",
       "         [2.6564e-08, 7.4733e-09, 8.5742e-09,  ..., 1.0651e-08, 1.6224e-09,\n",
       "          4.0397e-08],\n",
       "         ...,\n",
       "         [2.0069e-07, 1.1731e-07, 2.6967e-09,  ..., 2.4152e-07, 2.7575e-08,\n",
       "          1.8112e-08],\n",
       "         [3.7040e-07, 2.6564e-07, 1.5605e-08,  ..., 2.7997e-07, 4.3404e-08,\n",
       "          1.6801e-07],\n",
       "         [1.3812e-07, 9.2823e-08, 5.4659e-08,  ..., 1.3276e-07, 1.1046e-08,\n",
       "          2.0118e-07]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.2.layer.1.EncDecAttention.o.weight': tensor([[1.2868e-07, 9.6296e-09, 1.1628e-08,  ..., 1.7456e-07, 5.8000e-08,\n",
       "          2.2491e-08],\n",
       "         [5.8233e-08, 3.1310e-08, 2.4526e-07,  ..., 8.9936e-07, 1.8476e-06,\n",
       "          1.0629e-07],\n",
       "         [1.3755e-07, 2.9568e-08, 7.1052e-08,  ..., 8.3769e-07, 2.1229e-06,\n",
       "          8.2707e-08],\n",
       "         ...,\n",
       "         [2.2212e-08, 4.6053e-09, 4.3814e-08,  ..., 5.3964e-08, 5.3792e-09,\n",
       "          3.0262e-08],\n",
       "         [4.7216e-08, 1.7517e-08, 1.1046e-07,  ..., 5.8053e-07, 6.5561e-07,\n",
       "          7.2312e-08],\n",
       "         [4.9115e-08, 6.8320e-09, 4.4773e-09,  ..., 1.6072e-07, 1.6769e-07,\n",
       "          5.5547e-08]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.2.layer.1.layer_norm.weight': tensor([3.5412e-02, 1.4314e-03, 2.1688e-03, 2.8531e-03, 9.2086e+00, 6.6457e-02,\n",
       "         6.4871e-03, 3.5086e-02, 5.4467e-03, 7.7807e-05, 1.1363e-03, 2.4873e-02,\n",
       "         2.5671e-03, 2.8179e-03, 1.2085e-05, 1.0175e-03, 4.1896e-04, 5.0185e-04,\n",
       "         2.0599e-02, 1.1915e-02, 2.4137e-04, 8.0741e-04, 7.6884e-03, 1.6839e-02,\n",
       "         7.1348e-04, 2.3857e-03, 2.4933e-04, 5.4149e-04, 1.0785e-02, 8.6720e-03,\n",
       "         2.3527e-03, 3.0895e-02, 2.6887e-04, 3.9659e-03, 4.0395e-03, 7.9133e-03,\n",
       "         6.1167e-03, 1.4896e-03, 2.4643e-03, 7.3105e-03, 9.3920e-03, 1.2847e-03,\n",
       "         2.5327e-03, 8.0780e-03, 1.4734e-03, 1.1350e-02, 2.2502e-01, 1.1856e-03,\n",
       "         4.1705e-04, 2.7222e-03, 2.0360e-02, 4.1768e-03, 1.9701e-02, 2.3207e-02,\n",
       "         2.0762e-03, 3.9015e-02, 1.1902e-02, 2.7519e-02, 1.8446e-03, 3.8982e-04,\n",
       "         1.0625e-03, 3.2378e-03, 5.9648e-04, 1.2589e-03, 1.3697e-03, 1.6477e-03,\n",
       "         1.7543e-02, 1.5698e-04, 1.5350e-02, 3.6457e-03, 1.7405e-03, 2.1954e-04,\n",
       "         1.4911e-03, 9.9545e-03, 1.4659e-03, 2.9630e-02, 1.7400e-04, 5.2402e-03,\n",
       "         7.9275e-03, 6.0285e-03, 2.3921e-02, 3.6576e-03, 3.1501e-05, 5.1963e-04,\n",
       "         2.2595e-03, 1.7174e-03, 3.1428e-02, 2.1658e-02, 1.1829e-03, 4.6908e-03,\n",
       "         5.2508e-03, 2.1876e-03, 2.9518e-04, 7.4124e-03, 2.6924e-04, 2.2505e-04,\n",
       "         7.1050e-03, 3.4173e-02, 5.5184e-03, 5.3675e-03, 2.5304e-02, 2.7279e-04,\n",
       "         2.7064e-03, 5.3182e-03, 7.8374e-03, 5.9265e-03, 3.2423e-03, 7.6315e-03,\n",
       "         1.1550e-03, 1.1553e-03, 4.5523e-03, 1.3362e-03, 6.2405e-04, 4.4144e-04,\n",
       "         9.1062e-04, 7.5200e-03, 5.1225e-04, 3.1452e-03, 1.0605e-02, 1.4630e-03,\n",
       "         2.1329e-04, 2.1937e-03, 3.5890e-04, 2.4748e-03, 2.1192e-04, 6.2837e-03,\n",
       "         5.7479e-03, 1.8632e-04, 1.2214e-02, 2.7765e-02, 1.3848e-03, 4.2489e-02,\n",
       "         1.3558e-03, 6.0183e-03, 1.3432e-03, 4.9609e-03, 4.4276e-03, 3.5303e-02,\n",
       "         2.0274e-02, 5.0704e-04, 5.1075e-04, 1.0363e-02, 8.6325e-04, 4.3714e-02,\n",
       "         3.0795e-03, 3.7320e-03, 7.7629e-03, 1.9403e-02, 7.6748e-03, 1.8465e-02,\n",
       "         1.3948e-02, 3.0584e-03, 3.7593e-04, 3.5698e-02, 2.8442e-04, 2.9099e-03,\n",
       "         1.2837e-05, 2.3808e-03, 3.3562e-04, 1.5531e-02, 4.1430e-04, 2.7436e-02,\n",
       "         2.8096e-03, 3.5330e-03, 2.9606e-04, 2.9356e-03, 1.1283e-02, 2.8337e-04,\n",
       "         8.8080e-04, 3.3064e-04, 3.7142e-04, 5.2937e-04, 2.1705e-02, 1.1616e-03,\n",
       "         1.3030e-03, 2.0593e-03, 1.6815e-03, 3.8581e-03, 1.1698e-02, 1.1457e-03,\n",
       "         9.4268e-04, 1.7825e-04, 1.0632e-02, 3.9981e-03, 6.0841e-03, 1.5373e-02,\n",
       "         3.8628e-03, 3.9740e-04, 2.9139e-03, 4.2427e-04, 8.4655e-03, 3.0170e-02,\n",
       "         3.9436e-04, 8.8519e-05, 7.0144e-04, 1.1872e-03, 7.9615e-03, 3.7623e-04,\n",
       "         4.7480e-02, 3.0722e-03, 5.9310e-03, 1.7899e-02, 5.1819e-03, 1.8610e-03,\n",
       "         1.7359e-02, 9.3173e-04, 4.6701e-03, 7.3406e-03, 7.1798e-04, 5.7722e-03,\n",
       "         4.4558e-02, 3.7868e-03, 2.4810e-03, 3.0060e-03, 2.8571e-03, 3.4694e-03,\n",
       "         9.9074e-04, 1.7469e-02, 3.6831e-03, 1.3233e-03, 1.2811e-04, 1.9984e-03,\n",
       "         2.9068e-02, 4.3685e-03, 4.6875e-03, 5.3651e-03, 4.0859e-03, 3.6052e-02,\n",
       "         1.0525e-02, 4.8715e-03, 1.4471e-03, 2.5894e-03, 1.8557e-02, 4.4856e-03,\n",
       "         2.9178e-03, 1.0104e-03, 2.3879e-03, 3.6554e-04, 5.0692e-03, 1.0699e-03,\n",
       "         4.1082e-02, 1.5398e-04, 5.0200e-03, 3.9059e-03, 7.3626e-04, 4.2189e-01,\n",
       "         1.0201e-04, 5.8184e-04, 1.6158e-03, 5.8314e-04, 7.0133e-04, 1.0861e-04,\n",
       "         4.7608e-04, 1.9694e-02, 2.2131e-04, 8.3090e-03, 2.7750e-03, 7.1863e-04,\n",
       "         9.6713e-03, 6.5221e-02, 8.3502e-03, 2.5502e-03, 3.9105e-03, 3.5705e-03,\n",
       "         8.6771e-04, 1.6010e-03, 1.4439e-03, 2.1983e-04, 1.5415e-02, 8.6253e-04,\n",
       "         1.4282e-03, 1.7580e-02, 1.0773e-03, 4.6363e-03, 5.6515e-04, 3.7511e-03,\n",
       "         7.9458e-04, 1.0192e-02, 4.3137e-04, 3.6752e-03, 3.4196e-03, 1.4888e-02,\n",
       "         2.1637e-03, 1.9771e-03, 7.6360e-04, 1.4965e-03, 7.3651e-03, 2.8758e-04,\n",
       "         3.3506e-03, 5.7223e-04, 2.3586e-02, 2.7506e-03, 2.9172e-02, 6.6505e-04,\n",
       "         1.7028e-03, 1.5156e-03, 5.2713e-04, 1.3255e-02, 8.7445e-04, 1.3854e-03,\n",
       "         1.9964e-03, 7.2391e-04, 1.0307e-03, 6.6918e-04, 1.4036e-01, 6.7698e-03,\n",
       "         1.2401e-02, 7.2545e-02, 2.7184e-04, 1.2864e-02, 1.0424e-02, 6.1175e-03,\n",
       "         2.9824e-02, 9.7262e-04, 2.4833e-03, 2.0965e-02, 8.4524e-03, 1.0254e-03,\n",
       "         4.8286e-02, 4.0086e-03, 1.7943e-02, 2.9439e-03, 1.9793e-03, 1.2762e-01,\n",
       "         1.9141e-02, 3.2829e-04, 3.9041e-03, 7.9989e-05, 2.3591e-03, 2.2476e-04,\n",
       "         3.4995e-03, 1.8619e-03, 2.5031e-03, 5.0155e-04, 3.8284e-03, 6.6817e-03,\n",
       "         3.4472e-03, 2.0583e-02, 8.6044e-03, 5.1112e-04, 3.1643e-03, 7.1353e-04,\n",
       "         2.2781e-03, 3.3017e-02, 1.3127e-03, 8.8030e-03, 1.1339e-03, 9.0172e-03,\n",
       "         4.1289e-03, 4.4121e-03, 1.1106e-03, 1.0795e-02, 1.8264e-03, 1.5340e-04,\n",
       "         1.4664e-03, 2.0995e-03, 4.5776e-03, 5.6126e-03, 3.0367e-02, 8.8772e-03,\n",
       "         1.1524e-04, 1.9589e-04, 1.9297e-03, 6.6017e-04, 1.8346e-03, 3.0930e-02,\n",
       "         1.5912e-02, 1.4917e+00, 4.3678e-03, 2.2353e-01, 3.0351e-04, 1.1114e-03,\n",
       "         1.1978e-03, 4.0715e-04, 3.0820e-02, 8.7462e-03, 1.5170e-03, 2.3547e-02,\n",
       "         4.2167e-03, 5.1533e-04, 8.1998e-04, 8.4031e-03, 8.9091e-03, 3.5839e-05,\n",
       "         3.2992e-02, 3.6153e-03, 7.0308e-03, 7.1792e-04, 6.5202e-02, 1.5053e-02,\n",
       "         2.8138e-04, 7.6128e-05, 4.7341e-02, 6.4270e-03, 3.7657e-04, 1.8492e-03,\n",
       "         1.0305e-03, 1.1760e-03, 9.8618e-04, 1.3859e-03, 4.9779e-02, 3.9032e-03,\n",
       "         7.2843e-04, 6.6087e-01, 5.7348e-04, 5.6131e-04, 4.9786e-03, 2.3024e-03,\n",
       "         1.1470e-03, 1.0463e-03, 6.9326e-04, 5.6396e-03, 2.5125e-02, 8.1180e-02,\n",
       "         7.7857e-04, 5.9334e-03, 3.2792e-03, 1.6552e-02, 7.8081e-04, 2.9693e-04,\n",
       "         8.9003e-03, 5.8333e-03, 1.3779e-03, 1.0057e-03, 7.0406e-04, 8.3069e-03,\n",
       "         1.9152e-02, 1.7864e-02, 2.4146e-04, 5.0033e-04, 6.5683e-02, 3.6684e-03,\n",
       "         7.9829e-04, 3.3917e-04, 2.9500e-04, 5.2963e-03, 3.8167e-03, 3.3588e-04,\n",
       "         5.0064e-03, 2.9268e-04, 7.8259e-03, 1.7151e-03, 6.6838e-03, 2.8189e-03,\n",
       "         8.8576e-05, 4.0209e-04, 5.8705e-03, 3.8922e-04, 5.9549e-04, 1.4682e-03,\n",
       "         8.4470e-02, 7.2168e-05, 1.0286e-03, 1.2150e-01, 2.2254e-03, 4.1733e-04,\n",
       "         3.5419e-04, 1.6856e-03, 3.2525e-03, 6.9016e-04, 3.0100e-04, 5.6874e-03,\n",
       "         1.4294e-02, 7.1272e-03, 3.9279e-04, 8.3104e-03, 7.8286e-03, 8.2783e-02,\n",
       "         5.0637e-03, 1.3989e-02, 3.8752e-03, 1.6923e-03, 1.8720e-03, 1.1245e-02,\n",
       "         5.2736e-04, 5.4815e-03, 8.9868e-04, 5.0855e-02, 4.6971e-03, 3.9372e-04,\n",
       "         1.5501e-04, 1.2821e-03, 6.1175e-04, 3.5033e-02, 4.3006e-04, 3.3055e-02,\n",
       "         1.6902e-03, 2.8542e-03, 4.4722e-03, 1.4617e-02, 6.1510e-03, 7.1597e-03,\n",
       "         2.5288e-03, 1.7291e-02, 2.3435e-03, 3.6163e-03, 1.8038e-03, 7.0352e-03,\n",
       "         4.4955e-02, 1.1926e-02, 2.3694e-03, 2.6533e-02, 9.7492e-04, 4.5468e-02,\n",
       "         1.3389e-03, 6.4685e-03, 3.7578e-04, 1.4163e-03, 3.0348e-03, 1.9006e-03,\n",
       "         2.9139e-03, 1.5595e-03], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.2.layer.2.DenseReluDense.wi.weight': tensor([[4.4549e-12, 8.9975e-12, 3.7029e-12,  ..., 4.1051e-14, 3.3380e-12,\n",
       "          4.5961e-12],\n",
       "         [6.6983e-13, 1.5944e-13, 3.9229e-16,  ..., 1.3755e-12, 5.7080e-14,\n",
       "          1.5528e-13],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         ...,\n",
       "         [2.0270e-13, 3.8355e-12, 1.9050e-11,  ..., 5.9370e-13, 1.7169e-11,\n",
       "          6.7945e-12],\n",
       "         [8.7280e-14, 1.2693e-09, 2.1252e-11,  ..., 6.1901e-10, 6.6715e-10,\n",
       "          1.1511e-09],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.2.layer.2.DenseReluDense.wo.weight': tensor([[9.7583e-12, 4.2672e-12, 0.0000e+00,  ..., 2.3461e-12, 1.8271e-11,\n",
       "          0.0000e+00],\n",
       "         [7.8362e-12, 9.3103e-13, 0.0000e+00,  ..., 9.8367e-12, 4.0549e-10,\n",
       "          0.0000e+00],\n",
       "         [4.5920e-12, 7.0780e-12, 0.0000e+00,  ..., 2.9204e-12, 5.3190e-11,\n",
       "          0.0000e+00],\n",
       "         ...,\n",
       "         [9.5665e-13, 1.7406e-12, 0.0000e+00,  ..., 0.0000e+00, 4.8086e-10,\n",
       "          0.0000e+00],\n",
       "         [4.5367e-12, 4.7592e-11, 0.0000e+00,  ..., 3.2245e-11, 1.6513e-11,\n",
       "          0.0000e+00],\n",
       "         [2.6136e-12, 5.7450e-13, 0.0000e+00,  ..., 2.5861e-12, 2.1130e-10,\n",
       "          0.0000e+00]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.2.layer.2.layer_norm.weight': tensor([1.9305e-05, 3.4654e-06, 1.0045e-04, 4.0522e-06, 4.2697e-02, 4.0196e-05,\n",
       "         7.3811e-06, 1.1738e-05, 7.7675e-05, 1.9774e-06, 1.2982e-06, 2.7659e-05,\n",
       "         2.0226e-06, 1.4204e-06, 1.9854e-07, 1.1379e-05, 4.8264e-07, 4.3037e-06,\n",
       "         1.5821e-05, 1.8386e-06, 5.4380e-06, 9.1015e-06, 9.6509e-06, 5.0771e-05,\n",
       "         1.2761e-06, 7.0440e-05, 3.2524e-06, 1.0519e-05, 1.4974e-05, 1.7007e-05,\n",
       "         8.0438e-06, 1.7754e-05, 3.6103e-06, 3.1229e-06, 2.9152e-06, 1.5799e-05,\n",
       "         2.6509e-06, 3.2686e-06, 9.5411e-05, 3.5699e-05, 1.7326e-05, 8.6125e-06,\n",
       "         1.6148e-05, 3.0499e-06, 1.9845e-05, 6.4330e-06, 2.6940e-03, 6.7144e-06,\n",
       "         3.4817e-06, 4.4635e-06, 4.6611e-05, 1.4907e-06, 1.7390e-05, 3.8986e-04,\n",
       "         4.0915e-05, 3.2524e-04, 1.5034e-04, 3.9757e-05, 4.6233e-06, 1.5471e-05,\n",
       "         5.7316e-06, 1.4741e-05, 2.9029e-06, 1.2071e-05, 8.7771e-06, 4.8174e-06,\n",
       "         8.8483e-05, 2.2978e-06, 7.7300e-05, 1.8247e-05, 2.7646e-06, 8.1203e-06,\n",
       "         5.8997e-06, 2.1001e-04, 4.9388e-06, 2.5049e-06, 3.8823e-07, 1.3044e-05,\n",
       "         1.7480e-06, 8.3642e-07, 3.4982e-05, 1.3308e-05, 5.4828e-06, 1.3729e-05,\n",
       "         1.8551e-05, 2.0911e-05, 5.0737e-05, 4.1118e-05, 5.8791e-06, 1.0714e-04,\n",
       "         7.7337e-06, 1.3390e-05, 3.8203e-07, 6.7992e-06, 5.2820e-06, 1.5616e-06,\n",
       "         3.2814e-05, 4.3509e-05, 2.5326e-05, 1.2686e-05, 9.8853e-05, 2.6051e-06,\n",
       "         4.3370e-05, 9.6507e-05, 4.7008e-06, 3.1825e-05, 3.0987e-05, 9.7622e-05,\n",
       "         3.9624e-06, 3.1110e-05, 1.8353e-05, 2.1440e-05, 2.4620e-05, 1.3921e-05,\n",
       "         2.5365e-06, 5.3475e-05, 7.2919e-06, 1.5262e-05, 3.2398e-05, 2.0569e-06,\n",
       "         3.7457e-06, 2.8023e-06, 2.4580e-06, 6.9792e-05, 2.5602e-05, 1.2623e-06,\n",
       "         6.9249e-06, 8.1574e-07, 1.2862e-04, 5.3280e-06, 9.7283e-06, 1.5579e-05,\n",
       "         8.3415e-06, 1.2340e-05, 2.2410e-06, 3.3254e-06, 1.0691e-05, 5.3969e-05,\n",
       "         4.0825e-05, 8.9866e-06, 3.7990e-06, 7.4371e-05, 1.3344e-05, 2.0848e-05,\n",
       "         1.2954e-05, 2.5827e-06, 4.5345e-06, 1.1641e-04, 1.0910e-05, 4.2095e-03,\n",
       "         1.1338e-06, 3.4302e-05, 7.1404e-07, 2.1861e-06, 7.3258e-06, 9.4787e-06,\n",
       "         1.1454e-06, 1.4817e-05, 1.6212e-05, 8.6889e-05, 3.4814e-05, 7.9312e-05,\n",
       "         3.7289e-05, 1.7554e-05, 6.5775e-07, 4.6217e-06, 6.2916e-06, 2.8290e-06,\n",
       "         2.0689e-05, 9.5964e-07, 3.3971e-05, 1.5988e-05, 2.5243e-05, 1.8386e-05,\n",
       "         7.9138e-06, 5.4692e-06, 1.0864e-05, 3.5004e-05, 1.0754e-05, 4.2295e-05,\n",
       "         5.9839e-06, 3.2628e-05, 4.7591e-04, 5.1596e-06, 4.2590e-05, 2.1521e-05,\n",
       "         2.6899e-06, 1.3176e-06, 1.8954e-05, 1.4475e-06, 1.8710e-05, 7.7144e-05,\n",
       "         1.2898e-05, 1.1312e-06, 4.9565e-06, 4.1188e-06, 4.3151e-06, 1.3490e-06,\n",
       "         2.5235e-05, 2.7339e-06, 4.9682e-05, 7.0398e-06, 1.9083e-05, 1.1148e-05,\n",
       "         4.6488e-05, 4.0356e-06, 1.9171e-05, 1.3507e-05, 4.0208e-06, 4.2091e-05,\n",
       "         2.3649e-04, 4.0067e-06, 2.1017e-05, 3.7331e-06, 4.1932e-06, 7.5771e-06,\n",
       "         1.1952e-06, 7.5503e-05, 9.5413e-06, 4.6034e-06, 2.7206e-05, 3.8779e-06,\n",
       "         2.1851e-05, 6.1282e-05, 1.0153e-05, 2.9987e-05, 5.4936e-05, 8.6842e-05,\n",
       "         1.3376e-05, 6.9077e-06, 1.8054e-06, 4.0412e-06, 4.9728e-05, 1.5165e-06,\n",
       "         2.5824e-06, 5.6972e-06, 1.0855e-05, 5.5532e-06, 4.1286e-06, 1.9927e-05,\n",
       "         2.7765e-05, 3.1277e-06, 2.6211e-06, 4.4596e-06, 1.4337e-05, 4.8106e-04,\n",
       "         1.1703e-06, 5.9973e-05, 1.1177e-04, 4.9193e-06, 6.5717e-06, 1.3226e-05,\n",
       "         7.9152e-06, 1.4598e-05, 3.2951e-06, 3.9216e-05, 1.8052e-05, 5.9695e-06,\n",
       "         5.2464e-06, 3.1478e-05, 2.1318e-05, 3.1525e-06, 1.8365e-05, 7.4912e-06,\n",
       "         5.3767e-06, 1.2600e-05, 6.6294e-05, 2.3279e-06, 1.8745e-05, 4.8329e-06,\n",
       "         1.0811e-05, 2.0291e-06, 2.0630e-06, 4.2023e-05, 3.9072e-06, 1.3245e-05,\n",
       "         8.1579e-06, 6.0676e-06, 1.8374e-06, 1.3857e-05, 1.6128e-05, 6.8627e-06,\n",
       "         1.4808e-05, 2.2965e-05, 2.2581e-05, 1.5567e-06, 9.9703e-06, 5.0514e-06,\n",
       "         6.4900e-05, 6.4688e-07, 1.1529e-05, 2.5628e-05, 1.8562e-05, 4.1418e-06,\n",
       "         1.1064e-05, 2.6467e-05, 4.4103e-05, 1.9476e-05, 7.9382e-07, 3.9223e-06,\n",
       "         2.6345e-04, 2.9318e-05, 1.2646e-05, 6.0620e-06, 2.3390e-05, 9.4800e-06,\n",
       "         1.6255e-05, 8.0342e-05, 2.2091e-06, 3.5182e-05, 2.4123e-05, 1.3408e-06,\n",
       "         2.8672e-05, 4.9193e-05, 3.9423e-06, 2.3789e-05, 2.4115e-06, 1.2610e-06,\n",
       "         4.6743e-05, 3.1036e-05, 4.6580e-06, 1.2194e-06, 7.5275e-06, 3.3141e-04,\n",
       "         9.3811e-05, 2.1375e-06, 2.2688e-06, 6.4510e-07, 9.9578e-06, 1.3611e-05,\n",
       "         7.9870e-06, 8.8901e-06, 1.1712e-05, 4.0900e-06, 7.4580e-06, 4.6390e-06,\n",
       "         1.2913e-05, 2.1910e-04, 5.0970e-06, 1.9414e-05, 2.0364e-06, 8.1691e-06,\n",
       "         3.8249e-06, 2.6716e-06, 1.0214e-05, 1.6684e-04, 1.3523e-05, 2.5294e-05,\n",
       "         2.2148e-06, 1.5063e-06, 1.6994e-06, 1.6445e-04, 1.5655e-05, 2.3598e-06,\n",
       "         1.2452e-06, 1.2535e-05, 6.2049e-06, 4.1333e-06, 1.2626e-04, 3.9133e-06,\n",
       "         1.0956e-06, 1.7436e-05, 7.5794e-06, 2.7867e-05, 1.3239e-05, 2.0982e-05,\n",
       "         4.5090e-05, 1.5662e-03, 4.1277e-05, 2.2843e-05, 2.3387e-05, 2.7423e-06,\n",
       "         1.1444e-05, 1.3736e-05, 1.6140e-04, 1.1670e-05, 8.8785e-06, 4.9526e-05,\n",
       "         2.8677e-06, 9.8252e-05, 5.3847e-06, 2.2352e-04, 2.6206e-05, 1.9082e-06,\n",
       "         8.6124e-06, 8.8270e-06, 2.8422e-05, 9.9139e-06, 3.1557e-05, 3.3382e-05,\n",
       "         3.6544e-06, 1.3188e-05, 1.0011e-04, 2.9558e-05, 8.5071e-06, 2.8949e-06,\n",
       "         1.4729e-05, 1.3744e-05, 1.2118e-05, 2.5970e-06, 4.8622e-05, 1.3469e-05,\n",
       "         2.2684e-05, 8.6850e-03, 9.9251e-06, 2.7441e-05, 5.8303e-06, 4.6007e-05,\n",
       "         1.5581e-05, 2.2647e-05, 5.9589e-06, 4.4577e-05, 5.6710e-05, 1.4433e-04,\n",
       "         1.8100e-05, 7.9060e-06, 1.7502e-05, 6.0914e-05, 3.4138e-06, 9.5776e-06,\n",
       "         3.6337e-06, 4.9196e-05, 7.9973e-06, 1.4791e-05, 5.3435e-06, 2.5509e-06,\n",
       "         1.3014e-05, 2.4907e-05, 1.3864e-05, 6.4250e-06, 2.7159e-05, 2.5885e-06,\n",
       "         1.4890e-06, 5.8151e-06, 7.0011e-06, 3.4348e-05, 6.9758e-06, 3.5104e-06,\n",
       "         1.0473e-05, 2.6010e-05, 6.0915e-06, 1.9422e-05, 8.1363e-06, 2.2825e-06,\n",
       "         1.4434e-06, 4.6776e-06, 1.0363e-05, 8.7921e-07, 5.5904e-06, 8.2702e-06,\n",
       "         8.4011e-05, 3.7205e-05, 5.2867e-07, 8.0338e-05, 7.9088e-06, 2.1611e-05,\n",
       "         7.2262e-07, 9.3662e-06, 8.3814e-05, 3.3628e-06, 3.2292e-06, 5.3580e-06,\n",
       "         1.6886e-05, 3.2960e-06, 1.8015e-06, 4.2598e-05, 5.7997e-05, 3.2313e-04,\n",
       "         6.8452e-06, 5.8682e-06, 1.8662e-05, 1.5152e-06, 9.0537e-05, 1.0996e-04,\n",
       "         3.6527e-06, 1.9033e-04, 1.0941e-04, 1.0170e-04, 2.1082e-06, 9.9036e-06,\n",
       "         6.1319e-06, 1.7433e-06, 2.9507e-06, 1.0916e-05, 3.2973e-06, 4.7513e-06,\n",
       "         5.4807e-06, 3.7301e-06, 9.2721e-05, 2.1664e-05, 3.0161e-04, 2.4444e-05,\n",
       "         2.7928e-05, 1.4952e-05, 2.5991e-05, 1.3412e-05, 6.6655e-06, 5.1309e-05,\n",
       "         3.0161e-05, 8.2559e-06, 7.2996e-07, 1.3129e-04, 7.4195e-06, 1.8479e-05,\n",
       "         3.2958e-06, 1.4539e-04, 4.1213e-06, 8.6295e-06, 6.0658e-06, 7.8989e-06,\n",
       "         6.2401e-06, 7.5896e-06], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.3.layer.0.SelfAttention.q.weight': tensor([[5.1050e-07, 2.5509e-05, 2.3963e-05,  ..., 1.2109e-05, 2.0513e-05,\n",
       "          3.0040e-06],\n",
       "         [2.1116e-06, 7.9437e-05, 7.2020e-05,  ..., 3.7704e-05, 6.0333e-05,\n",
       "          1.1276e-05],\n",
       "         [7.6891e-08, 2.8926e-06, 2.7572e-06,  ..., 1.4394e-06, 2.4952e-06,\n",
       "          3.1921e-07],\n",
       "         ...,\n",
       "         [1.1383e-07, 6.3507e-08, 4.2689e-07,  ..., 1.8788e-07, 8.8493e-07,\n",
       "          3.5936e-08],\n",
       "         [2.6748e-08, 2.9471e-08, 1.4409e-07,  ..., 1.0963e-07, 3.1432e-07,\n",
       "          4.4145e-09],\n",
       "         [3.4129e-08, 1.9748e-08, 1.8284e-08,  ..., 1.4131e-08, 1.0452e-07,\n",
       "          1.4441e-09]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.3.layer.0.SelfAttention.k.weight': tensor([[1.9420e-08, 1.1193e-06, 1.6994e-06,  ..., 5.9886e-07, 2.5768e-06,\n",
       "          8.3896e-08],\n",
       "         [2.5510e-09, 4.8098e-08, 6.2888e-08,  ..., 2.6520e-08, 9.2671e-08,\n",
       "          1.1536e-08],\n",
       "         [5.6455e-10, 4.1011e-08, 6.4814e-08,  ..., 2.1830e-08, 9.8621e-08,\n",
       "          1.9443e-09],\n",
       "         ...,\n",
       "         [9.7381e-10, 2.1501e-09, 7.6290e-10,  ..., 5.1845e-09, 4.7477e-09,\n",
       "          9.8554e-09],\n",
       "         [1.2285e-09, 5.0846e-10, 7.2599e-10,  ..., 1.3429e-09, 1.1988e-09,\n",
       "          3.0325e-09],\n",
       "         [1.3130e-09, 2.4103e-09, 8.0837e-10,  ..., 1.7852e-09, 2.3261e-09,\n",
       "          1.3492e-09]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.3.layer.0.SelfAttention.v.weight': tensor([[2.3551e-09, 1.9011e-08, 1.9428e-08,  ..., 1.1115e-08, 2.4689e-08,\n",
       "          7.6114e-09],\n",
       "         [2.2256e-09, 3.8553e-08, 2.8183e-08,  ..., 1.8803e-08, 1.7155e-08,\n",
       "          1.1397e-08],\n",
       "         [7.6565e-09, 3.6397e-08, 2.4281e-08,  ..., 1.8189e-08, 1.5801e-08,\n",
       "          1.2854e-08],\n",
       "         ...,\n",
       "         [4.7746e-09, 3.9207e-09, 4.3244e-09,  ..., 5.9830e-09, 1.0683e-08,\n",
       "          8.9126e-09],\n",
       "         [2.0504e-09, 5.4617e-09, 3.9668e-09,  ..., 1.1873e-08, 1.0026e-08,\n",
       "          6.6694e-09],\n",
       "         [5.2193e-09, 5.0542e-09, 9.1391e-10,  ..., 9.0826e-09, 8.5241e-09,\n",
       "          8.7365e-09]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.3.layer.0.SelfAttention.o.weight': tensor([[7.8935e-09, 1.6260e-08, 8.7411e-09,  ..., 2.0823e-09, 3.6354e-09,\n",
       "          2.7815e-09],\n",
       "         [4.6846e-09, 2.1046e-08, 6.0024e-09,  ..., 1.8368e-09, 5.1973e-10,\n",
       "          7.9454e-10],\n",
       "         [1.5635e-08, 1.6905e-08, 1.4384e-08,  ..., 9.6132e-10, 5.2359e-10,\n",
       "          8.4278e-10],\n",
       "         ...,\n",
       "         [3.4990e-09, 8.1459e-09, 4.6478e-09,  ..., 6.5102e-10, 3.2331e-10,\n",
       "          7.3273e-10],\n",
       "         [9.7906e-08, 9.2319e-08, 9.0415e-08,  ..., 5.6845e-09, 8.5925e-09,\n",
       "          9.1865e-09],\n",
       "         [5.4328e-09, 1.2713e-08, 7.1714e-09,  ..., 2.7386e-10, 4.6353e-10,\n",
       "          7.6011e-10]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.3.layer.0.layer_norm.weight': tensor([6.0378e-04, 3.9760e-04, 1.5180e-03, 6.3886e-04, 1.2098e+00, 4.5113e-03,\n",
       "         6.7448e-04, 3.4031e-04, 1.2375e-02, 4.0414e-04, 1.8429e-03, 1.2363e-02,\n",
       "         1.7977e-04, 1.1424e-04, 7.6267e-04, 4.7629e-04, 3.8017e-04, 1.4080e-03,\n",
       "         1.7175e-03, 9.3034e-04, 1.6319e-04, 3.4191e-04, 6.3569e-04, 4.8216e-02,\n",
       "         1.3381e-04, 3.4337e-04, 3.9190e-04, 1.8539e-03, 9.4059e-04, 7.2274e-04,\n",
       "         2.6780e-03, 3.1632e-03, 1.0828e-04, 2.7206e-04, 3.6553e-03, 4.5191e-03,\n",
       "         3.1427e-03, 1.2418e-03, 5.1908e-03, 1.4655e-02, 5.7827e-03, 2.2247e-03,\n",
       "         4.6518e-04, 2.3167e-03, 6.4798e-04, 5.8174e-04, 1.4512e-01, 3.4209e-04,\n",
       "         4.1830e-04, 1.6699e-04, 6.5615e-04, 1.0470e-04, 2.5927e-04, 2.0980e-03,\n",
       "         2.1012e-03, 6.6747e-04, 1.1620e-03, 4.8275e-03, 1.0455e-03, 2.1693e-04,\n",
       "         5.1074e-04, 1.6749e-03, 5.4486e-04, 1.3912e-04, 4.0132e-04, 6.5928e-04,\n",
       "         1.4271e-03, 7.2395e-04, 2.0156e-03, 1.1817e-03, 1.6536e-03, 3.7367e-04,\n",
       "         3.4121e-04, 2.4855e-04, 6.0296e-04, 5.5288e-04, 2.5492e-04, 6.1615e-04,\n",
       "         9.9964e-04, 2.9978e-04, 9.8668e-04, 5.2784e-04, 5.2856e-04, 1.2867e-03,\n",
       "         1.9320e-03, 5.4145e-04, 1.0068e-02, 1.2546e-04, 1.8374e-03, 9.7274e-04,\n",
       "         1.5109e-03, 1.1811e-03, 1.8665e-04, 7.9023e-04, 5.1531e-04, 2.2100e-04,\n",
       "         3.0811e-04, 6.3780e-03, 1.1973e-03, 4.8098e-04, 2.5251e-04, 1.2257e-03,\n",
       "         5.7088e-05, 2.4013e-02, 3.8884e-04, 6.0692e-04, 5.5442e-04, 2.0879e-04,\n",
       "         1.1741e-04, 5.6362e-02, 3.8520e-04, 3.4458e-03, 1.0774e-03, 4.6579e-04,\n",
       "         3.9028e-04, 6.0386e-04, 4.5872e-05, 4.3222e-03, 1.7661e-03, 2.5117e-03,\n",
       "         2.5195e-04, 9.2799e-04, 5.4225e-04, 1.3881e-02, 1.7976e-03, 1.9708e-02,\n",
       "         4.1493e-04, 1.0777e-04, 2.6620e-03, 1.7890e-03, 3.3831e-04, 1.4748e-03,\n",
       "         4.5508e-04, 1.4546e-03, 2.4890e-04, 2.7489e-04, 8.9842e-04, 3.4384e-02,\n",
       "         2.2750e-03, 3.7845e-04, 1.0272e-04, 1.1841e-03, 4.2038e-04, 1.1330e-03,\n",
       "         1.0812e-03, 1.1156e-03, 8.7583e-04, 3.1861e-04, 5.0694e-04, 4.8527e-02,\n",
       "         6.4027e-04, 1.0161e-03, 8.7226e-05, 1.9660e-02, 7.4516e-03, 1.3926e-03,\n",
       "         1.5205e-04, 7.8362e-04, 1.7763e-03, 8.1863e-02, 1.2654e-04, 3.2007e-04,\n",
       "         7.1224e-03, 1.9875e-03, 8.9735e-04, 1.0470e-04, 3.1460e-04, 5.1880e-04,\n",
       "         3.2719e-03, 8.8896e-04, 5.0736e-04, 6.0364e-04, 8.4138e-04, 8.1284e-04,\n",
       "         3.1328e-04, 5.1520e-04, 3.1854e-04, 1.6397e-03, 2.4427e-04, 4.7835e-04,\n",
       "         1.3057e-04, 1.3770e-04, 5.3246e-02, 2.0209e-04, 8.1404e-03, 1.4103e-03,\n",
       "         3.3488e-04, 4.6904e-04, 6.4387e-03, 9.3423e-04, 1.3952e-03, 2.7781e-03,\n",
       "         7.1997e-04, 5.2560e-05, 6.8685e-04, 2.9132e-04, 5.9476e-04, 8.8247e-05,\n",
       "         5.1650e-04, 1.7563e-04, 6.2645e-03, 4.6360e-02, 6.9946e-04, 1.2121e-03,\n",
       "         7.0595e-04, 5.6388e-04, 4.3166e-04, 2.0685e-03, 2.5545e-04, 2.5614e-03,\n",
       "         1.0227e-03, 1.2892e-04, 9.3540e-04, 8.6054e-04, 1.6027e-03, 8.1689e-05,\n",
       "         4.9331e-04, 1.2610e-02, 6.0566e-04, 1.4171e-03, 2.0982e-03, 1.0070e-03,\n",
       "         2.5774e-04, 1.0606e-03, 2.4581e-04, 2.2766e-03, 7.3181e-04, 2.2496e-03,\n",
       "         3.3952e-03, 4.2064e-05, 2.9295e-03, 1.6197e-03, 4.6868e-04, 5.2593e-05,\n",
       "         5.0273e-04, 1.4095e-04, 7.1763e-04, 2.4963e-04, 5.0616e-03, 1.1207e-03,\n",
       "         8.2431e-05, 6.4173e-04, 5.2268e-04, 1.2877e-04, 3.0720e-03, 4.4229e-02,\n",
       "         5.9906e-04, 2.8080e-03, 2.1977e-03, 2.0784e-03, 1.3160e-03, 1.1138e-03,\n",
       "         2.3096e-04, 8.5626e-04, 2.3111e-04, 7.6789e-04, 3.6389e-03, 4.4768e-04,\n",
       "         3.3163e-03, 7.7615e-04, 4.0704e-03, 2.3272e-04, 6.0747e-04, 1.3602e-03,\n",
       "         1.0147e-03, 3.1702e-05, 1.4523e-03, 2.5168e-04, 2.4337e-03, 2.2003e-04,\n",
       "         9.7756e-04, 3.8814e-04, 1.1339e-03, 1.7525e-02, 1.1735e-03, 1.1230e-04,\n",
       "         1.6051e-04, 2.5982e-04, 5.5040e-04, 1.6847e-04, 4.4756e-03, 1.5105e-03,\n",
       "         9.6310e-04, 2.2581e-03, 1.0114e-03, 1.8832e-03, 5.6986e-04, 7.4689e-03,\n",
       "         3.9036e-04, 8.9766e-04, 1.7900e-02, 1.5647e-03, 1.8279e-03, 8.8983e-04,\n",
       "         2.9452e-03, 1.7434e-03, 1.6663e-03, 1.1456e-03, 2.0344e-04, 8.3419e-04,\n",
       "         6.6249e-03, 7.0606e-05, 5.5930e-04, 1.1327e-04, 3.9068e-03, 1.6279e-03,\n",
       "         2.9771e-04, 3.3841e-03, 1.3791e-04, 1.0164e-02, 1.6067e-03, 9.3616e-04,\n",
       "         9.5294e-02, 9.6252e-04, 1.4247e-03, 9.9989e-04, 4.6219e-04, 6.1819e-05,\n",
       "         1.2436e-03, 2.8250e-04, 6.7217e-03, 6.3289e-03, 9.2638e-04, 2.4380e-02,\n",
       "         3.0393e-02, 8.2967e-04, 4.4301e-04, 6.3066e-04, 5.8142e-03, 3.4779e-04,\n",
       "         2.8701e-03, 2.3376e-03, 4.2838e-04, 2.9656e-04, 7.4657e-03, 7.9863e-04,\n",
       "         1.0647e-03, 1.6933e-03, 7.0042e-03, 4.1112e-03, 9.9535e-03, 3.0157e-04,\n",
       "         2.5803e-03, 7.4153e-04, 4.6388e-04, 5.6131e-04, 1.3569e-04, 6.2222e-03,\n",
       "         9.1442e-05, 2.6081e-04, 5.9375e-04, 2.3435e-03, 1.0224e-03, 5.3563e-04,\n",
       "         4.6157e-04, 1.3228e-03, 3.0908e-04, 2.4945e-03, 2.1231e-03, 6.7457e-03,\n",
       "         9.6131e-04, 4.5654e-04, 7.5045e-04, 1.2441e-04, 1.7600e-02, 1.6949e-03,\n",
       "         1.1642e-03, 3.3237e+00, 4.7735e-04, 7.9246e-04, 3.7896e-04, 9.3133e-05,\n",
       "         1.2054e-04, 6.6066e-03, 5.9066e-02, 1.6991e-03, 2.1891e-04, 3.2370e-03,\n",
       "         5.8062e-04, 1.5676e-02, 2.9896e-04, 5.2794e-03, 1.0525e-03, 2.1897e-04,\n",
       "         6.5155e-04, 2.4180e-04, 2.0696e-03, 7.2251e-05, 4.2027e-03, 1.4753e-04,\n",
       "         1.8088e-04, 2.3258e-04, 3.5536e-03, 8.0128e-04, 1.4541e-03, 2.0982e-04,\n",
       "         6.3229e-04, 6.3869e-04, 1.3027e-04, 3.1059e-04, 8.7733e-04, 5.6998e-03,\n",
       "         1.7088e-04, 2.5637e-02, 2.7981e-04, 7.9287e-04, 1.3244e-03, 2.6464e-03,\n",
       "         1.9301e-03, 3.8236e-04, 9.6855e-05, 5.1525e-04, 4.6755e-04, 2.8995e-03,\n",
       "         4.0326e-03, 6.1857e-04, 1.2045e-04, 7.4061e-04, 8.5298e-04, 4.4966e-05,\n",
       "         7.8114e-04, 6.6171e-04, 1.9723e-04, 9.4800e-04, 1.3450e-04, 1.0730e-03,\n",
       "         1.8547e-03, 1.8636e-03, 2.6153e-04, 1.7609e-04, 2.1974e-03, 7.4817e-04,\n",
       "         6.7388e-04, 3.1973e-03, 2.3030e-04, 1.8320e-03, 7.4306e-03, 4.1560e-04,\n",
       "         6.8676e-04, 2.0063e-03, 9.5103e-03, 3.3073e-03, 2.3397e-04, 1.2779e-03,\n",
       "         8.6068e-05, 6.6057e-04, 5.9729e-03, 5.9246e-04, 3.3552e-04, 1.0782e-03,\n",
       "         9.5774e-04, 1.5717e-03, 1.3460e-04, 5.7071e-02, 2.1677e-04, 5.0329e-03,\n",
       "         1.7608e-04, 1.3866e-04, 3.5754e-03, 7.5307e-03, 5.8986e-04, 1.6857e-04,\n",
       "         6.9096e-04, 5.5649e-03, 4.3882e-04, 2.8422e-03, 1.1339e-04, 2.1193e-01,\n",
       "         7.9553e-04, 2.7928e-03, 2.9907e-03, 4.5300e-04, 1.1858e-02, 5.7406e-04,\n",
       "         2.9129e-04, 3.0651e-02, 1.0981e-03, 5.1353e-03, 2.2027e-04, 1.5538e-02,\n",
       "         8.1396e-05, 7.3568e-04, 4.0801e-04, 1.9062e-03, 1.6214e-03, 7.3045e-04,\n",
       "         3.2312e-04, 3.9423e-03, 1.1406e-03, 1.3118e-04, 2.5070e-03, 7.1426e-03,\n",
       "         4.2107e-04, 4.8743e-04, 1.6421e-03, 2.6288e-04, 2.6783e-04, 5.7887e-04,\n",
       "         3.3654e-04, 2.0606e-04, 4.8780e-04, 8.6915e-03, 4.1396e-04, 2.1067e-03,\n",
       "         4.0468e-04, 5.8912e-03, 2.4182e-04, 1.2669e-04, 1.6644e-03, 8.4455e-04,\n",
       "         3.7147e-03, 1.0316e-03], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.3.layer.1.EncDecAttention.q.weight': tensor([[1.8168e-04, 1.1337e-05, 7.5680e-05,  ..., 3.6097e-05, 5.6609e-05,\n",
       "          1.3911e-05],\n",
       "         [1.3000e-05, 1.9799e-05, 4.7419e-06,  ..., 1.1531e-05, 8.1185e-06,\n",
       "          1.4059e-05],\n",
       "         [5.3168e-05, 1.1776e-05, 1.8963e-05,  ..., 1.4236e-05, 1.9883e-05,\n",
       "          1.1959e-05],\n",
       "         ...,\n",
       "         [1.6751e-04, 2.3890e-05, 7.0324e-05,  ..., 4.6647e-05, 3.7701e-05,\n",
       "          2.3680e-05],\n",
       "         [1.3920e-03, 8.3698e-05, 5.6875e-04,  ..., 2.6533e-04, 2.8250e-04,\n",
       "          8.2044e-05],\n",
       "         [7.0780e-04, 4.5934e-05, 2.9066e-04,  ..., 1.3565e-04, 1.4235e-04,\n",
       "          4.6647e-05]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.3.layer.1.EncDecAttention.k.weight': tensor([[9.5717e-07, 5.3453e-07, 2.7080e-07,  ..., 1.8762e-06, 1.9052e-06,\n",
       "          3.2669e-07],\n",
       "         [9.9104e-07, 2.6786e-07, 2.7656e-08,  ..., 1.5314e-08, 1.2314e-07,\n",
       "          1.8055e-07],\n",
       "         [2.8279e-06, 4.3153e-07, 1.0529e-07,  ..., 1.7078e-07, 3.8203e-07,\n",
       "          7.0899e-07],\n",
       "         ...,\n",
       "         [2.1063e-07, 1.2488e-07, 6.9682e-07,  ..., 4.5978e-07, 2.0896e-07,\n",
       "          1.1729e-07],\n",
       "         [3.1805e-06, 2.6430e-07, 4.6382e-06,  ..., 1.4038e-05, 1.7066e-06,\n",
       "          1.6792e-07],\n",
       "         [6.0671e-07, 1.6441e-07, 2.7049e-07,  ..., 6.4545e-07, 1.2234e-07,\n",
       "          5.0600e-08]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.3.layer.1.EncDecAttention.v.weight': tensor([[3.3387e-08, 6.0159e-08, 3.7460e-08,  ..., 2.1492e-08, 1.7425e-08,\n",
       "          2.1999e-08],\n",
       "         [3.8151e-08, 1.6065e-07, 3.7080e-08,  ..., 1.0218e-07, 3.0977e-08,\n",
       "          3.5195e-08],\n",
       "         [4.5364e-08, 4.7007e-08, 9.7985e-08,  ..., 7.4525e-08, 2.7261e-08,\n",
       "          4.2609e-08],\n",
       "         ...,\n",
       "         [2.5697e-08, 1.2347e-07, 1.0075e-07,  ..., 2.0739e-07, 1.8828e-08,\n",
       "          1.0535e-07],\n",
       "         [1.7345e-08, 7.6538e-08, 2.9840e-08,  ..., 4.8839e-08, 1.4892e-08,\n",
       "          3.8683e-08],\n",
       "         [2.3359e-09, 1.6283e-08, 1.3382e-08,  ..., 3.9523e-08, 5.4855e-09,\n",
       "          2.0100e-08]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.3.layer.1.EncDecAttention.o.weight': tensor([[5.4211e-07, 4.9793e-08, 2.9896e-07,  ..., 1.1744e-07, 1.6083e-07,\n",
       "          2.9866e-08],\n",
       "         [7.8175e-07, 1.5825e-07, 1.6406e-07,  ..., 6.9384e-08, 2.6223e-07,\n",
       "          4.6540e-07],\n",
       "         [1.7751e-07, 8.4159e-08, 9.5984e-08,  ..., 5.8966e-08, 7.4869e-08,\n",
       "          1.3743e-07],\n",
       "         ...,\n",
       "         [4.8741e-08, 1.4514e-07, 2.9501e-08,  ..., 5.2349e-08, 1.6362e-08,\n",
       "          1.2885e-07],\n",
       "         [8.2538e-07, 2.3903e-06, 5.4262e-07,  ..., 1.0078e-06, 3.5664e-07,\n",
       "          2.6634e-06],\n",
       "         [1.2589e-07, 9.1697e-08, 5.0168e-08,  ..., 1.2650e-08, 2.8155e-08,\n",
       "          1.0505e-07]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.3.layer.1.layer_norm.weight': tensor([4.9460e-03, 1.1198e-03, 6.9920e-03, 1.1357e-03, 1.4575e+00, 6.8835e-02,\n",
       "         9.9531e-03, 2.1125e-02, 9.5208e-02, 1.7970e-03, 3.4679e-03, 7.8038e-03,\n",
       "         4.2486e-04, 9.4224e-04, 3.5398e-04, 3.7998e-03, 4.3657e-03, 2.2317e-03,\n",
       "         1.5535e-03, 3.8944e-03, 6.1380e-03, 1.8587e-04, 2.6333e-03, 7.6690e-03,\n",
       "         3.2080e-04, 8.9688e-04, 5.9576e-04, 1.2441e-03, 1.7836e-02, 4.9279e-03,\n",
       "         1.6828e-03, 1.2441e-02, 1.2316e-03, 2.1210e-03, 2.9399e-03, 2.7481e-03,\n",
       "         2.5506e-04, 5.0406e-04, 5.3581e-04, 5.4568e-03, 7.7133e-03, 3.0952e-04,\n",
       "         7.7531e-04, 2.1179e-03, 1.0307e-03, 4.6913e-03, 7.4284e-02, 2.8220e-04,\n",
       "         1.1164e-04, 1.8278e-03, 9.2159e-04, 6.9596e-04, 1.9430e-03, 2.4969e-02,\n",
       "         7.5983e-03, 5.2889e-04, 1.9506e-02, 2.1512e-03, 1.0723e-04, 5.2581e-04,\n",
       "         3.0566e-04, 1.0873e-03, 3.5325e-04, 2.9280e-04, 2.4857e-03, 3.1918e-03,\n",
       "         1.2288e-02, 2.7838e-03, 9.8608e-03, 3.0353e-03, 2.2371e-03, 3.2265e-03,\n",
       "         1.5509e-03, 2.3257e-03, 3.7383e-03, 1.3227e-04, 2.8094e-04, 5.1105e-03,\n",
       "         1.8705e-03, 2.4739e-04, 3.9466e-03, 2.3054e-03, 2.8838e-04, 1.5713e-03,\n",
       "         3.9009e-03, 1.4386e-03, 4.7245e-03, 4.6400e-03, 3.9373e-05, 1.2809e-02,\n",
       "         8.2332e-04, 8.2653e-04, 6.0473e-04, 5.2276e-04, 6.6119e-04, 9.5829e-05,\n",
       "         2.0586e-03, 5.2582e-03, 5.5317e-03, 4.0772e-03, 5.5960e-03, 4.0709e-03,\n",
       "         2.4882e-03, 3.0249e-03, 2.3094e-03, 1.5282e-03, 1.4860e-02, 2.1269e-03,\n",
       "         1.1560e-04, 4.0844e-03, 4.6862e-04, 3.5315e-04, 1.0789e-02, 1.2699e-04,\n",
       "         1.4156e-04, 1.0496e-02, 5.8181e-04, 5.7572e-03, 3.4470e-03, 4.3840e-03,\n",
       "         5.7659e-04, 2.2189e-04, 2.0004e-03, 2.3914e-03, 1.0710e-03, 2.4714e-02,\n",
       "         9.8963e-03, 2.4456e-04, 2.2623e-03, 2.3235e-03, 4.4140e-03, 3.0186e-03,\n",
       "         5.6710e-03, 5.6669e-03, 1.6261e-03, 3.7996e-03, 4.8576e-04, 5.6917e-03,\n",
       "         8.0213e-03, 3.9074e-04, 1.7600e-04, 1.2175e-03, 5.9352e-04, 7.7763e-03,\n",
       "         6.1837e-04, 1.4528e-04, 1.5249e-02, 7.7405e-03, 8.0317e-04, 1.6476e-01,\n",
       "         5.2966e-03, 1.4892e-02, 2.6718e-04, 5.7704e-02, 2.5089e-02, 2.7903e-04,\n",
       "         1.4285e-04, 1.7312e-03, 1.4022e-04, 1.4281e-01, 1.1051e-03, 2.3698e-03,\n",
       "         3.7510e-03, 6.0952e-04, 6.7124e-03, 4.2483e-03, 2.2206e-02, 7.8870e-04,\n",
       "         1.0620e-02, 8.6302e-03, 2.0716e-03, 8.9815e-03, 1.5507e-02, 4.6724e-04,\n",
       "         1.3292e-03, 3.9922e-04, 1.5272e-03, 2.2733e-02, 5.2865e-03, 2.0982e-03,\n",
       "         2.1911e-03, 2.8850e-03, 5.3360e-03, 4.0055e-04, 6.3246e-04, 1.0564e-03,\n",
       "         2.1106e-04, 8.4173e-04, 8.7121e-03, 2.1378e-03, 6.7916e-02, 7.5035e-04,\n",
       "         1.5754e-04, 2.5498e-04, 2.7279e-03, 1.6198e-03, 5.4932e-04, 5.9461e-04,\n",
       "         6.9435e-03, 1.6605e-04, 8.2828e-03, 2.4955e-03, 1.3478e-03, 5.3299e-03,\n",
       "         5.8364e-03, 3.7837e-04, 9.8173e-04, 5.4811e-04, 1.1643e-03, 1.9773e-02,\n",
       "         1.8703e-02, 3.1928e-04, 6.4383e-03, 1.8520e-03, 7.5161e-04, 3.3762e-05,\n",
       "         4.4881e-04, 4.3775e-04, 8.1096e-03, 3.3595e-03, 2.1377e-03, 1.1686e-03,\n",
       "         1.9155e-03, 3.7354e-03, 7.8148e-04, 1.5563e-03, 3.5111e-03, 4.5361e-02,\n",
       "         3.5134e-03, 1.1010e-03, 2.0040e-03, 3.9900e-04, 1.1973e-01, 1.5983e-03,\n",
       "         4.2629e-03, 1.2661e-03, 7.4305e-04, 1.7099e-04, 4.5157e-03, 1.7555e-02,\n",
       "         4.4539e-03, 1.9880e-03, 2.4260e-03, 3.2685e-03, 8.4577e-03, 4.2345e-01,\n",
       "         3.2388e-04, 2.0270e-04, 4.0655e-03, 9.1444e-04, 5.4949e-04, 4.0938e-04,\n",
       "         3.7821e-04, 1.7297e-04, 1.2721e-04, 7.4264e-04, 1.5939e-03, 1.8021e-03,\n",
       "         9.1650e-04, 1.2930e-02, 1.5122e-03, 1.4087e-03, 1.1480e-02, 1.2756e-03,\n",
       "         3.6605e-04, 1.8253e-03, 2.9754e-03, 1.1627e-03, 6.8739e-03, 9.7705e-04,\n",
       "         8.4477e-04, 2.9967e-03, 1.7896e-03, 3.9303e-02, 1.4005e-03, 1.5905e-03,\n",
       "         1.0393e-03, 4.1704e-04, 4.3311e-04, 5.0570e-03, 1.3427e-03, 2.5681e-02,\n",
       "         8.3426e-04, 2.2467e-03, 1.7676e-03, 5.8124e-04, 1.1569e-03, 5.7838e-04,\n",
       "         2.6731e-02, 2.6260e-04, 7.4673e-03, 6.8763e-04, 4.4940e-04, 7.2123e-04,\n",
       "         5.7622e-04, 7.7375e-03, 2.5657e-03, 3.4588e-03, 2.6121e-03, 1.3198e-04,\n",
       "         4.7935e-04, 2.7482e-04, 1.1158e-03, 3.2619e-03, 3.7550e-02, 1.2202e-03,\n",
       "         5.5132e-03, 7.2956e-02, 2.0765e-03, 1.4568e-02, 5.5231e-03, 1.5910e-03,\n",
       "         2.1488e-02, 8.1293e-03, 5.4676e-04, 7.5499e-03, 7.2208e-04, 1.6979e-03,\n",
       "         1.2730e-03, 9.7003e-04, 1.8529e-02, 5.5015e-03, 5.5558e-03, 7.5641e-02,\n",
       "         1.0089e-01, 1.5293e-03, 9.2518e-04, 9.6060e-04, 2.5933e-03, 9.5792e-04,\n",
       "         1.7496e-02, 7.7840e-04, 5.1762e-03, 2.0337e-04, 1.3412e-03, 3.4618e-04,\n",
       "         5.7248e-03, 3.6861e-03, 4.2071e-03, 6.6917e-04, 5.0181e-03, 1.7004e-04,\n",
       "         3.7386e-03, 7.7071e-05, 5.1682e-04, 8.9685e-04, 7.5389e-04, 1.4947e-03,\n",
       "         1.5422e-04, 3.7977e-04, 2.2006e-04, 1.3522e-03, 3.6191e-03, 1.9217e-03,\n",
       "         3.8417e-03, 1.7941e-03, 8.0272e-03, 1.4398e-02, 4.9726e-03, 5.9805e-03,\n",
       "         1.1965e-03, 6.0818e-03, 3.2689e-03, 2.2247e-03, 1.4884e-03, 9.6246e-03,\n",
       "         5.1996e-03, 6.7347e-01, 7.1250e-03, 9.1952e-03, 2.5858e-04, 4.7195e-04,\n",
       "         1.1324e-03, 9.2852e-03, 7.8265e-03, 6.9914e-04, 4.7534e-03, 9.6685e-03,\n",
       "         2.4601e-04, 2.1849e-02, 2.0908e-03, 1.1404e-02, 9.3576e-05, 2.7980e-04,\n",
       "         1.0003e-02, 3.6180e-04, 7.0520e-02, 4.9844e-04, 5.5246e-02, 1.0785e-02,\n",
       "         4.7357e-04, 2.7270e-04, 1.1578e-01, 1.2274e-03, 1.1988e-03, 4.4953e-04,\n",
       "         7.3114e-04, 3.9745e-04, 2.4315e-04, 2.2020e-03, 2.5406e-03, 1.3872e-02,\n",
       "         1.7905e-03, 2.3593e-01, 1.0579e-03, 3.2239e-04, 1.4904e-03, 1.5738e-02,\n",
       "         4.8109e-03, 2.3574e-03, 1.0828e-03, 6.4624e-05, 8.8957e-04, 7.5202e-03,\n",
       "         3.1248e-03, 3.4341e-03, 3.2869e-04, 7.5990e-03, 1.4283e-02, 2.2877e-05,\n",
       "         4.4219e-04, 4.0937e-04, 1.0546e-03, 2.1104e-03, 2.5408e-04, 3.0737e-03,\n",
       "         2.9484e-03, 4.9638e-03, 2.3759e-03, 3.7201e-03, 3.3093e-03, 2.1241e-03,\n",
       "         3.9258e-03, 2.6336e-03, 4.8108e-04, 1.4695e-03, 5.0861e-03, 1.8733e-04,\n",
       "         2.7231e-03, 2.0256e-02, 2.6894e-02, 4.0409e-03, 7.9537e-05, 6.3645e-04,\n",
       "         3.4423e-04, 1.8865e-03, 1.5770e-04, 2.2977e-04, 5.1975e-04, 4.2986e-03,\n",
       "         1.7740e-04, 1.7376e-04, 1.0318e-03, 2.6196e-02, 5.5811e-04, 1.8578e-03,\n",
       "         8.1031e-04, 4.7694e-04, 7.4671e-03, 3.9459e-04, 1.1348e-03, 1.2176e-03,\n",
       "         8.7710e-05, 1.1049e-03, 1.1054e-03, 8.9228e-04, 9.7811e-04, 2.1333e-02,\n",
       "         2.4007e-03, 8.2915e-04, 1.0797e-02, 2.6998e-04, 2.3576e-03, 5.1586e-02,\n",
       "         4.9638e-04, 1.6863e-03, 3.0315e-02, 1.1473e-02, 3.3561e-04, 1.4571e-02,\n",
       "         4.5375e-04, 2.2420e-04, 2.0171e-03, 4.3852e-03, 4.9642e-04, 2.5166e-03,\n",
       "         8.4865e-05, 2.7733e-03, 7.3162e-03, 3.0827e-04, 8.9594e-03, 1.0970e-02,\n",
       "         2.7090e-03, 9.9101e-03, 2.0948e-02, 5.8645e-03, 1.8889e-04, 3.7264e-03,\n",
       "         3.9719e-04, 9.5950e-04, 3.7598e-03, 2.0507e-02, 6.8661e-05, 7.0381e-03,\n",
       "         1.8788e-03, 1.1657e-02, 8.2410e-04, 4.3280e-04, 7.8637e-04, 2.4651e-03,\n",
       "         1.0267e-03, 2.4251e-03], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.3.layer.2.DenseReluDense.wi.weight': tensor([[2.3490e-07, 1.3712e-08, 3.3747e-07,  ..., 3.5155e-08, 8.0588e-08,\n",
       "          1.4937e-07],\n",
       "         [6.4665e-10, 1.7724e-09, 8.1076e-10,  ..., 1.0691e-10, 4.4618e-11,\n",
       "          2.7185e-09],\n",
       "         [1.8456e-11, 1.9092e-11, 1.1718e-11,  ..., 3.7718e-12, 1.8563e-11,\n",
       "          8.1829e-12],\n",
       "         ...,\n",
       "         [1.4602e-09, 3.1765e-09, 5.2878e-09,  ..., 7.7949e-09, 5.5456e-11,\n",
       "          6.2907e-09],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [2.1126e-12, 4.9837e-12, 1.2034e-12,  ..., 1.9704e-11, 1.8188e-11,\n",
       "          5.2389e-11]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.3.layer.2.DenseReluDense.wo.weight': tensor([[5.1800e-07, 8.6295e-09, 3.0347e-12,  ..., 3.4502e-07, 0.0000e+00,\n",
       "          3.4804e-11],\n",
       "         [9.2578e-07, 6.7663e-10, 1.4423e-11,  ..., 5.2410e-08, 0.0000e+00,\n",
       "          7.1375e-12],\n",
       "         [1.0963e-06, 5.0630e-09, 1.1297e-12,  ..., 1.1648e-10, 0.0000e+00,\n",
       "          1.4652e-11],\n",
       "         ...,\n",
       "         [3.7610e-07, 4.6136e-11, 2.2233e-12,  ..., 4.5369e-07, 0.0000e+00,\n",
       "          8.1398e-11],\n",
       "         [4.6437e-06, 4.1208e-08, 4.5871e-11,  ..., 4.4571e-07, 0.0000e+00,\n",
       "          2.1881e-11],\n",
       "         [5.5599e-06, 2.0939e-08, 3.6406e-12,  ..., 7.5990e-07, 0.0000e+00,\n",
       "          1.1721e-10]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.3.layer.2.layer_norm.weight': tensor([4.3154e-06, 1.2564e-06, 2.4087e-05, 1.0203e-05, 7.2944e-02, 2.5880e-05,\n",
       "         2.2966e-06, 1.6507e-06, 5.0408e-05, 1.8502e-06, 2.3426e-05, 4.2157e-05,\n",
       "         7.7163e-06, 3.0026e-06, 2.6739e-07, 4.0986e-06, 8.0925e-06, 8.1688e-06,\n",
       "         2.0252e-06, 2.3289e-06, 3.4024e-06, 6.3107e-06, 5.4099e-06, 1.4239e-04,\n",
       "         9.9677e-07, 2.9473e-05, 2.2701e-06, 3.0628e-06, 6.0325e-05, 7.5040e-06,\n",
       "         1.5607e-05, 1.8907e-05, 2.3787e-05, 1.1869e-06, 1.0994e-05, 3.0810e-05,\n",
       "         1.0402e-05, 3.7982e-06, 3.4739e-06, 3.4076e-05, 1.0567e-05, 5.8076e-06,\n",
       "         6.6128e-06, 1.5013e-05, 5.3634e-06, 9.6256e-06, 4.9905e-04, 1.5760e-06,\n",
       "         6.8914e-06, 3.7881e-06, 1.4102e-05, 5.5074e-06, 7.6553e-06, 1.5488e-06,\n",
       "         5.0436e-05, 9.0126e-06, 5.8588e-06, 1.6488e-05, 1.1398e-05, 2.9769e-06,\n",
       "         3.7062e-06, 7.4585e-06, 1.6648e-06, 3.9460e-06, 3.8330e-06, 1.4698e-06,\n",
       "         2.3418e-06, 5.9044e-06, 2.7172e-05, 5.6508e-06, 2.5515e-06, 1.2838e-06,\n",
       "         8.9034e-06, 1.2742e-05, 1.5886e-05, 3.3058e-06, 1.6630e-06, 4.2955e-06,\n",
       "         8.9501e-06, 6.2198e-06, 2.1342e-05, 9.7750e-06, 8.8806e-06, 4.9636e-06,\n",
       "         1.7540e-06, 1.7374e-05, 8.8673e-06, 6.1629e-05, 1.0970e-06, 1.0561e-05,\n",
       "         3.5762e-06, 6.3447e-06, 1.5794e-07, 2.1288e-06, 9.8688e-07, 1.8526e-06,\n",
       "         1.0531e-05, 5.0259e-05, 1.5531e-05, 2.1465e-06, 3.6964e-05, 2.0068e-05,\n",
       "         8.1284e-06, 4.6951e-05, 1.8027e-06, 5.5051e-06, 1.7492e-05, 2.7947e-06,\n",
       "         1.7748e-05, 6.3643e-05, 2.5212e-07, 2.2678e-06, 1.0581e-05, 7.6897e-07,\n",
       "         5.2679e-06, 2.5492e-05, 4.4342e-06, 1.5922e-06, 8.4356e-06, 5.3171e-06,\n",
       "         1.0866e-05, 1.5767e-06, 3.3686e-06, 2.4108e-05, 5.4650e-06, 2.1350e-05,\n",
       "         5.5623e-06, 9.5635e-07, 4.3977e-05, 1.4748e-06, 6.0721e-06, 1.7679e-05,\n",
       "         2.6478e-06, 8.7802e-06, 4.0282e-06, 8.4428e-06, 2.8633e-06, 4.6826e-05,\n",
       "         1.5647e-05, 6.7865e-06, 3.5888e-05, 2.8467e-05, 1.9494e-06, 1.1592e-05,\n",
       "         5.9851e-06, 4.4807e-06, 5.3121e-06, 1.1645e-05, 3.6680e-06, 1.9337e-03,\n",
       "         2.9945e-06, 1.4979e-05, 2.2102e-06, 2.6021e-05, 5.1593e-07, 1.7084e-06,\n",
       "         3.3398e-06, 7.4175e-06, 1.3862e-06, 1.2973e-04, 1.2790e-05, 2.1843e-06,\n",
       "         1.5587e-05, 5.7525e-06, 9.3546e-07, 1.5312e-05, 2.0792e-05, 1.6241e-06,\n",
       "         1.0783e-06, 1.6514e-06, 2.2953e-06, 1.4870e-05, 2.4604e-06, 2.4269e-06,\n",
       "         1.9443e-06, 1.6447e-06, 4.8298e-06, 5.7309e-06, 1.2369e-05, 3.2377e-05,\n",
       "         6.1292e-06, 2.1334e-05, 5.6064e-04, 4.4130e-06, 1.0252e-05, 9.0370e-06,\n",
       "         6.6530e-06, 2.8230e-06, 3.4654e-05, 3.7832e-06, 1.5548e-06, 1.0872e-05,\n",
       "         1.8053e-05, 1.2626e-06, 4.1384e-06, 8.8070e-07, 5.4950e-06, 5.0961e-06,\n",
       "         8.5671e-06, 2.3028e-06, 5.7630e-06, 7.3774e-06, 1.9811e-05, 2.9717e-06,\n",
       "         2.3623e-06, 8.4394e-06, 7.6885e-06, 5.7242e-06, 7.8722e-06, 7.1920e-06,\n",
       "         4.8674e-06, 2.3688e-06, 1.1716e-05, 1.7341e-05, 1.2124e-05, 5.3313e-06,\n",
       "         4.5305e-06, 8.5374e-05, 7.0230e-06, 2.3138e-06, 5.0983e-06, 7.6119e-06,\n",
       "         4.3079e-06, 6.7504e-06, 7.7731e-06, 2.6635e-05, 6.1484e-06, 1.1350e-05,\n",
       "         4.1071e-05, 5.0296e-06, 2.8789e-06, 3.2746e-06, 2.2435e-05, 8.3571e-06,\n",
       "         6.3555e-06, 2.2756e-06, 7.3973e-06, 1.0509e-06, 1.0797e-05, 1.3483e-05,\n",
       "         2.2338e-05, 1.0899e-06, 8.8441e-06, 2.1906e-05, 3.0039e-05, 5.9533e-04,\n",
       "         9.3067e-06, 1.3772e-06, 3.1997e-05, 4.1307e-06, 3.1231e-06, 2.6814e-06,\n",
       "         2.0818e-06, 1.0898e-06, 2.0542e-06, 1.0213e-05, 4.2733e-06, 1.5786e-05,\n",
       "         2.6337e-06, 1.6547e-05, 1.0264e-05, 2.6595e-05, 2.5176e-05, 9.0563e-06,\n",
       "         2.5018e-06, 3.5350e-06, 4.3539e-05, 7.3949e-07, 6.4964e-07, 2.3998e-06,\n",
       "         3.8799e-05, 3.7669e-06, 4.3250e-06, 1.1028e-05, 9.2945e-06, 1.5609e-06,\n",
       "         3.8507e-06, 4.3043e-06, 1.7081e-06, 4.9280e-06, 9.2020e-05, 7.1238e-06,\n",
       "         1.3338e-06, 1.0565e-05, 5.6007e-06, 2.2835e-05, 5.6118e-05, 2.5773e-06,\n",
       "         2.4799e-05, 1.3358e-06, 7.9198e-05, 5.3520e-06, 7.1402e-06, 6.1209e-05,\n",
       "         6.8012e-06, 7.3189e-05, 1.3372e-05, 1.2523e-05, 3.9080e-06, 1.4757e-06,\n",
       "         4.8731e-05, 3.4775e-06, 5.3776e-05, 3.5330e-06, 9.1905e-05, 4.2621e-05,\n",
       "         2.2669e-06, 4.1180e-05, 3.3637e-06, 2.7956e-05, 1.3351e-05, 1.9566e-06,\n",
       "         2.8384e-05, 1.3522e-05, 1.3790e-05, 1.1342e-05, 1.7666e-06, 9.0830e-06,\n",
       "         6.5812e-06, 2.7039e-06, 9.2753e-05, 1.5276e-05, 2.9786e-06, 2.4371e-05,\n",
       "         7.4907e-05, 1.6860e-06, 2.9576e-06, 2.1883e-07, 8.5660e-07, 5.1908e-06,\n",
       "         2.0181e-06, 2.2588e-06, 2.1902e-06, 1.1279e-05, 1.9792e-06, 4.4665e-06,\n",
       "         4.7078e-06, 3.1942e-06, 9.3657e-06, 8.9957e-06, 7.1082e-06, 8.4164e-06,\n",
       "         4.6726e-06, 1.7749e-05, 4.2403e-06, 2.9875e-05, 1.7935e-05, 2.0626e-05,\n",
       "         8.3682e-06, 8.8742e-06, 2.8103e-06, 1.2509e-06, 4.6070e-06, 2.4597e-06,\n",
       "         2.9499e-05, 4.1383e-06, 5.7794e-06, 2.0823e-06, 2.3681e-06, 8.0478e-06,\n",
       "         1.6563e-06, 1.5731e-05, 3.8130e-06, 5.1468e-06, 3.4177e-06, 5.3054e-05,\n",
       "         6.9837e-06, 1.2581e-02, 4.0755e-06, 4.6686e-06, 7.8839e-06, 2.5778e-06,\n",
       "         4.1055e-05, 7.6680e-06, 7.6186e-05, 1.6512e-05, 1.7709e-06, 1.5281e-05,\n",
       "         2.3865e-05, 7.2443e-05, 2.7164e-06, 6.5698e-05, 1.4403e-06, 9.9096e-07,\n",
       "         1.8775e-05, 5.5930e-06, 2.2792e-05, 8.3378e-06, 1.5585e-05, 3.7387e-06,\n",
       "         1.7587e-06, 7.6122e-07, 1.1274e-05, 1.3357e-04, 6.0036e-07, 6.2294e-06,\n",
       "         1.7072e-06, 8.2935e-06, 8.8469e-07, 1.5599e-06, 2.3349e-06, 9.1607e-05,\n",
       "         3.4629e-05, 2.2260e-03, 1.1282e-05, 8.1850e-06, 1.4871e-05, 1.4043e-05,\n",
       "         2.8316e-05, 1.7604e-05, 1.1302e-06, 2.5157e-06, 5.5112e-06, 8.9102e-06,\n",
       "         1.2295e-06, 2.2673e-06, 7.8374e-06, 6.7213e-05, 2.1519e-05, 9.7946e-06,\n",
       "         5.4708e-06, 8.3769e-06, 2.5684e-06, 1.4751e-05, 1.1051e-05, 2.2043e-06,\n",
       "         8.7294e-06, 5.4173e-06, 1.2580e-06, 4.0258e-06, 2.7383e-05, 9.4737e-06,\n",
       "         8.0985e-07, 1.1273e-05, 3.0427e-06, 2.2373e-05, 9.2522e-06, 4.4950e-06,\n",
       "         1.4941e-06, 1.0704e-05, 2.0972e-05, 7.4231e-06, 1.2068e-05, 3.3518e-06,\n",
       "         2.1218e-06, 3.4816e-06, 2.7332e-06, 3.2118e-06, 1.3566e-06, 3.6113e-06,\n",
       "         3.5285e-05, 2.0604e-06, 4.7265e-06, 4.7925e-06, 1.1923e-06, 3.1953e-05,\n",
       "         1.8695e-06, 5.4247e-07, 4.7097e-06, 1.2522e-06, 1.6479e-06, 2.6491e-06,\n",
       "         8.3700e-07, 2.7785e-06, 2.8129e-06, 3.4494e-06, 4.2976e-05, 9.6514e-05,\n",
       "         5.6176e-06, 2.4386e-05, 4.2645e-06, 3.7755e-06, 1.8185e-05, 1.8286e-05,\n",
       "         1.7046e-06, 2.1080e-05, 7.6674e-06, 7.2944e-05, 9.6210e-06, 1.3702e-05,\n",
       "         7.7117e-06, 3.1983e-06, 2.0381e-06, 1.0820e-06, 3.3708e-06, 3.0296e-06,\n",
       "         1.2320e-06, 2.6957e-05, 5.0726e-06, 4.7510e-05, 3.7049e-04, 2.3056e-05,\n",
       "         3.1897e-05, 5.7398e-06, 1.1915e-05, 2.3123e-06, 6.7560e-07, 3.8315e-06,\n",
       "         1.0335e-05, 5.2835e-06, 1.9648e-06, 7.3665e-05, 6.7611e-06, 3.1064e-05,\n",
       "         1.6325e-06, 1.3641e-06, 6.2636e-06, 4.0356e-06, 5.1653e-06, 2.5024e-06,\n",
       "         4.6601e-06, 5.3028e-05], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.4.layer.0.SelfAttention.q.weight': tensor([[1.9189e-07, 6.9612e-06, 2.4980e-05,  ..., 6.6885e-06, 8.9704e-07,\n",
       "          3.8951e-06],\n",
       "         [1.8616e-07, 7.3945e-06, 2.6606e-05,  ..., 7.1658e-06, 8.6032e-07,\n",
       "          4.2465e-06],\n",
       "         [1.5512e-07, 1.0257e-06, 3.7017e-06,  ..., 9.7015e-07, 4.5139e-07,\n",
       "          5.9703e-07],\n",
       "         ...,\n",
       "         [4.2892e-11, 7.0036e-11, 4.6669e-11,  ..., 4.6931e-12, 5.9466e-11,\n",
       "          9.6767e-12],\n",
       "         [2.4939e-11, 1.1684e-11, 3.1655e-10,  ..., 1.5644e-11, 1.4266e-10,\n",
       "          1.1373e-11],\n",
       "         [7.4635e-11, 1.1205e-10, 6.8243e-11,  ..., 1.4048e-11, 7.2058e-11,\n",
       "          1.5482e-11]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.4.layer.0.SelfAttention.k.weight': tensor([[1.0542e-08, 3.3439e-08, 1.0988e-07,  ..., 5.7090e-08, 8.2802e-08,\n",
       "          3.4505e-10],\n",
       "         [1.1583e-08, 3.6998e-08, 1.2193e-07,  ..., 6.3261e-08, 9.1265e-08,\n",
       "          6.5339e-10],\n",
       "         [5.3889e-09, 1.4548e-08, 4.8546e-08,  ..., 2.5138e-08, 3.7503e-08,\n",
       "          8.0541e-10],\n",
       "         ...,\n",
       "         [5.5114e-13, 7.4397e-14, 4.3913e-13,  ..., 1.7869e-12, 1.6725e-12,\n",
       "          9.2915e-13],\n",
       "         [1.3035e-12, 9.0894e-14, 3.0908e-13,  ..., 1.3681e-12, 9.1637e-13,\n",
       "          1.5204e-13],\n",
       "         [1.2145e-12, 3.6239e-13, 2.3067e-13,  ..., 2.7320e-12, 1.7248e-12,\n",
       "          1.0874e-12]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.4.layer.0.SelfAttention.v.weight': tensor([[3.5430e-08, 1.2815e-08, 5.2423e-08,  ..., 5.7955e-08, 1.1146e-07,\n",
       "          9.0392e-08],\n",
       "         [5.4922e-08, 6.7444e-08, 2.4295e-07,  ..., 9.1942e-08, 1.0904e-08,\n",
       "          6.7582e-08],\n",
       "         [1.3426e-08, 6.5631e-09, 2.4266e-08,  ..., 2.3168e-08, 2.8996e-08,\n",
       "          2.2716e-08],\n",
       "         ...,\n",
       "         [3.3239e-09, 2.0448e-09, 5.5247e-09,  ..., 1.5695e-08, 6.1226e-09,\n",
       "          5.5718e-09],\n",
       "         [1.1340e-08, 1.2079e-09, 6.9427e-09,  ..., 3.5847e-09, 1.7514e-08,\n",
       "          1.0868e-08],\n",
       "         [7.3093e-09, 1.2536e-09, 1.0580e-08,  ..., 9.0114e-08, 1.1310e-07,\n",
       "          8.7057e-08]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.4.layer.0.SelfAttention.o.weight': tensor([[4.6296e-08, 2.3593e-08, 5.1241e-08,  ..., 5.5023e-09, 4.1693e-09,\n",
       "          1.0290e-09],\n",
       "         [7.8910e-08, 2.1676e-09, 1.6572e-07,  ..., 2.6309e-09, 1.7334e-09,\n",
       "          4.6630e-10],\n",
       "         [4.2771e-08, 2.6159e-09, 8.7979e-08,  ..., 2.2558e-09, 3.3732e-09,\n",
       "          1.9513e-09],\n",
       "         ...,\n",
       "         [1.1654e-08, 7.0719e-09, 9.6014e-09,  ..., 1.2090e-09, 1.6411e-09,\n",
       "          1.9534e-10],\n",
       "         [7.3002e-07, 7.7900e-08, 1.6821e-06,  ..., 1.8669e-08, 1.4213e-08,\n",
       "          3.1681e-09],\n",
       "         [6.6712e-08, 2.2338e-08, 7.7150e-08,  ..., 4.5774e-09, 3.0291e-09,\n",
       "          1.3449e-09]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.4.layer.0.layer_norm.weight': tensor([1.3652e-03, 1.3732e-04, 2.3203e-03, 1.5754e-02, 2.3030e+00, 1.7795e-03,\n",
       "         3.7762e-04, 4.3862e-03, 1.6715e-03, 1.4598e-04, 5.3068e-03, 6.2325e-03,\n",
       "         1.9539e-04, 2.4665e-04, 4.3112e-05, 5.0930e-04, 4.2764e-04, 1.1714e-03,\n",
       "         2.8265e-04, 6.6634e-05, 6.5228e-04, 7.6358e-04, 8.8932e-04, 4.3477e-03,\n",
       "         7.2504e-04, 1.4548e-04, 4.6294e-04, 6.5647e-04, 3.9872e-04, 1.6199e-03,\n",
       "         7.1715e-04, 2.3604e-03, 1.2001e-03, 9.4465e-05, 1.4459e-03, 9.6591e-03,\n",
       "         1.8047e-04, 3.8570e-04, 5.2167e-04, 1.8350e-03, 3.0711e-04, 5.6118e-04,\n",
       "         2.7076e-03, 1.7574e-04, 4.1296e-04, 2.7934e-04, 4.0383e-03, 5.1359e-04,\n",
       "         2.7268e-04, 4.6876e-04, 1.0510e-03, 3.5814e-04, 3.0568e-03, 1.9223e-03,\n",
       "         2.2774e-03, 2.7283e-03, 4.5156e-04, 6.4511e-04, 1.9177e-03, 1.5146e-04,\n",
       "         3.7032e-04, 3.2924e-03, 4.2064e-04, 3.2462e-04, 6.1504e-04, 9.4943e-03,\n",
       "         1.8766e-03, 5.4767e-05, 4.2393e-03, 1.6206e-03, 2.8043e-04, 1.8179e-04,\n",
       "         3.6764e-04, 3.7843e-04, 1.4755e-03, 9.9711e-04, 6.0205e-04, 1.9411e-04,\n",
       "         5.1516e-04, 6.1244e-04, 1.0861e-03, 3.1832e-03, 3.8801e-04, 5.1860e-04,\n",
       "         2.0605e-03, 1.2446e-03, 2.5765e-03, 1.9102e-03, 8.3820e-04, 1.7639e-03,\n",
       "         1.7748e-03, 5.2851e-04, 4.5629e-04, 5.1752e-04, 1.0133e-03, 1.6658e-04,\n",
       "         1.4287e-02, 4.4578e-04, 9.1140e-04, 5.7848e-04, 2.0905e-03, 4.9678e-03,\n",
       "         4.8767e-04, 9.4895e-03, 1.0647e-03, 4.9238e-04, 1.1623e-04, 3.1169e-04,\n",
       "         2.5259e-04, 3.5551e-02, 2.7700e-04, 2.1717e-04, 1.3974e-03, 1.9962e-04,\n",
       "         4.4394e-04, 5.5167e-03, 2.1220e-03, 1.1713e-03, 3.1910e-04, 6.9026e-04,\n",
       "         1.6629e-03, 4.7906e-04, 7.5134e-04, 9.5037e-04, 1.3449e-03, 2.5993e-04,\n",
       "         2.6916e-04, 2.4181e-04, 3.8118e-03, 6.2268e-04, 9.8551e-03, 4.0294e-04,\n",
       "         1.3567e-03, 8.8245e-04, 5.5730e-04, 5.7498e-04, 2.7419e-03, 7.9744e-03,\n",
       "         1.7251e-03, 2.3550e-04, 3.6725e-04, 6.8167e-04, 8.8052e-05, 5.9107e-04,\n",
       "         5.0336e-04, 1.2363e-03, 5.6363e-04, 2.9516e-04, 2.9873e-04, 3.9162e-02,\n",
       "         2.0958e-04, 1.8776e-03, 3.0877e-04, 6.2970e-05, 5.4795e-04, 9.5673e-04,\n",
       "         1.7330e-04, 1.2124e-03, 1.1016e-04, 3.1098e-03, 9.6373e-04, 3.2197e-04,\n",
       "         4.0324e-04, 3.4889e-04, 9.1908e-05, 1.8984e-04, 1.8885e-03, 7.5363e-04,\n",
       "         4.0751e-04, 9.0783e-05, 1.2129e-04, 3.7444e-04, 9.1184e-03, 8.0245e-05,\n",
       "         2.2348e-03, 9.0113e-05, 3.2397e-04, 1.8631e-02, 3.9037e-03, 2.2033e-03,\n",
       "         1.2285e-04, 7.7831e-04, 5.9480e-02, 3.9698e-04, 1.7544e-03, 4.0348e-03,\n",
       "         1.6794e-04, 3.4139e-04, 3.5908e-03, 1.0235e-03, 8.3598e-03, 1.4548e-04,\n",
       "         4.2514e-04, 2.6331e-04, 1.0022e-03, 9.8954e-04, 5.7972e-04, 5.1819e-04,\n",
       "         1.0747e-02, 5.8109e-04, 3.5081e-03, 1.6434e-02, 1.8021e-03, 8.6422e-04,\n",
       "         1.8307e-04, 7.9503e-04, 3.3882e-04, 1.0943e-03, 2.5818e-03, 1.6915e-03,\n",
       "         7.9073e-04, 2.4969e-04, 2.4292e-04, 3.5154e-03, 1.1003e-03, 1.7331e-03,\n",
       "         1.1774e-04, 6.6079e-03, 7.0167e-03, 6.9905e-04, 1.8945e-03, 3.6656e-04,\n",
       "         1.3927e-04, 4.2927e-04, 9.3009e-04, 2.2425e-03, 3.2276e-03, 9.4235e-03,\n",
       "         1.2844e-03, 2.9557e-04, 1.5138e-04, 1.4059e-03, 1.1081e-02, 3.6152e-03,\n",
       "         2.2705e-03, 2.7222e-04, 8.2429e-04, 7.2226e-05, 5.6565e-04, 7.2734e-04,\n",
       "         1.0663e-03, 1.2430e-03, 1.4483e-03, 4.9303e-04, 4.7164e-03, 1.6031e-01,\n",
       "         1.7872e-03, 4.0719e-04, 3.4303e-03, 4.0973e-04, 3.9377e-03, 2.6940e-04,\n",
       "         2.2669e-04, 1.1905e-04, 2.1636e-03, 1.2902e-04, 5.9370e-04, 6.8783e-04,\n",
       "         2.7795e-04, 4.6849e-04, 1.2738e-03, 4.0184e-04, 1.1463e-03, 1.1702e-03,\n",
       "         2.2237e-03, 9.7055e-04, 5.2746e-04, 1.0747e-04, 8.9821e-05, 2.1426e-04,\n",
       "         1.3116e-03, 2.8896e-03, 4.9976e-04, 1.1297e-02, 7.1312e-04, 6.7403e-04,\n",
       "         2.6376e-04, 3.7397e-04, 1.1431e-03, 1.9042e-03, 2.8141e-03, 4.4632e-04,\n",
       "         3.5320e-04, 1.5968e-03, 2.5879e-04, 7.5153e-04, 2.3896e-04, 3.4488e-03,\n",
       "         3.1181e-04, 5.9256e-04, 4.7950e-03, 1.9674e-04, 1.3323e-03, 3.1646e-04,\n",
       "         4.4337e-04, 6.1393e-04, 8.8368e-03, 1.4001e-03, 9.0669e-05, 1.3064e-04,\n",
       "         9.4529e-03, 1.7898e-03, 1.5127e-02, 6.5016e-04, 6.3115e-03, 3.3676e-03,\n",
       "         3.2136e-04, 1.1170e-03, 3.8781e-04, 2.0128e-02, 1.1863e-03, 5.0303e-04,\n",
       "         6.0698e-03, 4.3418e-03, 9.4570e-04, 3.6843e-04, 1.2794e-04, 2.6560e-04,\n",
       "         1.4253e-03, 1.0466e-03, 1.0705e-03, 1.9534e-03, 2.3182e-04, 4.7867e-03,\n",
       "         5.1450e-04, 6.7830e-03, 6.7763e-04, 6.8903e-05, 2.1061e-03, 3.1051e-04,\n",
       "         2.2481e-04, 3.5933e-04, 3.1826e-04, 9.0964e-04, 1.3668e-03, 3.7329e-04,\n",
       "         1.9853e-03, 1.7600e-04, 2.5484e-03, 1.3312e-04, 1.0729e-03, 7.8160e-04,\n",
       "         1.1050e-04, 6.3823e-03, 2.0037e-04, 5.7263e-04, 6.2053e-04, 8.3353e-03,\n",
       "         8.2726e-04, 1.8791e-04, 8.9340e-04, 3.2202e-04, 4.7016e-04, 3.3648e-04,\n",
       "         1.8012e-04, 9.0806e-04, 2.8956e-03, 4.5853e-04, 2.1141e-03, 3.1305e-03,\n",
       "         2.2268e-04, 7.5561e-04, 3.2830e-04, 5.2852e-04, 8.3888e-03, 1.2129e-03,\n",
       "         3.5079e-04, 1.3082e+00, 3.0759e-04, 1.2643e-03, 2.4870e-04, 3.4036e-04,\n",
       "         2.3854e-04, 3.7371e-02, 1.4075e-02, 8.3372e-05, 2.4923e-04, 4.1878e-04,\n",
       "         3.2583e-04, 6.4810e-03, 3.2231e-04, 1.6939e-03, 5.9245e-04, 1.0090e-03,\n",
       "         9.8212e-03, 1.8912e-04, 5.7123e-04, 5.0063e-04, 6.4257e-03, 9.5122e-05,\n",
       "         1.6657e-04, 1.8276e-04, 2.5488e-03, 4.8068e-04, 8.6601e-04, 3.1407e-04,\n",
       "         3.9092e-04, 4.4662e-04, 4.1740e-04, 1.0993e-03, 2.7312e-04, 2.6628e-04,\n",
       "         3.5968e-03, 1.3761e-01, 3.0098e-03, 3.2547e-03, 9.2067e-04, 3.7990e-04,\n",
       "         1.4039e-03, 3.0297e-03, 7.3207e-05, 4.9522e-04, 1.1883e-03, 1.3319e-03,\n",
       "         1.1274e-03, 2.2884e-03, 1.1153e-03, 7.5616e-04, 3.3665e-04, 5.7418e-04,\n",
       "         9.7444e-04, 2.3358e-04, 1.1336e-03, 5.9198e-04, 6.1387e-04, 2.7732e-04,\n",
       "         3.1114e-04, 2.6806e-04, 1.4601e-04, 1.2971e-04, 1.5170e-04, 1.2116e-03,\n",
       "         6.3646e-04, 1.9030e-04, 3.8763e-04, 5.9924e-03, 1.7562e-03, 3.1991e-03,\n",
       "         9.5666e-04, 2.6356e-04, 6.4150e-03, 1.5561e-03, 5.5146e-04, 4.0082e-04,\n",
       "         9.5126e-05, 2.5781e-04, 5.3230e-04, 2.6635e-03, 8.7666e-04, 1.6459e-03,\n",
       "         1.9175e-03, 1.3381e-04, 2.3952e-03, 7.5245e-02, 1.4444e-03, 1.3340e-03,\n",
       "         2.6454e-04, 1.4091e-03, 2.3527e-04, 3.9602e-03, 2.2251e-03, 4.2015e-04,\n",
       "         1.8415e-04, 3.8760e-04, 6.2809e-04, 1.0418e-04, 3.8519e-03, 1.3098e-02,\n",
       "         1.9778e-03, 2.0450e-04, 2.5702e-03, 7.2209e-04, 1.7502e-03, 6.3191e-03,\n",
       "         9.3154e-04, 3.1637e-02, 3.0977e-04, 1.2344e-02, 3.4696e-04, 1.4823e-02,\n",
       "         7.9564e-05, 1.7207e-03, 4.6337e-04, 1.1771e-03, 5.6335e-04, 2.8542e-04,\n",
       "         2.3944e-04, 1.6547e-04, 5.1987e-04, 4.8452e-03, 8.2105e-02, 4.4783e-03,\n",
       "         6.4769e-04, 2.8099e-04, 6.5212e-04, 6.7329e-04, 1.0004e-04, 9.2596e-04,\n",
       "         1.7250e-03, 1.3864e-04, 6.5804e-04, 9.6131e-03, 4.5365e-04, 5.6492e-04,\n",
       "         1.5104e-03, 2.0571e-04, 2.1451e-04, 6.9234e-05, 9.7363e-04, 8.4722e-04,\n",
       "         1.5358e-04, 2.1838e-03], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.4.layer.1.EncDecAttention.q.weight': tensor([[6.2143e-06, 9.8539e-06, 1.5027e-05,  ..., 2.7508e-06, 2.2342e-06,\n",
       "          2.9069e-06],\n",
       "         [1.1849e-05, 3.2442e-05, 4.7136e-05,  ..., 8.2622e-06, 8.6430e-06,\n",
       "          1.2068e-05],\n",
       "         [1.3085e-05, 4.6040e-06, 4.3862e-05,  ..., 6.6364e-06, 4.1900e-05,\n",
       "          1.4480e-05],\n",
       "         ...,\n",
       "         [2.6664e-05, 2.0499e-06, 5.0766e-05,  ..., 3.7547e-06, 5.8645e-06,\n",
       "          1.5715e-06],\n",
       "         [3.5655e-06, 1.5035e-06, 5.0877e-06,  ..., 7.1895e-07, 2.1404e-06,\n",
       "          3.5787e-06],\n",
       "         [1.1470e-05, 7.7770e-06, 1.8508e-05,  ..., 2.1361e-06, 2.0123e-06,\n",
       "          2.1064e-06]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.4.layer.1.EncDecAttention.k.weight': tensor([[4.5667e-06, 1.0321e-05, 2.4563e-05,  ..., 3.3487e-05, 1.6754e-05,\n",
       "          8.8166e-06],\n",
       "         [1.2243e-07, 7.6151e-08, 1.3241e-07,  ..., 2.0680e-07, 9.9355e-08,\n",
       "          6.3830e-08],\n",
       "         [8.6607e-06, 1.9020e-05, 4.6144e-05,  ..., 6.3826e-05, 3.1751e-05,\n",
       "          1.5961e-05],\n",
       "         ...,\n",
       "         [8.2875e-07, 3.5647e-07, 6.2690e-07,  ..., 2.0334e-07, 2.5312e-07,\n",
       "          3.6352e-07],\n",
       "         [5.7088e-08, 5.3854e-08, 1.7766e-07,  ..., 1.1719e-07, 4.3461e-08,\n",
       "          5.2653e-08],\n",
       "         [2.3646e-08, 8.5004e-08, 7.1055e-07,  ..., 4.2085e-08, 1.1354e-07,\n",
       "          1.7884e-08]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.4.layer.1.EncDecAttention.v.weight': tensor([[1.3629e-08, 1.5755e-08, 2.8157e-08,  ..., 6.1934e-08, 5.9901e-09,\n",
       "          1.6017e-08],\n",
       "         [2.5867e-08, 1.9330e-08, 5.6512e-08,  ..., 1.0531e-07, 1.6680e-08,\n",
       "          2.2516e-08],\n",
       "         [1.0468e-08, 7.0653e-09, 5.0601e-09,  ..., 5.1688e-08, 3.8840e-09,\n",
       "          1.1488e-08],\n",
       "         ...,\n",
       "         [7.5931e-09, 8.6985e-09, 1.0366e-08,  ..., 1.6559e-08, 3.8321e-09,\n",
       "          8.1895e-09],\n",
       "         [2.7788e-09, 1.1937e-08, 1.2511e-08,  ..., 8.0213e-09, 2.2094e-09,\n",
       "          3.3988e-09],\n",
       "         [5.3191e-09, 2.2390e-09, 5.0092e-09,  ..., 1.5339e-08, 1.8400e-09,\n",
       "          6.0869e-09]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.4.layer.1.EncDecAttention.o.weight': tensor([[5.2922e-08, 8.4709e-08, 6.6885e-09,  ..., 5.5669e-09, 2.1571e-08,\n",
       "          3.3603e-08],\n",
       "         [1.0892e-08, 1.5355e-08, 8.4912e-09,  ..., 4.9558e-09, 6.2009e-09,\n",
       "          1.5559e-09],\n",
       "         [2.8281e-08, 4.8758e-08, 2.5061e-08,  ..., 5.7445e-09, 1.8385e-08,\n",
       "          2.7701e-09],\n",
       "         ...,\n",
       "         [2.9800e-08, 4.6755e-08, 1.1000e-08,  ..., 4.0262e-09, 1.8857e-08,\n",
       "          1.3983e-08],\n",
       "         [4.3464e-07, 2.1330e-07, 2.3512e-07,  ..., 1.8159e-07, 3.0863e-07,\n",
       "          1.8952e-07],\n",
       "         [7.2800e-08, 1.7848e-07, 2.5556e-08,  ..., 3.2028e-09, 5.1980e-08,\n",
       "          5.2268e-08]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.4.layer.1.layer_norm.weight': tensor([7.6213e-03, 6.3819e-03, 6.2999e-03, 3.2920e-02, 3.8427e-01, 2.0739e-03,\n",
       "         1.5916e-03, 1.3677e-02, 1.4432e-02, 1.9250e-03, 1.6516e-02, 6.9210e-03,\n",
       "         1.2636e-03, 1.5402e-02, 1.9779e-03, 8.1650e-04, 3.3170e-03, 9.7613e-04,\n",
       "         2.2275e-03, 1.6739e-04, 8.4604e-04, 4.3884e-03, 1.6394e-03, 7.5764e-02,\n",
       "         2.8565e-04, 9.2615e-03, 1.5006e-03, 3.4448e-03, 8.0506e-02, 8.9747e-04,\n",
       "         1.9000e-03, 2.0413e-02, 2.1072e-02, 3.6364e-03, 1.2015e-03, 5.2604e-04,\n",
       "         4.8301e-03, 1.0548e-02, 3.8605e-04, 2.3613e-02, 6.7671e-04, 7.6045e-04,\n",
       "         5.5863e-03, 4.9006e-03, 3.2630e-02, 8.4964e-03, 1.4928e-01, 1.3708e-03,\n",
       "         3.2950e-03, 9.6996e-03, 7.5170e-02, 2.5469e-03, 4.9536e-03, 1.8259e-01,\n",
       "         3.9316e-03, 5.6845e-03, 2.7952e-02, 1.6542e-01, 2.0013e-03, 1.1966e-03,\n",
       "         1.6799e-03, 6.0066e-03, 3.9624e-03, 1.6379e-03, 2.2377e-03, 1.9017e-03,\n",
       "         6.2736e-03, 1.8081e-03, 4.9357e-03, 1.4496e-02, 3.7732e-02, 1.9534e-03,\n",
       "         1.3311e-03, 3.5357e-03, 2.0001e-02, 5.5039e-03, 1.2084e-03, 3.8915e-03,\n",
       "         1.0013e-03, 7.5733e-04, 8.4662e-03, 1.9649e-02, 1.7636e-02, 1.4934e-03,\n",
       "         1.9174e-03, 1.4663e-02, 1.4205e-01, 1.3741e-01, 9.3082e-04, 2.1911e-02,\n",
       "         8.4535e-03, 1.8089e-03, 4.9700e-03, 2.9438e-03, 9.9934e-04, 3.2683e-03,\n",
       "         5.6839e-04, 2.9632e-02, 1.0512e-03, 5.0617e-04, 2.4021e-02, 2.7579e-02,\n",
       "         1.6657e-03, 4.3668e-03, 8.5212e-03, 5.9694e-02, 1.7871e-03, 3.1066e-03,\n",
       "         2.8306e-04, 9.0213e-04, 3.3594e-03, 5.3112e-03, 7.3627e-03, 5.6183e-02,\n",
       "         7.9533e-04, 2.3916e-02, 1.1689e-03, 7.0871e-04, 1.2225e-03, 4.1459e-02,\n",
       "         4.6344e-03, 3.9624e-03, 4.0408e-03, 2.8955e-03, 6.9739e-03, 3.6535e-03,\n",
       "         2.1423e-03, 7.2940e-03, 2.0652e-02, 2.5174e-02, 1.6057e-01, 4.8879e-03,\n",
       "         1.7464e-03, 1.5007e-02, 1.9469e-03, 1.1440e-03, 9.4016e-03, 8.3760e-03,\n",
       "         4.3941e-02, 1.4259e-03, 5.3072e-03, 1.6968e-03, 9.5111e-03, 1.1788e-03,\n",
       "         6.5478e-04, 3.7783e-03, 3.9781e-03, 9.7018e-04, 1.2272e-03, 1.6562e-01,\n",
       "         8.8773e-03, 3.7793e-03, 1.7060e-03, 1.6408e-01, 1.2261e-02, 2.2832e-03,\n",
       "         1.4404e-03, 2.5878e-02, 1.6141e-02, 7.1187e-02, 5.4796e-03, 3.0374e-02,\n",
       "         1.8820e-02, 4.9893e-02, 9.4717e-03, 9.5889e-04, 1.5033e-02, 1.7767e-04,\n",
       "         3.2940e-02, 2.6308e-04, 3.8285e-03, 3.7325e-03, 9.4461e-03, 1.0251e-03,\n",
       "         9.9885e-04, 7.9003e-04, 9.1390e-04, 9.7495e-03, 6.5630e-03, 7.7836e-03,\n",
       "         5.5201e-03, 2.5900e-03, 3.2590e-02, 3.4979e-03, 4.1823e-02, 9.2119e-03,\n",
       "         1.9686e-03, 8.2538e-03, 3.1350e-03, 1.3128e-02, 1.0113e-01, 5.6936e-03,\n",
       "         8.4984e-03, 8.1434e-04, 9.9927e-04, 1.8934e-03, 8.6863e-04, 1.2096e-02,\n",
       "         1.0615e-02, 1.4586e-03, 2.5745e-03, 8.2690e-02, 9.0608e-03, 3.7102e-03,\n",
       "         9.7564e-04, 9.9012e-03, 2.3500e-03, 1.8139e-03, 6.7958e-03, 2.3032e-02,\n",
       "         3.8508e-02, 1.0225e-03, 6.8001e-03, 8.7831e-03, 9.9705e-04, 1.0945e-02,\n",
       "         2.6018e-03, 5.7449e-02, 4.2760e-03, 1.6178e-03, 1.1153e-02, 1.8294e-03,\n",
       "         7.7768e-03, 9.8750e-03, 8.1655e-03, 1.0872e-03, 1.7038e-03, 8.6541e-03,\n",
       "         3.1994e-02, 7.6200e-04, 7.5177e-03, 2.5266e-04, 5.0979e-02, 3.4251e-03,\n",
       "         1.2675e-02, 4.2827e-03, 1.9938e-03, 3.2337e-04, 2.0809e-03, 6.6708e-04,\n",
       "         4.7579e-03, 4.8536e-04, 7.0075e-03, 3.3918e-03, 1.6915e-02, 4.7849e-02,\n",
       "         3.9534e-03, 6.7788e-03, 7.4429e-02, 4.4578e-04, 6.2152e-04, 2.6796e-03,\n",
       "         2.0077e-03, 1.0840e-03, 3.1031e-04, 3.7226e-03, 1.5637e-03, 3.3893e-03,\n",
       "         6.2275e-03, 4.6421e-02, 1.6442e-02, 4.3801e-03, 3.1260e-03, 8.4527e-03,\n",
       "         5.6950e-03, 5.8486e-02, 8.5844e-03, 2.1355e-03, 1.8923e-03, 1.2609e-03,\n",
       "         6.7187e-04, 3.1015e-02, 1.4010e-03, 3.2434e-03, 2.5679e-03, 2.2456e-03,\n",
       "         1.4940e-02, 1.6492e-03, 4.5713e-03, 2.3547e-02, 1.5758e-03, 1.3778e-02,\n",
       "         2.0869e-03, 2.1965e-02, 1.0059e-03, 2.0088e-03, 7.8697e-03, 1.1296e-02,\n",
       "         1.9347e-03, 7.7216e-04, 3.6563e-04, 2.5537e-02, 2.8266e-03, 9.5024e-03,\n",
       "         8.1462e-03, 1.0921e-03, 2.6557e-03, 4.2760e-03, 1.8122e-03, 3.0949e-04,\n",
       "         2.9878e-02, 1.9848e-03, 2.8966e-01, 5.9538e-03, 1.4249e-02, 7.1885e-03,\n",
       "         2.2693e-03, 7.3011e-03, 9.7369e-02, 4.3016e-01, 3.5015e-03, 2.1837e-03,\n",
       "         4.9413e-02, 1.7215e-02, 4.4636e-03, 4.4121e-03, 1.3016e-02, 2.5133e-03,\n",
       "         5.1838e-03, 4.7454e-03, 1.8262e-03, 1.6799e-02, 7.2548e-03, 2.0649e-02,\n",
       "         2.9259e-02, 4.8523e-02, 2.5274e-03, 1.5255e-03, 9.6833e-03, 2.4966e-04,\n",
       "         5.5252e-03, 6.9646e-03, 1.0826e-02, 1.1018e-02, 2.9936e-03, 5.3769e-04,\n",
       "         2.5272e-03, 2.3135e-03, 2.8662e-03, 4.3323e-02, 1.1888e-03, 2.6781e-03,\n",
       "         5.0993e-04, 1.5869e-02, 1.0269e-03, 8.3911e-04, 2.9379e-03, 3.4878e-02,\n",
       "         1.0295e-03, 9.1453e-04, 6.2543e-03, 5.3340e-03, 7.6006e-04, 5.7199e-04,\n",
       "         3.0061e-03, 7.4848e-04, 6.3009e-03, 4.4852e-03, 1.1030e-03, 2.4260e-02,\n",
       "         5.5881e-03, 4.1044e-04, 3.8015e-03, 8.4558e-02, 7.2481e-02, 1.9540e-02,\n",
       "         2.6881e-03, 3.8028e-01, 1.2780e-03, 3.3094e-02, 5.0182e-03, 4.2338e-04,\n",
       "         2.4615e-03, 7.1834e-03, 2.7970e-01, 1.4096e-02, 3.6169e-03, 1.8569e-02,\n",
       "         6.8622e-03, 2.0838e-02, 4.3885e-03, 5.3731e-02, 1.2157e-02, 1.0317e-03,\n",
       "         5.2351e-03, 1.3339e-03, 1.6815e-02, 3.3834e-04, 2.5085e-02, 5.5715e-04,\n",
       "         1.8748e-03, 1.1992e-03, 1.8687e-03, 6.3344e-03, 1.5980e-03, 6.4822e-04,\n",
       "         1.2991e-02, 9.1904e-03, 2.5204e-03, 2.8406e-04, 1.8572e-03, 1.8510e-03,\n",
       "         5.8862e-04, 4.2087e-01, 2.5707e-03, 3.6475e-03, 3.1714e-02, 1.4207e-03,\n",
       "         2.2274e-03, 1.8044e-03, 1.3637e-03, 4.9363e-04, 1.4566e-03, 1.6353e-03,\n",
       "         8.6537e-04, 3.5676e-02, 1.1723e-03, 1.1990e-02, 8.4170e-03, 9.7659e-04,\n",
       "         2.7784e-03, 1.7754e-02, 2.6482e-03, 7.4497e-03, 3.1561e-03, 1.0328e-03,\n",
       "         8.5590e-03, 5.4387e-02, 1.6012e-03, 3.5939e-02, 1.4509e-03, 1.9095e-02,\n",
       "         3.6091e-03, 5.1111e-03, 5.8139e-03, 1.7413e-03, 1.0219e-03, 4.4987e-03,\n",
       "         7.5049e-03, 7.4358e-03, 4.1726e-02, 4.7701e-04, 1.4374e-02, 2.9235e-04,\n",
       "         9.1652e-04, 1.0868e-03, 1.2501e-02, 1.4976e-03, 1.3356e-03, 1.8593e-03,\n",
       "         1.3583e-02, 3.9768e-03, 5.9773e-03, 1.6485e-01, 2.1321e-03, 2.6614e-02,\n",
       "         9.4834e-03, 1.5273e-03, 9.5952e-03, 1.1634e-02, 8.2553e-03, 3.0161e-03,\n",
       "         6.9759e-03, 7.9814e-03, 3.6883e-03, 4.2392e-04, 1.6046e-03, 1.3553e-01,\n",
       "         1.5383e-03, 3.7023e-03, 6.2248e-03, 7.6620e-03, 1.3040e-02, 3.8765e-01,\n",
       "         2.8813e-03, 5.1134e-03, 2.7045e-03, 1.5962e-02, 9.1441e-04, 2.0632e-02,\n",
       "         2.7734e-03, 6.5400e-04, 6.2915e-02, 9.1853e-03, 3.8513e-03, 8.8322e-04,\n",
       "         3.6583e-03, 1.9459e-03, 5.9380e-04, 3.2029e-03, 3.4669e-01, 3.7741e-02,\n",
       "         8.9708e-03, 4.5206e-02, 5.8298e-02, 9.5222e-03, 1.9124e-03, 2.8246e-03,\n",
       "         1.4369e-03, 7.1539e-03, 6.1748e-03, 2.5307e-02, 1.6926e-02, 8.4074e-02,\n",
       "         3.1867e-03, 7.6854e-03, 7.7994e-04, 6.2175e-04, 4.7868e-02, 5.7428e-03,\n",
       "         6.3397e-04, 2.9919e-04], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.4.layer.2.DenseReluDense.wi.weight': tensor([[1.0333e-15, 1.0431e-12, 1.2364e-12,  ..., 2.1844e-12, 1.6627e-12,\n",
       "          2.3358e-12],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         ...,\n",
       "         [7.9239e-11, 4.2387e-11, 2.0962e-10,  ..., 1.4496e-12, 5.2433e-11,\n",
       "          2.6296e-10],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [1.6375e-09, 1.5451e-08, 5.3142e-08,  ..., 2.4955e-08, 7.8800e-09,\n",
       "          1.2463e-08]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.4.layer.2.DenseReluDense.wo.weight': tensor([[3.1564e-12, 0.0000e+00, 0.0000e+00,  ..., 1.7522e-11, 0.0000e+00,\n",
       "          7.1868e-09],\n",
       "         [5.8455e-12, 0.0000e+00, 0.0000e+00,  ..., 7.5187e-12, 0.0000e+00,\n",
       "          8.5188e-09],\n",
       "         [1.5540e-12, 0.0000e+00, 0.0000e+00,  ..., 2.5313e-12, 0.0000e+00,\n",
       "          2.5232e-08],\n",
       "         ...,\n",
       "         [1.0457e-13, 0.0000e+00, 0.0000e+00,  ..., 1.9981e-12, 0.0000e+00,\n",
       "          7.3105e-08],\n",
       "         [8.7783e-11, 0.0000e+00, 0.0000e+00,  ..., 5.2075e-11, 0.0000e+00,\n",
       "          3.2301e-07],\n",
       "         [1.5136e-12, 0.0000e+00, 0.0000e+00,  ..., 9.2417e-12, 0.0000e+00,\n",
       "          1.7365e-08]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.4.layer.2.layer_norm.weight': tensor([2.4412e-06, 1.2813e-06, 5.8961e-06, 3.4315e-06, 7.8081e-04, 7.8079e-06,\n",
       "         3.1288e-06, 8.5173e-07, 4.6042e-07, 7.0903e-06, 6.1665e-07, 4.6046e-06,\n",
       "         2.7860e-06, 7.6513e-07, 6.7124e-07, 1.5217e-06, 4.9426e-06, 2.5637e-06,\n",
       "         1.6093e-05, 1.0274e-06, 4.0935e-06, 1.4550e-05, 5.6616e-07, 1.3462e-05,\n",
       "         1.3707e-06, 4.7530e-06, 4.5079e-06, 3.9192e-06, 2.7500e-06, 1.5967e-06,\n",
       "         4.9162e-07, 5.1373e-06, 2.7873e-05, 3.0066e-06, 3.5483e-06, 1.4693e-06,\n",
       "         5.1030e-06, 5.6435e-06, 1.9999e-06, 4.5729e-06, 1.6240e-06, 3.8382e-06,\n",
       "         3.4794e-06, 3.7729e-06, 3.9745e-06, 2.3828e-06, 7.2213e-05, 9.5308e-07,\n",
       "         1.6524e-06, 4.8393e-06, 1.2209e-06, 1.5457e-06, 2.4702e-06, 9.3271e-06,\n",
       "         4.2531e-06, 3.3782e-06, 4.2735e-06, 2.0434e-06, 1.5249e-06, 2.1785e-06,\n",
       "         4.2057e-06, 1.0622e-05, 3.2269e-06, 4.4091e-06, 2.6265e-06, 2.2022e-06,\n",
       "         9.7273e-07, 1.3340e-06, 2.0094e-06, 8.1881e-06, 1.9979e-06, 6.4119e-07,\n",
       "         8.0518e-06, 5.7893e-06, 3.1224e-06, 1.0445e-06, 1.3386e-06, 5.5766e-06,\n",
       "         1.0677e-06, 1.2026e-06, 2.8621e-06, 4.4270e-06, 1.6552e-06, 1.6770e-06,\n",
       "         4.1765e-06, 7.9600e-07, 1.6618e-05, 6.4715e-05, 3.5636e-06, 6.6418e-06,\n",
       "         3.3539e-06, 1.0996e-06, 3.0781e-06, 1.2597e-06, 1.4853e-06, 1.2188e-06,\n",
       "         2.7915e-06, 2.4564e-05, 6.5366e-06, 4.7093e-06, 1.5086e-06, 1.3732e-05,\n",
       "         3.3653e-05, 2.7707e-06, 2.0542e-06, 5.4360e-06, 1.8732e-05, 5.1003e-06,\n",
       "         3.0271e-07, 6.6730e-06, 1.8863e-06, 9.6951e-07, 9.2358e-06, 2.1669e-05,\n",
       "         2.3818e-06, 1.8903e-06, 8.9606e-07, 9.5065e-07, 4.3666e-06, 4.4414e-06,\n",
       "         1.0481e-06, 3.0984e-06, 3.9484e-06, 2.2268e-06, 8.3260e-06, 1.2916e-06,\n",
       "         2.5741e-06, 2.1466e-05, 1.0919e-05, 2.3997e-06, 2.6140e-06, 5.7587e-06,\n",
       "         2.8191e-06, 2.8497e-06, 1.6129e-06, 4.7453e-06, 4.7844e-06, 9.4288e-06,\n",
       "         3.2031e-06, 7.1174e-07, 8.5165e-06, 2.9906e-06, 2.5769e-06, 1.7291e-06,\n",
       "         1.8978e-05, 4.5072e-07, 3.9233e-06, 8.0707e-06, 1.0367e-06, 8.3680e-04,\n",
       "         2.0875e-06, 4.0472e-06, 3.6180e-06, 6.7035e-06, 1.8168e-06, 5.8164e-06,\n",
       "         4.1311e-06, 1.2536e-05, 1.4155e-05, 1.7520e-05, 1.3030e-06, 1.3163e-06,\n",
       "         1.7905e-06, 3.4222e-05, 1.9177e-06, 8.8937e-06, 7.4308e-07, 1.5357e-06,\n",
       "         1.3387e-06, 5.0302e-06, 3.5080e-06, 4.2577e-06, 3.3580e-06, 4.7555e-06,\n",
       "         5.2198e-06, 6.2550e-07, 7.3319e-07, 6.2407e-06, 6.4749e-06, 2.0026e-06,\n",
       "         2.3273e-05, 5.3142e-06, 6.7492e-05, 1.9190e-06, 5.1124e-06, 8.9109e-06,\n",
       "         6.2904e-06, 1.3899e-06, 5.1072e-05, 4.8108e-06, 4.9093e-06, 5.2253e-07,\n",
       "         9.3412e-07, 1.5221e-06, 1.7043e-06, 1.4089e-06, 2.9919e-06, 1.6698e-06,\n",
       "         3.9132e-06, 5.5289e-07, 5.0831e-06, 3.8745e-06, 6.0639e-06, 7.7329e-07,\n",
       "         1.4167e-06, 3.4378e-06, 3.6841e-06, 3.0969e-06, 8.1777e-06, 7.3249e-06,\n",
       "         2.2428e-06, 2.3465e-06, 2.6437e-06, 1.6652e-05, 1.2469e-05, 8.4705e-06,\n",
       "         6.7389e-06, 1.1335e-06, 3.9410e-06, 1.7840e-06, 1.7768e-06, 2.1286e-06,\n",
       "         1.4300e-06, 3.4726e-06, 2.7563e-05, 4.8793e-07, 4.2316e-06, 1.5294e-06,\n",
       "         2.3638e-06, 1.4477e-06, 5.0223e-06, 4.4913e-06, 2.5899e-05, 3.4052e-06,\n",
       "         2.4137e-06, 3.1438e-06, 5.4625e-06, 5.0289e-07, 2.1987e-07, 1.1743e-06,\n",
       "         8.0436e-06, 5.0990e-06, 1.6437e-06, 6.1337e-06, 6.6262e-06, 1.4047e-04,\n",
       "         8.5378e-06, 1.6345e-06, 1.3869e-05, 2.7516e-06, 4.4249e-06, 1.0147e-06,\n",
       "         6.4031e-07, 3.3631e-06, 2.4446e-06, 2.9740e-06, 6.3685e-06, 3.3156e-06,\n",
       "         4.5080e-07, 2.1548e-06, 7.2923e-07, 1.3728e-05, 6.7745e-06, 9.2173e-06,\n",
       "         3.5907e-06, 2.2585e-05, 2.3289e-06, 2.4483e-06, 4.1481e-06, 1.9726e-06,\n",
       "         2.9331e-06, 6.7467e-07, 1.6773e-06, 5.0605e-06, 9.8241e-07, 8.3421e-07,\n",
       "         3.5377e-06, 1.9276e-06, 1.6664e-06, 3.7116e-06, 3.9533e-07, 1.4954e-06,\n",
       "         2.9836e-06, 7.1497e-06, 3.5912e-06, 8.4552e-07, 1.6570e-06, 8.5799e-07,\n",
       "         3.4144e-06, 2.5265e-06, 3.9924e-06, 8.5509e-08, 9.9679e-06, 1.6310e-05,\n",
       "         7.3737e-07, 2.1510e-06, 3.2853e-06, 1.8836e-06, 1.2336e-06, 4.2423e-07,\n",
       "         9.7618e-06, 1.0086e-06, 2.4883e-04, 2.6028e-06, 6.7246e-07, 5.3044e-05,\n",
       "         2.1654e-06, 1.2181e-05, 7.0700e-06, 3.4147e-06, 1.8887e-06, 3.8447e-07,\n",
       "         1.6549e-06, 3.1226e-05, 3.4295e-06, 2.6380e-05, 1.1303e-05, 2.5105e-06,\n",
       "         4.6010e-06, 1.3730e-06, 5.1297e-06, 5.7445e-06, 1.9224e-06, 1.0233e-05,\n",
       "         1.0932e-05, 5.8846e-06, 3.2126e-06, 2.1259e-06, 2.9585e-06, 6.1442e-07,\n",
       "         2.8014e-06, 4.4427e-06, 7.6570e-06, 2.6041e-06, 1.6097e-05, 5.0077e-07,\n",
       "         1.0150e-06, 1.4886e-06, 5.2248e-06, 1.1301e-06, 2.0487e-06, 5.3797e-07,\n",
       "         2.5761e-06, 2.0022e-06, 4.3971e-06, 4.2575e-06, 2.3181e-06, 4.4130e-06,\n",
       "         3.3333e-06, 6.4184e-07, 6.1899e-06, 3.0712e-06, 1.7737e-06, 5.0528e-06,\n",
       "         1.1659e-06, 1.2700e-06, 2.8896e-06, 1.7739e-06, 4.5107e-06, 9.8993e-07,\n",
       "         8.9083e-07, 6.4913e-06, 7.4909e-06, 2.9193e-06, 1.1519e-05, 6.9041e-06,\n",
       "         5.4276e-06, 9.1733e-04, 1.7721e-06, 1.9584e-06, 3.6602e-06, 2.5889e-06,\n",
       "         2.2528e-06, 6.7779e-07, 1.0251e-05, 1.9021e-06, 3.8160e-06, 5.7995e-06,\n",
       "         2.2344e-06, 1.5469e-06, 1.6860e-06, 1.4027e-05, 4.7965e-06, 1.4634e-06,\n",
       "         1.1664e-05, 1.0946e-06, 3.3426e-06, 9.8300e-07, 1.2561e-05, 5.5826e-06,\n",
       "         1.3497e-06, 2.1461e-06, 6.4786e-06, 8.1199e-06, 1.0378e-06, 7.5792e-06,\n",
       "         1.1408e-06, 2.5019e-06, 2.2564e-05, 4.0201e-07, 4.9711e-07, 3.2404e-06,\n",
       "         1.5466e-06, 3.8933e-03, 1.7257e-06, 4.1198e-06, 8.3103e-07, 1.1988e-05,\n",
       "         2.1506e-06, 8.8305e-06, 1.0392e-06, 1.5301e-06, 4.6168e-07, 2.0979e-06,\n",
       "         1.7512e-05, 1.0104e-06, 1.0621e-06, 2.8828e-06, 1.1573e-06, 4.1557e-06,\n",
       "         1.5020e-06, 4.2151e-06, 1.2389e-06, 1.2030e-06, 3.8256e-06, 1.1664e-06,\n",
       "         3.7798e-06, 2.6005e-06, 3.4945e-06, 2.8689e-06, 5.7973e-07, 4.7725e-06,\n",
       "         1.0905e-06, 6.3193e-06, 9.0372e-06, 2.3749e-06, 1.3068e-06, 3.1703e-06,\n",
       "         4.6982e-06, 8.0193e-06, 3.4337e-06, 5.3541e-07, 1.4892e-06, 9.2726e-07,\n",
       "         3.2415e-06, 9.4013e-06, 2.9396e-06, 4.6782e-06, 9.1130e-06, 8.3232e-07,\n",
       "         2.0919e-06, 5.4535e-07, 3.2547e-07, 3.9561e-06, 1.3888e-05, 2.4845e-06,\n",
       "         3.6356e-06, 6.9461e-07, 1.6575e-06, 1.9642e-06, 3.1510e-06, 3.2864e-07,\n",
       "         1.2356e-06, 1.7275e-06, 4.6368e-06, 5.8116e-06, 5.3745e-06, 3.5831e-05,\n",
       "         1.0390e-06, 7.8280e-06, 9.1556e-06, 4.6973e-06, 1.9472e-06, 4.4323e-05,\n",
       "         4.8018e-06, 1.3091e-05, 1.1465e-05, 1.6045e-06, 9.5927e-07, 7.8582e-06,\n",
       "         1.3635e-06, 6.1935e-06, 2.6657e-05, 1.1542e-05, 2.3296e-06, 1.4469e-06,\n",
       "         3.1643e-06, 1.2262e-06, 8.7593e-06, 5.1532e-06, 1.1416e-03, 2.5706e-05,\n",
       "         1.9365e-06, 5.4821e-06, 1.3546e-05, 4.2022e-06, 1.5417e-05, 7.1198e-06,\n",
       "         1.9726e-05, 8.7810e-06, 6.0452e-06, 6.8059e-06, 1.9504e-06, 5.9176e-06,\n",
       "         2.6206e-06, 9.5943e-07, 5.2379e-06, 1.2675e-06, 7.3076e-07, 3.2446e-06,\n",
       "         1.5792e-06, 3.6888e-06], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.5.layer.0.SelfAttention.q.weight': tensor([[3.5797e-07, 4.7119e-07, 2.9197e-07,  ..., 1.5629e-06, 1.9743e-06,\n",
       "          2.7544e-06],\n",
       "         [1.9161e-07, 4.7046e-07, 2.8416e-07,  ..., 2.4215e-07, 2.1464e-06,\n",
       "          4.0059e-07],\n",
       "         [3.0745e-07, 1.0759e-06, 1.9839e-06,  ..., 1.8528e-06, 1.3969e-05,\n",
       "          3.5354e-06],\n",
       "         ...,\n",
       "         [2.4418e-07, 3.9015e-07, 4.4999e-07,  ..., 1.2621e-08, 3.4652e-06,\n",
       "          3.3943e-08],\n",
       "         [5.6702e-08, 2.3570e-07, 1.6534e-07,  ..., 2.0674e-08, 8.0081e-07,\n",
       "          7.6641e-08],\n",
       "         [3.8651e-08, 2.0923e-07, 1.6843e-07,  ..., 8.6421e-09, 7.0096e-07,\n",
       "          8.5172e-08]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.5.layer.0.SelfAttention.k.weight': tensor([[4.3009e-08, 5.8623e-08, 2.8292e-08,  ..., 4.8751e-08, 2.0248e-07,\n",
       "          4.9565e-08],\n",
       "         [7.7965e-08, 5.9252e-08, 4.0726e-08,  ..., 1.2605e-07, 3.0782e-07,\n",
       "          9.0357e-09],\n",
       "         [2.2532e-08, 3.3178e-08, 2.6996e-08,  ..., 2.4130e-08, 2.2041e-07,\n",
       "          3.0642e-08],\n",
       "         ...,\n",
       "         [7.1035e-10, 1.5995e-10, 1.2077e-10,  ..., 1.2208e-10, 2.7390e-09,\n",
       "          9.4313e-10],\n",
       "         [1.0426e-09, 1.4759e-10, 6.9965e-11,  ..., 2.0961e-10, 3.9299e-09,\n",
       "          1.5680e-09],\n",
       "         [7.9066e-10, 2.9527e-10, 1.7840e-09,  ..., 8.8186e-10, 3.7107e-09,\n",
       "          3.0869e-09]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.5.layer.0.SelfAttention.v.weight': tensor([[1.8243e-08, 1.9634e-08, 2.3561e-08,  ..., 1.2542e-08, 1.3720e-07,\n",
       "          2.0758e-08],\n",
       "         [4.1220e-08, 3.4351e-08, 4.4033e-08,  ..., 2.7181e-08, 2.6918e-07,\n",
       "          4.2102e-08],\n",
       "         [5.4229e-08, 5.0693e-09, 2.5433e-08,  ..., 2.1828e-08, 4.5534e-07,\n",
       "          4.7910e-08],\n",
       "         ...,\n",
       "         [4.8484e-09, 5.6266e-09, 1.1444e-08,  ..., 3.7311e-09, 3.5678e-08,\n",
       "          6.1367e-09],\n",
       "         [1.2806e-07, 3.1483e-08, 5.5847e-08,  ..., 3.8316e-08, 1.0445e-06,\n",
       "          1.2318e-07],\n",
       "         [1.4024e-08, 1.2931e-08, 2.9460e-08,  ..., 6.0697e-09, 4.5749e-08,\n",
       "          1.5408e-08]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.5.layer.0.SelfAttention.o.weight': tensor([[9.2611e-08, 8.1862e-08, 6.4051e-08,  ..., 3.6957e-08, 1.8866e-08,\n",
       "          2.6224e-07],\n",
       "         [2.2202e-09, 1.7038e-09, 6.1071e-09,  ..., 1.4408e-09, 3.3127e-09,\n",
       "          1.0941e-08],\n",
       "         [3.4855e-08, 2.9414e-08, 4.5339e-08,  ..., 1.5020e-08, 8.8367e-09,\n",
       "          1.1731e-07],\n",
       "         ...,\n",
       "         [9.8609e-09, 8.1036e-09, 9.0138e-09,  ..., 4.4624e-09, 4.1085e-09,\n",
       "          3.3506e-08],\n",
       "         [3.4849e-07, 2.8543e-07, 3.9259e-07,  ..., 1.3483e-07, 7.4542e-08,\n",
       "          1.1307e-06],\n",
       "         [1.7694e-08, 4.1162e-09, 1.4159e-07,  ..., 1.3841e-08, 1.4594e-08,\n",
       "          3.6992e-08]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.5.layer.0.layer_norm.weight': tensor([1.9881e-03, 2.7002e-05, 3.5114e-04, 5.3527e-04, 7.3847e-02, 3.6022e-04,\n",
       "         8.7741e-05, 4.2826e-04, 4.1037e-04, 2.3716e-04, 4.4585e-04, 1.8349e-03,\n",
       "         1.8436e-04, 1.4892e-04, 7.5277e-05, 1.5758e-04, 7.0057e-04, 2.3574e-04,\n",
       "         1.3430e-03, 1.7355e-04, 1.4011e-04, 6.7008e-04, 1.5365e-04, 2.9879e-03,\n",
       "         1.1240e-04, 7.9054e-05, 6.8195e-04, 3.6171e-04, 2.7229e-04, 1.7802e-04,\n",
       "         5.2305e-05, 7.0813e-05, 4.1174e-04, 5.6401e-04, 7.2077e-04, 3.2292e-04,\n",
       "         1.1130e-04, 1.4462e-03, 6.4731e-04, 3.5251e-04, 6.4879e-04, 3.0675e-04,\n",
       "         2.1142e-04, 1.1495e-03, 1.9148e-04, 9.6582e-05, 2.4937e-02, 2.2484e-04,\n",
       "         3.0222e-04, 4.3207e-04, 3.8622e-04, 1.5946e-04, 2.1964e-04, 1.1944e-03,\n",
       "         1.0359e-04, 6.8563e-05, 5.8561e-04, 9.3208e-04, 1.1092e-04, 1.3154e-04,\n",
       "         4.9079e-04, 1.8460e-04, 1.3189e-04, 3.9397e-04, 7.0072e-05, 2.5237e-04,\n",
       "         1.0855e-04, 4.1863e-05, 1.7411e-03, 1.3724e-04, 7.4523e-04, 4.2781e-05,\n",
       "         1.0142e-04, 4.9952e-04, 4.0612e-04, 4.7066e-04, 6.5461e-04, 1.5914e-04,\n",
       "         1.3033e-04, 4.2225e-05, 1.7907e-04, 4.2378e-04, 9.2197e-05, 5.1063e-04,\n",
       "         2.4345e-04, 1.6187e-04, 1.0831e-03, 4.9520e-04, 1.5209e-04, 7.4400e-04,\n",
       "         6.0604e-04, 2.2985e-04, 5.0900e-04, 2.1269e-04, 2.6659e-04, 5.3744e-04,\n",
       "         6.5225e-04, 9.6845e-05, 1.8283e-04, 2.3223e-04, 2.8495e-04, 3.1809e-04,\n",
       "         7.8706e-05, 1.3971e-04, 6.0534e-04, 1.1200e-04, 1.3159e-03, 1.9136e-04,\n",
       "         2.1643e-04, 2.5689e-04, 2.8196e-04, 4.7945e-04, 2.1432e-04, 2.5136e-04,\n",
       "         1.3043e-04, 4.4306e-04, 1.2536e-03, 2.5877e-04, 2.9264e-04, 3.7164e-04,\n",
       "         5.0865e-04, 4.8984e-04, 7.2199e-04, 1.6990e-04, 2.1985e-04, 1.1429e-04,\n",
       "         7.1398e-04, 1.5746e-04, 6.5761e-04, 1.9473e-04, 2.6136e-03, 2.7618e-04,\n",
       "         4.3380e-04, 1.5572e-04, 2.9429e-04, 1.5840e-04, 1.3627e-05, 2.4032e-04,\n",
       "         3.5323e-04, 7.2722e-05, 2.8656e-04, 8.9558e-05, 1.2792e-04, 3.4181e-04,\n",
       "         2.3365e-04, 1.8868e-04, 2.1951e-04, 7.3629e-05, 2.3788e-04, 2.0383e-01,\n",
       "         2.6322e-04, 2.1131e-04, 1.2622e-04, 5.9560e-04, 1.1028e-04, 9.2872e-04,\n",
       "         3.0155e-04, 2.4934e-04, 6.8995e-05, 3.2834e-03, 1.3711e-04, 4.5076e-04,\n",
       "         4.8997e-04, 4.3566e-04, 4.0491e-04, 2.8232e-04, 7.8789e-05, 1.2333e-04,\n",
       "         1.5835e-04, 2.5788e-04, 1.4786e-04, 2.0339e-03, 1.2280e-04, 5.9916e-04,\n",
       "         4.5397e-04, 1.7621e-04, 7.1434e-05, 2.5803e-04, 1.1963e-04, 7.1533e-05,\n",
       "         1.3174e-03, 1.4094e-03, 2.8853e-04, 2.1279e-04, 3.7400e-04, 3.9253e-04,\n",
       "         1.9814e-04, 1.0441e-04, 4.9095e-04, 3.4504e-04, 1.4827e-03, 1.3651e-04,\n",
       "         2.9784e-04, 3.9515e-04, 9.3051e-05, 4.6274e-04, 2.0046e-04, 2.7554e-04,\n",
       "         9.5587e-04, 1.1068e-04, 2.3580e-04, 7.0214e-04, 4.7107e-04, 1.9077e-04,\n",
       "         7.6081e-04, 4.8583e-04, 2.8376e-04, 1.8176e-04, 8.0828e-05, 2.7402e-04,\n",
       "         1.8097e-04, 2.7471e-04, 3.5181e-04, 2.3367e-03, 3.8054e-04, 7.3174e-03,\n",
       "         4.3953e-04, 9.4817e-05, 5.8232e-04, 1.3740e-04, 7.0144e-04, 5.5547e-04,\n",
       "         8.9039e-05, 2.5644e-04, 1.4307e-04, 4.0083e-04, 2.8903e-04, 1.7338e-04,\n",
       "         1.6640e-03, 7.5741e-04, 3.1305e-04, 3.0556e-04, 6.6141e-03, 2.1157e-04,\n",
       "         1.9324e-03, 9.0877e-05, 5.8355e-04, 2.8388e-05, 3.1394e-04, 1.6759e-04,\n",
       "         4.4630e-04, 4.7394e-04, 2.0822e-04, 1.0257e-03, 7.8190e-05, 1.6422e-02,\n",
       "         1.1083e-03, 3.4077e-04, 1.1398e-03, 1.7987e-04, 4.0159e-04, 4.9202e-04,\n",
       "         3.8386e-04, 6.6322e-04, 2.1193e-03, 2.2833e-04, 6.8478e-04, 4.0919e-04,\n",
       "         9.5192e-05, 4.4755e-04, 3.3643e-04, 8.3798e-04, 2.0325e-04, 4.0901e-04,\n",
       "         9.7346e-04, 4.2321e-04, 3.3889e-04, 5.0409e-04, 2.8824e-04, 1.5259e-03,\n",
       "         3.8359e-04, 1.3982e-04, 8.9973e-06, 5.7887e-04, 5.4635e-04, 6.2258e-04,\n",
       "         4.0319e-04, 3.3448e-04, 1.4348e-04, 2.3806e-03, 2.4857e-04, 3.5838e-04,\n",
       "         1.5486e-03, 2.8852e-04, 3.9371e-04, 4.5846e-04, 8.5875e-05, 4.7647e-04,\n",
       "         6.2873e-04, 3.7648e-05, 6.7206e-05, 3.8253e-05, 6.4511e-04, 1.6461e-03,\n",
       "         1.1866e-03, 4.4075e-05, 2.3310e-03, 3.1015e-04, 1.2874e-04, 1.2895e-04,\n",
       "         3.6065e-04, 9.6677e-04, 2.0014e-01, 7.4263e-05, 1.3065e-04, 3.6675e-03,\n",
       "         2.5886e-04, 5.5679e-05, 6.1601e-04, 1.6595e-03, 2.3962e-04, 5.2976e-04,\n",
       "         2.0535e-04, 1.2459e-03, 1.4429e-03, 2.7002e-04, 7.7313e-05, 2.7755e-04,\n",
       "         1.1368e-04, 1.4671e-04, 5.2568e-05, 5.1889e-04, 1.6749e-04, 3.3816e-04,\n",
       "         3.8038e-03, 4.1065e-04, 2.3487e-04, 1.8781e-03, 7.5907e-05, 2.9224e-04,\n",
       "         1.4181e-04, 2.9413e-04, 2.7194e-05, 3.3727e-04, 5.8166e-04, 2.5842e-04,\n",
       "         5.0931e-04, 2.7935e-04, 1.1657e-04, 8.7856e-05, 1.1192e-04, 1.6210e-03,\n",
       "         1.8123e-04, 7.5028e-04, 5.5783e-04, 1.4232e-04, 5.1070e-04, 1.7764e-04,\n",
       "         2.7344e-04, 2.1127e-04, 7.6999e-04, 6.9812e-04, 1.7652e-04, 2.5885e-03,\n",
       "         3.4291e-04, 9.2246e-05, 7.0026e-04, 2.7504e-04, 1.8655e-03, 1.7999e-04,\n",
       "         2.1622e-04, 7.5152e-05, 4.7966e-04, 7.6935e-05, 6.2116e-04, 5.7303e-04,\n",
       "         2.8716e-04, 2.2563e-02, 4.2745e-04, 7.4828e-05, 3.7163e-04, 3.5523e-04,\n",
       "         1.0551e-04, 1.2192e-04, 1.1270e-03, 5.3899e-04, 2.4874e-04, 1.3716e-04,\n",
       "         2.9883e-04, 3.1966e-04, 2.4397e-04, 1.3969e-03, 1.1310e-03, 5.4235e-04,\n",
       "         5.2321e-05, 2.0841e-04, 2.5012e-04, 2.5307e-04, 2.3389e-04, 2.5574e-04,\n",
       "         4.2978e-04, 1.3579e-04, 3.6897e-03, 1.0052e-03, 1.0838e-04, 1.2638e-04,\n",
       "         1.1750e-04, 3.7434e-04, 1.3995e-03, 3.0007e-04, 8.5833e-05, 1.0044e-04,\n",
       "         3.3303e-04, 7.5575e-01, 1.8715e-03, 8.5507e-05, 1.4054e-04, 1.4104e-03,\n",
       "         9.5221e-04, 2.8026e-04, 2.3102e-05, 2.9082e-04, 1.1879e-04, 3.5574e-04,\n",
       "         3.7605e-04, 6.4755e-04, 1.1473e-04, 6.5134e-04, 2.0136e-04, 5.8434e-04,\n",
       "         1.5915e-04, 1.3767e-04, 2.3793e-04, 2.3010e-04, 2.4175e-04, 4.7743e-05,\n",
       "         1.0621e-04, 1.2429e-04, 7.2597e-04, 7.6637e-05, 2.5107e-04, 1.3524e-03,\n",
       "         1.4364e-04, 3.7058e-04, 1.1213e-04, 2.6651e-04, 1.6955e-04, 4.2607e-04,\n",
       "         2.0321e-04, 3.7779e-05, 5.4756e-03, 5.2030e-04, 1.5950e-03, 1.7121e-04,\n",
       "         1.6704e-04, 4.5808e-04, 1.3922e-03, 9.1929e-04, 3.0095e-04, 3.5044e-04,\n",
       "         1.3036e-04, 1.3050e-04, 3.4816e-04, 5.7740e-04, 2.2392e-04, 5.6908e-04,\n",
       "         3.6846e-04, 1.0887e-04, 5.1193e-04, 5.4322e-04, 6.1731e-04, 8.8572e-05,\n",
       "         1.4420e-04, 4.5998e-04, 2.3137e-04, 4.1804e-04, 8.0518e-05, 1.3471e-02,\n",
       "         5.9100e-04, 4.3208e-04, 2.2647e-03, 5.6400e-04, 3.2538e-04, 5.4143e-04,\n",
       "         1.7987e-04, 4.9763e-03, 4.8261e-04, 9.2559e-04, 2.1856e-04, 9.4568e-04,\n",
       "         9.7574e-04, 9.7600e-05, 4.7930e-04, 4.6161e-04, 2.5084e-04, 2.9518e-04,\n",
       "         1.1073e-03, 1.0971e-03, 1.7861e-04, 8.6554e-05, 4.0396e-01, 5.5729e-04,\n",
       "         7.7980e-04, 9.1230e-04, 1.8447e-03, 2.4015e-04, 6.6579e-04, 3.8597e-04,\n",
       "         3.6898e-04, 5.2524e-04, 2.4190e-04, 1.0297e-03, 5.6107e-04, 2.0332e-03,\n",
       "         5.1824e-05, 1.2086e-04, 3.0247e-04, 1.8862e-04, 8.6651e-04, 2.6294e-04,\n",
       "         9.6464e-04, 2.9592e-04], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.5.layer.1.EncDecAttention.q.weight': tensor([[6.6244e-05, 6.0490e-06, 1.3813e-05,  ..., 1.8797e-05, 9.0898e-05,\n",
       "          4.5598e-05],\n",
       "         [1.7533e-05, 6.9217e-06, 1.0544e-05,  ..., 1.0848e-05, 2.5617e-04,\n",
       "          7.0189e-05],\n",
       "         [3.2580e-05, 3.8500e-06, 5.3179e-06,  ..., 4.6016e-06, 4.8981e-05,\n",
       "          1.3121e-05],\n",
       "         ...,\n",
       "         [9.0248e-05, 1.2033e-05, 9.1528e-06,  ..., 1.3964e-05, 3.6621e-05,\n",
       "          3.8348e-05],\n",
       "         [6.6637e-04, 5.7472e-05, 2.7746e-05,  ..., 1.7469e-04, 9.8214e-05,\n",
       "          1.4208e-04],\n",
       "         [1.5240e-03, 1.1285e-04, 8.0751e-06,  ..., 9.0929e-05, 1.5389e-04,\n",
       "          3.2579e-05]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.5.layer.1.EncDecAttention.k.weight': tensor([[4.5021e-07, 1.8363e-07, 1.9710e-07,  ..., 6.4527e-08, 1.2518e-06,\n",
       "          2.3813e-06],\n",
       "         [4.3103e-07, 4.9260e-07, 6.9031e-08,  ..., 2.1574e-07, 1.1959e-06,\n",
       "          1.8413e-06],\n",
       "         [2.0951e-07, 1.1687e-07, 7.2930e-08,  ..., 5.8963e-08, 7.7467e-07,\n",
       "          1.2677e-06],\n",
       "         ...,\n",
       "         [5.1338e-06, 8.0782e-07, 1.4694e-06,  ..., 3.1832e-06, 1.5208e-06,\n",
       "          9.7014e-07],\n",
       "         [1.0197e-05, 4.9503e-07, 9.4277e-07,  ..., 2.3154e-06, 1.3017e-06,\n",
       "          4.3624e-07],\n",
       "         [2.8465e-06, 1.6759e-07, 3.6226e-07,  ..., 1.3381e-06, 6.3917e-07,\n",
       "          1.8813e-07]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.5.layer.1.EncDecAttention.v.weight': tensor([[8.0921e-08, 3.1061e-09, 8.5890e-09,  ..., 5.6679e-08, 1.2408e-08,\n",
       "          1.8357e-08],\n",
       "         [4.6433e-08, 1.8795e-09, 7.5761e-09,  ..., 3.8648e-08, 1.0939e-08,\n",
       "          5.0332e-09],\n",
       "         [8.5800e-08, 2.6326e-08, 1.5039e-08,  ..., 6.3078e-08, 4.9709e-08,\n",
       "          6.4455e-07],\n",
       "         ...,\n",
       "         [3.1040e-08, 3.0290e-08, 1.5557e-08,  ..., 6.8698e-08, 1.7232e-08,\n",
       "          3.6465e-08],\n",
       "         [3.7139e-08, 4.9904e-08, 1.0167e-07,  ..., 3.5578e-07, 7.7087e-08,\n",
       "          1.1695e-07],\n",
       "         [3.3138e-08, 1.8689e-09, 1.9194e-08,  ..., 1.1622e-07, 3.0494e-08,\n",
       "          5.1734e-08]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.5.layer.1.EncDecAttention.o.weight': tensor([[8.1830e-07, 1.4830e-06, 7.3759e-08,  ..., 6.7997e-08, 4.3918e-07,\n",
       "          1.5846e-07],\n",
       "         [8.9356e-08, 1.5201e-07, 9.0261e-09,  ..., 5.2007e-08, 1.1419e-07,\n",
       "          5.3911e-08],\n",
       "         [2.4264e-08, 6.2815e-08, 9.1503e-09,  ..., 1.7950e-08, 4.9185e-08,\n",
       "          2.0772e-08],\n",
       "         ...,\n",
       "         [3.6458e-07, 7.9478e-07, 2.4958e-07,  ..., 5.6652e-08, 6.2670e-08,\n",
       "          2.1513e-08],\n",
       "         [3.2341e-05, 6.9882e-05, 1.7173e-05,  ..., 1.1291e-07, 2.5236e-06,\n",
       "          2.0781e-07],\n",
       "         [5.4791e-08, 9.6633e-08, 2.1335e-08,  ..., 7.6644e-08, 7.9121e-08,\n",
       "          3.4252e-08]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.5.layer.1.layer_norm.weight': tensor([4.7323e-03, 7.1028e-04, 2.0270e-03, 3.0236e-03, 5.4860e-01, 2.2786e-02,\n",
       "         1.5121e-03, 1.9751e-02, 5.2650e-03, 5.9511e-04, 3.5982e-03, 4.7920e-03,\n",
       "         7.6728e-04, 2.1811e-03, 1.7011e-03, 4.3680e-03, 1.7461e-02, 6.2142e-03,\n",
       "         1.6354e-02, 3.3852e-03, 1.8032e-03, 9.5859e-03, 1.5028e-03, 5.4802e-02,\n",
       "         2.1680e-03, 6.9666e-03, 8.0466e-03, 5.4412e-03, 1.4976e-02, 9.8327e-04,\n",
       "         2.4850e-03, 2.4851e-03, 3.8399e-03, 2.1561e-03, 1.9748e-02, 3.8803e-03,\n",
       "         6.0603e-03, 5.3883e-03, 1.2201e-03, 7.3886e-04, 8.7919e-04, 1.3843e-02,\n",
       "         7.7103e-04, 4.9965e-03, 2.3617e-02, 1.3277e-03, 4.3792e-02, 1.6979e-03,\n",
       "         1.7452e-03, 2.1018e-03, 4.1548e-03, 1.9582e-02, 1.4218e-02, 2.8381e-02,\n",
       "         1.3370e-02, 9.3993e-03, 9.6653e-03, 2.3006e-03, 2.5338e-03, 1.0182e-03,\n",
       "         8.3816e-03, 7.5472e-03, 3.7859e-04, 1.5813e-02, 1.3360e-02, 7.5825e-04,\n",
       "         1.7143e-03, 1.4590e-03, 3.4727e-02, 5.3444e-04, 1.2514e-02, 7.0487e-03,\n",
       "         2.3247e-03, 1.0996e-02, 5.3325e-03, 5.3360e-03, 5.5864e-03, 1.5745e-03,\n",
       "         6.2242e-03, 1.9315e-02, 1.9483e-03, 1.2539e-02, 3.6133e-03, 1.2553e-03,\n",
       "         7.5181e-03, 9.0495e-03, 4.1719e-03, 2.8104e-02, 2.2857e-03, 1.0810e-02,\n",
       "         9.4275e-03, 7.8684e-03, 4.0608e-03, 5.1135e-03, 3.2883e-03, 1.3092e-02,\n",
       "         8.4501e-03, 6.5436e-03, 5.8743e-03, 3.5837e-03, 7.7983e-03, 3.5213e-03,\n",
       "         1.0239e-03, 2.4527e-03, 2.3349e-03, 3.6039e-03, 6.1794e-03, 1.9080e-02,\n",
       "         1.4722e-03, 1.0094e-02, 2.9306e-03, 4.6068e-03, 4.3294e-03, 6.8408e-03,\n",
       "         4.3306e-02, 1.2838e-02, 1.1228e-03, 1.2933e-03, 5.2154e-03, 4.1620e-03,\n",
       "         8.7376e-03, 1.3525e-03, 1.0882e-02, 9.8317e-03, 5.9451e-03, 2.2989e-03,\n",
       "         1.7882e-02, 9.2373e-03, 4.2720e-04, 9.5602e-03, 2.5452e-02, 1.9928e-03,\n",
       "         2.4048e-03, 9.3920e-04, 2.6548e-03, 3.0346e-03, 3.3942e-04, 1.6925e-02,\n",
       "         2.7965e-02, 8.8968e-04, 2.5314e-03, 1.3949e-02, 5.1068e-04, 1.8198e-03,\n",
       "         4.6347e-03, 2.5567e-03, 9.5188e-03, 5.6530e-03, 1.0988e-03, 7.4630e-01,\n",
       "         2.3671e-03, 1.8005e-02, 2.0372e-03, 1.1773e-02, 2.2573e-03, 1.9285e-03,\n",
       "         2.1357e-03, 1.7574e-03, 5.8274e-03, 4.1169e-02, 1.6078e-02, 3.8144e-03,\n",
       "         2.6763e-03, 1.6766e-02, 6.0474e-03, 1.7697e-03, 1.3055e-03, 1.3765e-02,\n",
       "         8.1562e-04, 3.9818e-03, 1.0623e-03, 1.5436e-02, 2.0560e-02, 7.0766e-02,\n",
       "         1.3195e-02, 7.0251e-04, 1.9870e-03, 6.3291e-04, 3.5744e-03, 8.3447e-04,\n",
       "         5.4285e-03, 1.5305e-03, 3.5999e-04, 3.4194e-03, 8.9064e-03, 7.1684e-03,\n",
       "         2.4536e-02, 7.1636e-03, 4.1719e-02, 6.6391e-04, 3.5681e-02, 1.5700e-02,\n",
       "         2.6803e-03, 1.5415e-03, 6.0806e-03, 3.6319e-03, 4.0420e-03, 1.0088e-03,\n",
       "         3.3633e-02, 6.2881e-04, 6.4402e-03, 7.0682e-03, 2.7843e-03, 8.3058e-04,\n",
       "         1.6635e-03, 2.7699e-03, 1.0869e-03, 2.2835e-03, 4.2312e-03, 6.2780e-03,\n",
       "         2.4726e-03, 2.0767e-03, 1.2143e-03, 2.2235e-02, 2.5140e-03, 3.4246e-02,\n",
       "         7.5570e-04, 2.3362e-03, 1.6412e-02, 2.4036e-03, 8.0794e-03, 4.6831e-03,\n",
       "         9.4731e-03, 3.3429e-03, 2.1083e-02, 8.7226e-04, 1.0247e-02, 1.4046e-03,\n",
       "         9.2776e-03, 1.4878e-03, 5.9696e-03, 1.1269e-03, 1.8690e-02, 5.9532e-04,\n",
       "         4.1072e-02, 2.5268e-03, 9.9882e-03, 1.6894e-03, 2.5522e-03, 1.0582e-02,\n",
       "         3.2659e-02, 4.1749e-03, 8.7043e-04, 1.6592e-02, 3.8995e-04, 3.0770e-01,\n",
       "         3.2075e-03, 2.5975e-03, 1.1950e-02, 1.4314e-02, 8.6388e-03, 1.6573e-03,\n",
       "         3.0579e-03, 4.5727e-03, 7.3607e-03, 2.6398e-03, 1.2433e-03, 3.4486e-02,\n",
       "         3.6580e-03, 8.8644e-04, 8.0130e-03, 1.2444e-02, 2.6905e-03, 9.5636e-04,\n",
       "         5.1890e-03, 2.0515e-02, 5.3181e-04, 4.4595e-03, 1.9047e-03, 2.4504e-03,\n",
       "         2.1614e-02, 8.9346e-03, 1.8124e-03, 8.3865e-03, 2.3456e-03, 1.6918e-03,\n",
       "         2.6864e-03, 1.0773e-03, 2.7963e-03, 7.1566e-03, 1.3538e-03, 4.9126e-02,\n",
       "         6.9324e-03, 3.5840e-03, 1.4002e-03, 5.0499e-03, 1.1188e-03, 2.4522e-03,\n",
       "         1.5783e-02, 1.1747e-02, 5.6523e-03, 2.2626e-03, 3.6421e-03, 2.0153e-03,\n",
       "         1.4662e-02, 1.7810e-03, 5.4570e-03, 5.2993e-03, 5.8395e-03, 5.3664e-04,\n",
       "         4.4159e-04, 1.4140e-02, 2.4876e-01, 8.8208e-04, 1.8997e-02, 4.1223e-03,\n",
       "         7.5365e-04, 5.3507e-02, 1.2643e-02, 5.8513e-03, 1.6213e-03, 1.5072e-02,\n",
       "         5.2021e-03, 1.0830e-02, 1.1262e-02, 7.0079e-02, 1.5317e-03, 5.0322e-03,\n",
       "         5.7613e-03, 3.9939e-03, 7.0183e-03, 2.1495e-03, 5.3026e-04, 9.6413e-03,\n",
       "         7.7377e-03, 2.2917e-02, 1.5732e-03, 6.1370e-03, 7.9712e-03, 2.4061e-03,\n",
       "         1.2640e-02, 1.6930e-03, 2.2290e-03, 3.8368e-03, 9.1948e-03, 2.7838e-03,\n",
       "         2.6879e-02, 2.3457e-03, 5.1340e-03, 7.9008e-04, 1.3220e-03, 5.0332e-03,\n",
       "         3.3632e-03, 1.4949e-02, 2.3347e-03, 3.9710e-04, 2.3618e-03, 3.8416e-03,\n",
       "         1.0874e-03, 1.1699e-03, 3.0055e-03, 1.3547e-03, 6.3327e-03, 5.8314e-03,\n",
       "         2.0539e-03, 1.3465e-03, 1.2620e-02, 4.7986e-03, 1.3762e-03, 2.6717e-03,\n",
       "         1.0975e-03, 3.1165e-03, 6.2050e-03, 1.0061e-03, 2.3481e-03, 6.4831e-03,\n",
       "         1.5896e-02, 1.3102e+00, 1.4774e-02, 1.2761e-03, 7.2282e-03, 4.6847e-03,\n",
       "         5.2428e-04, 2.7617e-02, 3.0247e-03, 5.8506e-03, 1.3934e-02, 4.2913e-03,\n",
       "         6.2906e-03, 1.4990e-02, 1.2439e-03, 9.7124e-03, 1.0340e-02, 4.6939e-04,\n",
       "         1.5862e-03, 1.2392e-03, 9.5024e-03, 1.4010e-03, 3.9643e-02, 1.2415e-02,\n",
       "         2.7328e-03, 4.7125e-03, 4.4295e-02, 3.9300e-02, 1.1194e-03, 1.0955e-02,\n",
       "         4.0999e-03, 1.1221e-02, 1.3338e-03, 1.1558e-02, 1.2758e-02, 3.6170e-02,\n",
       "         1.4461e-02, 4.4121e-01, 5.0759e-03, 1.1460e-03, 4.1920e-03, 9.0967e-03,\n",
       "         1.3261e-02, 9.6024e-03, 1.4410e-03, 6.5712e-04, 9.9387e-04, 1.4147e-03,\n",
       "         3.7104e-02, 3.0560e-03, 2.8794e-03, 1.0024e-02, 1.8458e-03, 4.0614e-03,\n",
       "         2.8881e-04, 4.3171e-03, 5.4073e-03, 4.1157e-04, 6.5935e-04, 2.9383e-03,\n",
       "         3.6584e-03, 2.2951e-03, 4.4959e-03, 6.9222e-03, 1.1065e-02, 1.3500e-02,\n",
       "         3.6134e-03, 7.6764e-03, 8.7809e-03, 9.7898e-04, 3.0328e-03, 1.9183e-03,\n",
       "         1.2087e-03, 3.9247e-04, 1.8070e-02, 5.0867e-03, 5.0007e-03, 1.2662e-03,\n",
       "         1.5545e-03, 7.8772e-03, 2.0431e-02, 1.0991e-02, 1.2758e-02, 4.9154e-03,\n",
       "         1.3277e-03, 6.9815e-04, 2.1484e-03, 3.4515e-02, 9.7425e-04, 7.8981e-03,\n",
       "         1.9660e-03, 1.8356e-03, 9.0598e-03, 8.9711e-03, 7.7912e-03, 6.2582e-04,\n",
       "         3.0067e-03, 1.1903e-02, 3.7753e-03, 1.7366e-02, 6.5793e-03, 3.3940e-02,\n",
       "         3.0984e-03, 2.3011e-02, 8.1697e-03, 1.4054e-03, 1.0847e-02, 4.3843e-02,\n",
       "         8.8982e-03, 1.7144e-02, 1.5067e-02, 1.3085e-02, 2.6513e-03, 4.0060e-03,\n",
       "         9.5563e-04, 5.4455e-03, 2.5349e-02, 5.3542e-03, 5.3407e-03, 5.5944e-03,\n",
       "         1.4577e-03, 3.9104e-03, 1.4906e-03, 4.7301e-03, 3.5800e-01, 6.0546e-02,\n",
       "         9.7717e-04, 1.6777e-02, 3.1018e-02, 5.1007e-03, 4.7881e-03, 3.9239e-03,\n",
       "         5.3522e-03, 3.5133e-03, 1.3332e-03, 3.2772e-02, 2.6121e-03, 4.7361e-03,\n",
       "         1.0262e-03, 1.5440e-03, 1.1255e-03, 7.4833e-03, 2.2469e-03, 1.3006e-03,\n",
       "         3.4748e-03, 2.1489e-03], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.5.layer.2.DenseReluDense.wi.weight': tensor([[1.1226e-09, 5.2477e-10, 1.0281e-10,  ..., 4.2932e-10, 3.0656e-09,\n",
       "          2.0712e-09],\n",
       "         [0.0000e+00, 0.0000e+00, 0.0000e+00,  ..., 0.0000e+00, 0.0000e+00,\n",
       "          0.0000e+00],\n",
       "         [3.2458e-08, 1.7829e-08, 7.6025e-09,  ..., 6.7604e-08, 2.0054e-08,\n",
       "          1.1890e-08],\n",
       "         ...,\n",
       "         [1.5159e-08, 1.5167e-08, 1.2517e-07,  ..., 1.9040e-08, 7.5813e-07,\n",
       "          1.9629e-07],\n",
       "         [1.5296e-13, 2.6539e-12, 2.3224e-13,  ..., 4.6530e-13, 9.4318e-14,\n",
       "          1.3034e-15],\n",
       "         [1.1285e-07, 2.8261e-07, 1.3145e-07,  ..., 1.5129e-06, 1.2577e-07,\n",
       "          4.9116e-06]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.5.layer.2.DenseReluDense.wo.weight': tensor([[1.8778e-15, 0.0000e+00, 5.6870e-07,  ..., 4.9691e-07, 3.8811e-15,\n",
       "          3.6316e-11],\n",
       "         [2.4544e-08, 0.0000e+00, 4.3594e-07,  ..., 9.1494e-08, 7.4828e-14,\n",
       "          1.3874e-07],\n",
       "         [4.9013e-08, 0.0000e+00, 2.7452e-08,  ..., 3.2549e-07, 8.1184e-15,\n",
       "          2.9058e-08],\n",
       "         ...,\n",
       "         [5.1003e-08, 0.0000e+00, 1.8058e-06,  ..., 8.1521e-08, 1.1960e-18,\n",
       "          5.3857e-08],\n",
       "         [8.6731e-12, 0.0000e+00, 8.3282e-08,  ..., 5.8010e-09, 4.2121e-15,\n",
       "          1.4650e-10],\n",
       "         [1.3954e-12, 0.0000e+00, 1.7472e-07,  ..., 1.2592e-07, 3.6043e-14,\n",
       "          4.5235e-08]], device='cuda:0', requires_grad=True),\n",
       " 'decoder.block.5.layer.2.layer_norm.weight': tensor([2.6924e-05, 6.7171e-07, 2.2364e-05, 2.7678e-06, 4.0129e-03, 3.1913e-05,\n",
       "         4.3872e-06, 1.3844e-05, 1.1786e-06, 1.0716e-05, 1.2065e-05, 2.1426e-06,\n",
       "         1.0828e-05, 9.1889e-06, 3.6108e-07, 7.7207e-06, 1.8790e-05, 3.4281e-06,\n",
       "         2.0470e-06, 9.0782e-06, 2.0684e-05, 1.2429e-04, 1.9773e-06, 7.5370e-05,\n",
       "         5.9171e-06, 1.5879e-06, 1.9077e-06, 1.6657e-06, 6.3878e-05, 9.3217e-07,\n",
       "         1.1972e-05, 7.6563e-06, 1.0043e-04, 8.8703e-06, 8.8765e-06, 9.3942e-06,\n",
       "         3.3696e-05, 5.3685e-06, 1.0796e-05, 2.9535e-05, 1.7246e-06, 7.7284e-06,\n",
       "         7.1638e-07, 6.0510e-06, 1.2704e-05, 1.7056e-05, 1.3944e-04, 3.9453e-06,\n",
       "         2.5827e-06, 2.9821e-06, 7.3458e-06, 4.7753e-06, 4.3086e-07, 2.2062e-06,\n",
       "         4.4598e-06, 1.5935e-05, 3.9836e-06, 1.5897e-05, 8.7492e-06, 2.8686e-06,\n",
       "         2.0412e-05, 4.9671e-05, 2.5277e-05, 4.6353e-06, 1.3118e-06, 4.7206e-06,\n",
       "         2.8072e-06, 2.2148e-06, 1.2343e-05, 1.4522e-06, 2.0299e-05, 2.0277e-06,\n",
       "         2.3804e-06, 4.2220e-05, 1.1970e-05, 4.2602e-06, 3.0967e-06, 4.3293e-06,\n",
       "         2.4929e-06, 7.7499e-07, 1.0851e-05, 1.2180e-05, 1.2421e-06, 7.0736e-07,\n",
       "         9.0649e-06, 5.8499e-06, 3.6956e-05, 3.3360e-05, 4.9061e-06, 5.5404e-06,\n",
       "         2.5098e-06, 7.9510e-06, 2.6383e-05, 1.1791e-06, 7.2873e-06, 4.3830e-06,\n",
       "         5.2265e-06, 2.7551e-05, 5.5271e-06, 3.1196e-06, 3.4784e-05, 8.6927e-05,\n",
       "         4.6533e-06, 6.7999e-07, 7.5285e-06, 1.0574e-05, 3.8426e-06, 3.9790e-06,\n",
       "         1.0482e-06, 3.3427e-06, 2.0827e-06, 1.0279e-06, 8.5395e-06, 1.3759e-05,\n",
       "         3.2695e-05, 1.2474e-05, 4.6819e-06, 2.6966e-06, 3.1644e-05, 1.8906e-05,\n",
       "         1.2260e-06, 5.6943e-06, 5.3073e-05, 3.6376e-06, 2.1288e-05, 2.4411e-05,\n",
       "         5.9836e-06, 1.1030e-05, 9.9013e-06, 4.1007e-06, 5.1952e-06, 1.6124e-06,\n",
       "         6.1727e-06, 3.8216e-06, 6.9586e-06, 4.5539e-06, 8.1708e-06, 2.0484e-06,\n",
       "         8.6810e-06, 1.5275e-05, 1.0311e-05, 2.8442e-06, 3.2354e-06, 6.2034e-06,\n",
       "         1.3931e-05, 1.7692e-06, 4.5222e-07, 2.8293e-06, 4.0847e-06, 1.1047e-03,\n",
       "         3.7130e-06, 3.5499e-06, 2.1840e-06, 3.6277e-06, 1.3680e-06, 3.0902e-05,\n",
       "         1.2192e-05, 1.2017e-06, 4.4396e-06, 1.6361e-04, 1.5357e-05, 3.2010e-06,\n",
       "         7.4974e-06, 1.9158e-05, 9.4785e-06, 1.4363e-05, 7.4983e-07, 4.6556e-07,\n",
       "         3.6032e-06, 1.8933e-05, 4.0617e-06, 1.4787e-05, 1.4633e-06, 3.2844e-05,\n",
       "         1.7694e-05, 1.2578e-06, 1.8593e-05, 6.8267e-07, 6.6554e-06, 3.4408e-05,\n",
       "         8.6409e-06, 7.4736e-06, 3.9609e-06, 5.2974e-06, 4.4095e-05, 1.7046e-05,\n",
       "         1.3817e-04, 8.9123e-06, 7.7778e-06, 2.5327e-06, 6.4808e-06, 8.2808e-07,\n",
       "         1.7449e-06, 1.7574e-06, 1.6044e-05, 1.5407e-05, 1.4693e-06, 1.0712e-06,\n",
       "         9.0674e-06, 2.5447e-06, 1.0503e-06, 8.2631e-07, 7.6598e-06, 8.3122e-07,\n",
       "         5.8156e-06, 9.2152e-06, 6.5784e-06, 1.7828e-06, 1.2406e-06, 7.4611e-06,\n",
       "         4.5149e-06, 2.1025e-06, 3.8118e-06, 1.2717e-05, 4.2789e-06, 1.5211e-04,\n",
       "         7.7584e-06, 5.3651e-07, 7.4960e-07, 2.3026e-05, 1.6794e-05, 1.0789e-05,\n",
       "         7.1081e-07, 3.7728e-06, 2.9613e-06, 4.5781e-06, 3.7632e-06, 3.0093e-06,\n",
       "         2.4788e-06, 7.1086e-06, 4.0402e-05, 3.4980e-06, 1.9199e-05, 7.4185e-06,\n",
       "         1.3078e-05, 5.4393e-06, 2.5533e-05, 6.1946e-07, 1.2140e-06, 1.2828e-05,\n",
       "         2.6282e-06, 2.5145e-06, 3.1704e-06, 2.3067e-06, 7.4517e-07, 1.0972e-04,\n",
       "         5.0272e-06, 7.8061e-06, 6.0235e-06, 1.0284e-05, 1.6536e-05, 2.5166e-06,\n",
       "         2.0704e-06, 3.4941e-05, 7.5574e-06, 2.4901e-06, 3.6432e-06, 3.6525e-06,\n",
       "         1.8551e-06, 7.6242e-07, 6.1508e-07, 9.5465e-06, 3.3820e-06, 7.8885e-06,\n",
       "         3.4156e-06, 3.4551e-06, 3.1127e-06, 3.2170e-06, 2.1773e-05, 6.2849e-07,\n",
       "         5.1082e-05, 1.5512e-06, 6.4463e-06, 6.3517e-06, 1.7680e-06, 2.1672e-06,\n",
       "         1.4705e-05, 4.4629e-06, 3.0606e-06, 1.7445e-05, 5.4436e-07, 8.4504e-06,\n",
       "         7.2251e-05, 7.7630e-06, 5.5184e-06, 4.4493e-06, 7.4775e-07, 8.7627e-05,\n",
       "         1.3199e-05, 1.0884e-06, 1.1528e-06, 2.8570e-06, 1.1623e-05, 7.8611e-06,\n",
       "         9.4555e-07, 2.1417e-06, 1.0163e-05, 5.6481e-06, 9.5360e-06, 2.1958e-06,\n",
       "         3.9027e-06, 2.1650e-06, 1.2418e-03, 2.2809e-06, 3.2322e-06, 7.8200e-05,\n",
       "         1.1770e-05, 2.3731e-06, 3.8143e-06, 1.0716e-04, 7.9261e-06, 8.7947e-06,\n",
       "         2.9321e-06, 2.7887e-05, 8.4963e-06, 2.0662e-04, 4.0043e-06, 6.3916e-05,\n",
       "         6.3591e-06, 1.9456e-06, 1.4046e-06, 1.0212e-04, 1.4270e-05, 1.4532e-05,\n",
       "         2.6084e-05, 1.1850e-05, 1.9478e-05, 3.8697e-05, 2.4648e-06, 4.4673e-06,\n",
       "         5.3905e-06, 6.3104e-06, 2.2513e-06, 4.3301e-06, 2.9659e-06, 1.7120e-06,\n",
       "         5.6068e-06, 7.9600e-06, 1.4862e-05, 7.3525e-06, 7.3153e-07, 1.3248e-05,\n",
       "         4.7354e-06, 2.2399e-06, 1.0694e-06, 1.7232e-05, 5.3349e-06, 3.6357e-06,\n",
       "         8.4868e-06, 5.9548e-06, 5.2829e-05, 2.5738e-06, 5.2156e-06, 2.4634e-06,\n",
       "         1.4977e-05, 1.3292e-06, 8.2641e-06, 6.6086e-06, 8.1367e-07, 1.4514e-05,\n",
       "         3.4389e-06, 8.0078e-06, 2.0157e-05, 6.8686e-07, 1.7999e-05, 5.4430e-06,\n",
       "         1.1988e-05, 3.8970e-03, 1.4384e-06, 3.8735e-06, 7.8298e-07, 1.6153e-05,\n",
       "         2.0146e-06, 8.3900e-06, 2.0109e-06, 6.8382e-07, 1.6947e-05, 1.0662e-05,\n",
       "         3.9676e-06, 1.8196e-05, 1.2068e-05, 2.3623e-05, 5.9996e-06, 1.1117e-06,\n",
       "         5.0457e-06, 1.3006e-05, 4.8549e-06, 1.3558e-05, 8.3442e-06, 6.0711e-05,\n",
       "         3.1948e-06, 7.5780e-06, 1.2532e-06, 2.3711e-05, 7.8870e-06, 2.9859e-05,\n",
       "         2.0596e-06, 8.4968e-07, 2.0014e-05, 2.6491e-05, 2.2351e-05, 2.2912e-05,\n",
       "         1.3434e-06, 9.2850e-04, 2.7212e-05, 1.8691e-06, 1.7447e-06, 3.5995e-06,\n",
       "         7.8038e-05, 1.0630e-04, 8.5001e-07, 6.7976e-07, 2.9706e-07, 2.0557e-06,\n",
       "         8.3498e-06, 8.8947e-06, 1.8963e-06, 1.0670e-06, 2.0808e-06, 2.7705e-06,\n",
       "         3.2461e-06, 4.0488e-06, 1.7192e-06, 1.4681e-06, 8.4132e-06, 2.5755e-06,\n",
       "         1.6615e-05, 9.8016e-06, 4.4893e-06, 1.0524e-06, 7.0508e-06, 1.7199e-06,\n",
       "         2.1334e-05, 2.6211e-06, 3.9312e-06, 8.0671e-07, 8.3107e-06, 3.9250e-06,\n",
       "         7.2775e-06, 1.4677e-06, 1.3491e-05, 1.1833e-05, 1.4674e-06, 9.3649e-06,\n",
       "         1.8024e-05, 2.6721e-05, 5.7057e-05, 3.2185e-06, 2.6070e-05, 8.0369e-05,\n",
       "         2.6329e-06, 3.2956e-06, 9.6609e-07, 4.2989e-06, 2.1664e-06, 3.8801e-06,\n",
       "         3.7014e-06, 4.9506e-06, 3.3718e-06, 9.3014e-06, 2.9238e-06, 5.8151e-07,\n",
       "         1.1888e-05, 8.4887e-06, 7.2881e-06, 4.5943e-06, 1.3724e-05, 1.7610e-05,\n",
       "         1.2423e-06, 1.2028e-05, 1.5788e-05, 9.1655e-05, 1.2957e-05, 3.8435e-04,\n",
       "         2.3276e-05, 1.2459e-05, 1.3467e-05, 6.9705e-06, 4.8728e-06, 2.9230e-05,\n",
       "         1.5757e-06, 4.6310e-06, 2.4835e-05, 9.4095e-06, 2.6044e-06, 9.6171e-06,\n",
       "         1.2623e-05, 9.1587e-06, 1.3390e-06, 3.3327e-06, 1.6727e-03, 4.5015e-04,\n",
       "         5.6065e-06, 4.1017e-05, 4.1477e-05, 4.1889e-06, 1.1907e-05, 4.4449e-06,\n",
       "         1.9539e-05, 7.8772e-06, 1.4838e-06, 4.5483e-06, 5.1621e-06, 1.4154e-05,\n",
       "         1.0273e-06, 9.9040e-06, 2.9902e-06, 1.8305e-05, 4.8934e-05, 2.5633e-06,\n",
       "         4.3457e-05, 1.5814e-06], device='cuda:0', requires_grad=True),\n",
       " 'decoder.final_layer_norm.weight': tensor([8.7446e-03, 9.2035e-04, 1.1446e-02, 1.6672e-03, 2.2211e+00, 1.7556e-02,\n",
       "         2.0011e-03, 3.0889e-03, 9.5050e-04, 1.4121e-02, 7.3983e-03, 4.1641e-03,\n",
       "         6.9554e-03, 1.6042e-02, 1.4234e-04, 1.8375e-02, 3.9902e-02, 1.6988e-03,\n",
       "         3.0126e-03, 9.9049e-03, 3.5503e-02, 7.1576e-02, 3.6314e-03, 4.3267e-04,\n",
       "         9.0057e-03, 3.8185e-03, 1.3631e-02, 2.0933e-04, 1.8372e-02, 4.3599e-03,\n",
       "         2.6210e-02, 2.3146e-03, 8.9355e-03, 1.2288e-02, 9.7331e-03, 4.0214e-03,\n",
       "         4.1814e-02, 1.4606e-02, 4.6693e-02, 2.9822e-03, 1.9272e-02, 1.2593e-02,\n",
       "         2.9614e-04, 1.6745e-02, 8.5817e-03, 5.2273e-03, 4.8993e-03, 1.1879e-03,\n",
       "         1.3897e-02, 1.1063e-02, 8.6638e-03, 1.0448e-03, 6.9293e-04, 4.5135e-03,\n",
       "         2.0904e-03, 1.4314e-03, 1.0213e-03, 6.8548e-03, 1.5074e-02, 1.3111e-03,\n",
       "         1.7549e-02, 3.3331e-03, 7.6702e-03, 9.6308e-03, 6.8571e-03, 4.2188e-03,\n",
       "         2.3100e-03, 2.4429e-02, 5.1962e-05, 1.6156e-03, 2.1902e-02, 5.5043e-03,\n",
       "         9.0497e-04, 9.8677e-02, 2.7508e-02, 3.8548e-03, 1.4407e-02, 8.3761e-04,\n",
       "         3.1887e-03, 5.4079e-04, 5.4414e-04, 5.5739e-03, 1.3590e-03, 6.4642e-03,\n",
       "         3.4173e-03, 1.8705e-03, 2.5405e-02, 1.4300e-03, 8.5898e-03, 7.0311e-04,\n",
       "         8.1000e-03, 7.9822e-03, 3.9428e-02, 1.4177e-03, 1.6379e-03, 2.5841e-03,\n",
       "         1.8134e-03, 3.3450e-02, 2.6558e-01, 1.2573e-02, 4.5827e-02, 3.7046e-02,\n",
       "         1.1470e-02, 8.3334e-04, 4.3319e-02, 1.6722e-02, 1.3067e-01, 7.1619e-03,\n",
       "         7.7276e-04, 1.0720e-02, 2.3618e-02, 5.5445e-04, 1.0629e-02, 6.5005e-03,\n",
       "         1.3107e-02, 8.3399e-03, 3.0235e-02, 6.7088e-03, 2.4107e-02, 1.7493e-02,\n",
       "         2.2898e-03, 3.5147e-03, 2.1824e-02, 1.6627e-02, 3.8499e-02, 2.5657e-03,\n",
       "         9.9869e-03, 1.1460e-02, 1.4100e+00, 5.2212e-03, 4.9205e-03, 7.8291e-03,\n",
       "         2.0239e-03, 4.1890e-03, 2.3248e-03, 1.5216e-02, 6.3385e-03, 2.2725e-03,\n",
       "         2.4461e-02, 7.0275e-02, 1.6320e-02, 2.7557e-03, 3.4902e-03, 1.0925e-02,\n",
       "         3.8817e-02, 1.9299e-03, 3.4945e-02, 5.4845e-03, 1.0026e-03, 4.2054e-04,\n",
       "         3.1723e-02, 5.5698e-03, 1.3930e-03, 3.3677e-03, 1.2447e-03, 3.7294e-02,\n",
       "         1.0718e-01, 1.2628e-03, 2.4040e-02, 1.5456e-05, 5.4135e-03, 5.2626e-03,\n",
       "         1.0478e-02, 4.0250e-02, 2.0593e-02, 1.3805e-02, 2.3707e-04, 3.8152e-04,\n",
       "         5.4470e-03, 1.8171e-02, 1.1032e-03, 4.5606e-02, 2.1122e-02, 2.7829e-02,\n",
       "         1.0769e-02, 1.9189e-03, 2.6412e-03, 3.3382e-04, 2.4324e-02, 2.3499e-03,\n",
       "         1.5589e-02, 1.0424e-02, 3.8743e-01, 9.8356e-03, 7.7533e-03, 1.4238e-02,\n",
       "         2.7262e-03, 1.6301e-02, 2.2447e-02, 1.1194e-03, 2.9163e-05, 3.9624e-04,\n",
       "         8.0521e-03, 2.8615e-04, 3.4202e-03, 4.2472e-03, 4.0253e-03, 8.6709e-04,\n",
       "         1.0453e-02, 3.4503e-03, 4.3846e-03, 5.0108e-03, 7.1635e-03, 2.0681e-03,\n",
       "         1.8335e-02, 8.1409e-03, 4.5349e-02, 2.8133e-03, 1.5649e-02, 2.3068e-02,\n",
       "         1.0793e-02, 2.9345e-03, 2.0814e-03, 2.0897e-01, 3.4141e-02, 1.1457e-01,\n",
       "         2.3430e-02, 2.5587e-03, 3.4232e-04, 1.5828e-02, 1.6926e-01, 1.2916e-02,\n",
       "         4.6098e-04, 9.5131e-02, 2.0097e-03, 7.4983e-03, 5.6763e-04, 6.9668e-03,\n",
       "         9.7499e-04, 6.8256e-03, 2.3059e-02, 9.5998e-03, 6.0306e-04, 1.2885e-02,\n",
       "         3.2443e-03, 6.8214e-03, 4.9698e-03, 8.5992e-04, 9.1385e-04, 3.0818e-03,\n",
       "         1.5508e-03, 2.6349e-03, 1.4187e-03, 3.3776e-03, 1.3252e-04, 1.8747e-03,\n",
       "         3.6556e-03, 1.1126e-02, 4.5935e-03, 3.1935e-03, 4.7961e-02, 1.9154e-02,\n",
       "         1.0011e-03, 5.4860e-02, 4.6315e-02, 5.2181e-03, 5.1175e-04, 8.6196e-03,\n",
       "         5.8956e-04, 1.8377e-03, 5.3478e-03, 5.8750e-02, 1.8934e-02, 7.2833e-05,\n",
       "         1.3947e-03, 1.1835e-02, 3.9721e-03, 2.1776e-03, 7.6283e-03, 2.8947e-03,\n",
       "         1.1080e-02, 2.6416e-03, 2.4422e-03, 1.1293e-04, 3.9281e-02, 4.5979e-04,\n",
       "         1.6592e-02, 1.0464e-02, 1.0480e-03, 1.5351e-03, 2.1771e-03, 2.1349e-03,\n",
       "         5.2832e-03, 9.5057e-03, 1.4190e-02, 2.5009e-03, 3.9626e-03, 3.7540e-02,\n",
       "         1.5502e-02, 1.0801e-03, 3.9487e-04, 2.7792e-03, 2.5998e-02, 2.0471e-02,\n",
       "         4.0350e-05, 1.3337e-03, 3.5508e-03, 1.3001e-02, 5.7264e-02, 2.2401e-04,\n",
       "         8.1553e-03, 2.4713e-03, 1.0451e+00, 1.1552e-02, 5.9188e-03, 2.5211e-02,\n",
       "         9.0805e-03, 5.1109e-04, 1.2046e-03, 6.2079e-03, 8.5478e-03, 1.4163e-02,\n",
       "         2.1017e-04, 3.6535e-03, 7.9527e-04, 3.9439e-02, 7.7139e-03, 2.0291e-02,\n",
       "         8.2404e-04, 2.1476e-03, 3.0984e-03, 8.5021e-03, 1.1291e-02, 2.7661e-03,\n",
       "         2.4848e-05, 5.4636e-02, 3.8599e-04, 4.9498e-02, 4.0052e-03, 5.1003e-04,\n",
       "         7.6284e-03, 1.1210e-02, 2.1751e-03, 1.8797e-02, 1.0836e-02, 2.2875e-03,\n",
       "         4.0930e-04, 6.9401e-04, 2.0236e-03, 2.4897e-02, 5.6886e-04, 2.5407e-02,\n",
       "         7.6251e-03, 9.1259e-04, 7.2684e-03, 1.1959e-03, 9.4058e-03, 1.6670e-02,\n",
       "         1.0384e-02, 4.8619e-03, 6.2680e-02, 1.8198e-02, 5.6998e-03, 1.1458e-02,\n",
       "         2.2393e-02, 1.6795e-04, 3.9828e-03, 2.8803e-02, 1.3032e-02, 6.8108e-03,\n",
       "         3.2484e-03, 2.6652e-03, 4.8082e-02, 3.8863e-03, 4.8210e-03, 1.6691e-03,\n",
       "         1.7601e-01, 2.5310e-02, 7.5452e-03, 4.6823e-03, 1.6042e-02, 7.6691e-04,\n",
       "         1.6067e-03, 1.0443e-03, 5.9513e-04, 3.4198e-02, 1.7370e-01, 1.5471e-02,\n",
       "         1.5668e-02, 3.2838e-03, 2.0559e-02, 1.8206e-04, 1.3454e-03, 2.3873e-03,\n",
       "         5.1833e-03, 1.6383e-02, 1.8162e-03, 4.1609e-03, 4.5749e-03, 8.4669e-02,\n",
       "         1.2573e-02, 4.6494e-02, 2.0609e-03, 4.5540e-03, 3.5992e-03, 3.6335e-03,\n",
       "         1.1380e-03, 3.5952e-03, 6.7757e-03, 5.3893e-03, 1.6454e-04, 8.4410e-04,\n",
       "         2.2330e-02, 3.1416e-01, 3.9180e-02, 6.2517e-03, 7.9595e-04, 3.4150e-02,\n",
       "         1.4514e-02, 5.3299e-02, 2.5371e-03, 6.5442e-04, 8.6666e-04, 4.8114e-03,\n",
       "         3.7861e-02, 1.3873e-03, 4.7937e-03, 8.9328e-03, 7.5132e-03, 1.7101e-02,\n",
       "         3.9785e-03, 1.4255e-03, 9.3021e-03, 8.7324e-03, 4.7627e-03, 3.6831e-03,\n",
       "         2.8522e-02, 5.8125e-03, 9.4026e-03, 1.1709e-03, 2.1347e-02, 3.1745e-02,\n",
       "         7.6126e-03, 1.1382e-03, 4.4178e-03, 5.0627e-03, 1.2924e-02, 1.6928e-03,\n",
       "         3.2096e-03, 2.8807e-03, 2.0305e-02, 9.9852e-03, 2.6420e-03, 7.3881e-03,\n",
       "         3.2994e-02, 5.3567e-02, 1.8450e-02, 1.6477e-02, 1.5750e-02, 1.1325e-02,\n",
       "         1.0011e-02, 5.7479e-03, 1.1663e-03, 1.4501e-03, 4.0248e-04, 2.0302e-02,\n",
       "         1.1675e-02, 4.8549e-03, 3.6444e-03, 8.5738e-02, 2.8393e-02, 2.2258e-04,\n",
       "         5.8493e-03, 2.0114e-02, 2.4021e-02, 3.1025e-02, 1.6540e-02, 3.6332e-02,\n",
       "         8.3100e-04, 8.7732e-02, 1.3696e-02, 6.2205e-02, 8.6401e-02, 1.0588e-01,\n",
       "         2.0704e-02, 1.8047e-02, 1.8299e-02, 1.2394e-03, 1.4223e-02, 9.4132e-02,\n",
       "         1.5058e-03, 2.8841e-02, 2.0006e-02, 4.2540e-02, 4.7675e-03, 2.4167e-02,\n",
       "         8.9306e-02, 6.6370e-03, 4.9375e-03, 2.5865e-03, 2.1353e-01, 1.2878e-01,\n",
       "         6.9633e-03, 4.1161e-02, 8.6036e-03, 4.5456e-03, 1.1086e-02, 4.9880e-03,\n",
       "         1.2064e-02, 2.8312e-03, 1.7529e-02, 2.1719e-04, 7.6604e-03, 1.1125e-02,\n",
       "         8.4517e-03, 8.2641e-04, 9.4824e-03, 3.5466e-03, 1.5401e-02, 1.9179e-02,\n",
       "         5.7119e-01, 7.1671e-05], device='cuda:0', requires_grad=True)}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewc._precision_matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8b819973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for n, p in model.named_parameters():\n",
    "    print(p - p.data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "793bce91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        ...,\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "        [0., 0., 0.,  ..., 0., 0., 0.]], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
      "        0., 0., 0., 0., 0., 0., 0., 0.], device='cuda:0',\n",
      "       grad_fn=<SubBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0., device='cuda:0', grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ewc.penalty(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4325460b",
   "metadata": {},
   "outputs": [],
   "source": [
    "src, trg = squad['train']['src'][0], squad['train']['trg'][0]\n",
    "src, trg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45b35d0f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.train()\n",
    "input_ids = tokenizer(src, return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "labels = tokenizer(trg, return_tensors=\"pt\", padding=True).input_ids.to(device)\n",
    "output = model(input_ids=input_ids, labels=labels)\n",
    "#loss = F.nll_loss(F.log_softmax(output.logits, dim=2).squeeze(), labels.squeeze())\n",
    "output.loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2275bfed",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.all(torch.tensor([torch.all(p.grad == 0) for n, p, in model.named_parameters()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceffc87f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "sentence = \"paraphrase: From the merger of the Four Rivers Council and the Audubon Council , the Shawnee Trails Council was born.\"\n",
    "\n",
    "encoding = tokenizer.encode_plus(sentence,pad_to_max_length=True, return_tensors=\"pt\")\n",
    "input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    beam_outputs = model.generate(\n",
    "        input_ids=input_ids, attention_mask=attention_masks,\n",
    "        do_sample=True,\n",
    "        max_length=256,\n",
    "        top_k=120,\n",
    "        top_p=0.98,\n",
    "        early_stopping=True,\n",
    "        num_return_sequences=10\n",
    "    )\n",
    "    print (\"\\nOriginal:\")\n",
    "    print (sentence)\n",
    "    print (\"\\n\")\n",
    "    print (\"Paraphrases:\")\n",
    "    final_outputs =[]\n",
    "    for beam_output in beam_outputs:\n",
    "        sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "        if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
    "            final_outputs.append(sent)\n",
    "\n",
    "    for i, final_output in enumerate(final_outputs):\n",
    "        print(\"{}: {}\".format(i, final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc076c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_squad(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8c33f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "paraphrases['train']['sentence1'][0][12:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8130d1ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "sentence = paraphrases['train']['sentence1'][0]\n",
    "\n",
    "encoding = tokenizer.encode_plus(sentence,pad_to_max_length=True, return_tensors=\"pt\")\n",
    "input_ids, attention_masks = encoding[\"input_ids\"].to(device), encoding[\"attention_mask\"].to(device)\n",
    "\n",
    "with torch.no_grad():\n",
    "    beam_outputs = model.generate(\n",
    "        input_ids=input_ids, attention_mask=attention_masks,\n",
    "        do_sample=True,\n",
    "        max_length=256,\n",
    "        top_k=120,\n",
    "        top_p=0.98,\n",
    "        early_stopping=True,\n",
    "        num_return_sequences=10\n",
    "    )\n",
    "    print (\"\\nOriginal:\")\n",
    "    print (sentence)\n",
    "    print (\"\\n\")\n",
    "    print (\"Paraphrases:\")\n",
    "    final_outputs =[]\n",
    "    for beam_output in beam_outputs:\n",
    "        sent = tokenizer.decode(beam_output, skip_special_tokens=True,clean_up_tokenization_spaces=True)\n",
    "        if sent.lower() != sentence.lower() and sent not in final_outputs:\n",
    "            final_outputs.append(sent)\n",
    "\n",
    "    for i, final_output in enumerate(final_outputs):\n",
    "        print(\"{}: {}\".format(i, final_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beba1d49",
   "metadata": {},
   "outputs": [],
   "source": [
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a85dc4f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
